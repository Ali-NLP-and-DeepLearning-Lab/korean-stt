{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled6.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Joovvhan/korean-stt/blob/master/kang/seq2seqtuto.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdGCiZQFIdqu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "1bfed7ce-b6c8-44f2-dfc7-ec18aa54fd5d"
      },
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G32aTpbdI5JJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "#word에서 index, index에서 word를 찾는 사전, 희귀 단어를 대체하는데 사용할\n",
        "# 단어의 빈도 수를 가진 Lang이라는 class\n",
        "class Lang:\n",
        "  def __init__(self, name):\n",
        "    self.name = name\n",
        "    self.wordToIndex = {}\n",
        "    self.wordToCount = {}\n",
        "    self.indexToWord = {0:\"SOS\", 1:\"EOS\"}\n",
        "    self.n_words = 2\n",
        "    \n",
        "  def addSentence(self, sentence):\n",
        "    for word in sentence.split(' '):\n",
        "      self.addWord(word)\n",
        "      \n",
        "  def addWord(self, word):\n",
        "    if word not in self.wordToIndex:\n",
        "      self.wordToIndex[word] = self.n_words\n",
        "      self.wordToCount[word] = 1\n",
        "      self.indexToWord[self.n_words] = word\n",
        "      self.n_words += 1\n",
        "    else:\n",
        "      self.wordToCount[word] += 1\n",
        "  \n",
        "\n",
        "def unicodeToAscii(s):\n",
        "  return ''.join(\n",
        "    c for c in unicodedata.normalize('NFD', s)\n",
        "    if unicodedata.category(c) != 'Mn'\n",
        "  )\n",
        "\n",
        "#문자 아닌 문자 제거, 소문자 다듬기\n",
        "def normalizeString(s):\n",
        "  s = unicodeToAscii(s.lower().strip())\n",
        "  s = re.sub(r\"([.!?])\", r\"\\1\", s)\n",
        "  s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
        "  return s\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrINg788KZKI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def readLangs(lang1, lang2, reverse=False):\n",
        "  print(\"Reading lines...\")\n",
        "  \n",
        "  lines = open('gdrive/My Drive/EnglishFrench/%s-%s.txt' % (lang1, lang2), encoding='utf-8').read().strip().split('\\n')\n",
        "  \n",
        "  pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
        "  \n",
        "  if reverse:\n",
        "    pairs = [list(reversed(p)) for p in pairs]\n",
        "    inputLang = Lang(lang1)\n",
        "    outputLang = Lang(lang2)\n",
        "  else:\n",
        "    inputLang = Lang(lang1)\n",
        "    outputLang = Lang(lang2)\n",
        "    \n",
        "  return inputLang, outputLang, pairs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYO8NNHFMkcz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_LENGTH = 10\n",
        "\n",
        "eng_prefixes = (\n",
        "  \"i am\", \"i m \",\n",
        "  \"he is\", \"he s \",\n",
        "  \"she is\", \"she s\",\n",
        "  \"you are\", \"you re \",\n",
        "  \"we are\", \"we re \", \"they are\", \"they re \"\n",
        ")\n",
        "\n",
        "def filterPair(p):\n",
        "  return len(p[0].split(' ')) < MAX_LENGTH and len(p[1].split(' ')) < MAX_LENGTH and \\\n",
        "    p[1].startswith(eng_prefixes)\n",
        "\n",
        "def filterPairs(pairs):\n",
        "  return [pair for pair in pairs if filterPair(pair)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ucireOBmTty",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "a28cf0ca-6184-46c2-a123-0b59c93b809b"
      },
      "source": [
        "#파일을 줄->쌍으로 분리\n",
        "#텍스트 정규화, 길이와 내용으로 필터링\n",
        "#쌍의 문장에서 단어 리스트 생성\n",
        "\n",
        "def prepareData(lang1, lang2, reverse=False):\n",
        "  input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
        "  pairs = filterPairs(pairs)\n",
        "  for pair in pairs:\n",
        "    input_lang.addSentence(pair[0])\n",
        "    output_lang.addSentence(pair[1])\n",
        "  return input_lang, output_lang, pairs\n",
        "\n",
        "input_lang, output_lang, pairs = prepareData('eng', 'fra', True)\n",
        "print(random.choice(pairs))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading lines...\n",
            "['vous n etes pas les seuls avec ce probleme.', 'you re not the only one with this problem.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIcgPNemvqmm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#seq2seq 인코더, 디코더 // 둘을 연결시켜서 쓰면 된다.\n",
        "\n",
        "class EncodeRNN(nn.Module):\n",
        "  def __init__(self,input_size, hidden_size):\n",
        "    super(EncodeRNN, self).__init__()\n",
        "    self.hiddenSize = hidden_size\n",
        "    \n",
        "    self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "    self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "    \n",
        "  def forward(self, input, hidden):\n",
        "    embedded = self.embedding(input).view(1,1,-1)\n",
        "    output = embedded\n",
        "    output, hidden = self.gru(output, hidden)\n",
        "    return output, hidden\n",
        "  \n",
        "  def initHidden(self):\n",
        "    return torch.zeros(1,1, self.hiddenSize, device=device)\n",
        "  \n",
        "  \n",
        "class DecodeRNN(nn.Module):\n",
        "  def __init__(self, hidden_size, output_size):\n",
        "    super(DecodeRNN, self).__init__()\n",
        "    self.hiddenSize = hidden_size\n",
        "    \n",
        "    self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "    self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "    self.out = nn.Linear(hidden_size, output_size)\n",
        "    self.softmax = nn.LogSoftmax(dim=1)\n",
        "    \n",
        "  def forward(self, input, hidden):\n",
        "    output = self.embedding(input).view(1,1,-1)\n",
        "    output = F.relu(output)\n",
        "    output, hidden = self.gru(output, hidden)\n",
        "    output = self.softmax(self.out(output[0]))\n",
        "    return output, hidden\n",
        "  \n",
        "  def initHidden(self):\n",
        "    return torch.zeros(1,1,self.hiddenSize, device=device)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7LM72s50cae",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 어텐션 디코더. 공간활용, 인코딩 부담 줄이기\n",
        "# 전체 문장을 한 번에 인코딩 하지 않고, 가중치를 계산해서 알맞은 출력 단어를 선택하도록\n",
        "\n",
        "class AttentionDecodeRNN(nn.Module):\n",
        "  def __init__(self, hidden_size, input_size, dropoutP=0.1, max_length=MAX_LENGTH):\n",
        "    super(AttentionDecodeRNN, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.input_size = input_size\n",
        "    self.output_size = input_size\n",
        "    self.dropoutP = dropoutP\n",
        "    self.max_length = max_length\n",
        "    \n",
        "    self.embedding = nn.Embedding(self.input_size, self.hidden_size)\n",
        "    self.attention = nn.Linear(self.hidden_size * 2, self.max_length)\n",
        "    self.attentionCombine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
        "    self.dropout = nn.Dropout(self.dropoutP)\n",
        "    self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
        "    self.out = nn.Linear(self.hidden_size, self.output_size)\n",
        "    \n",
        "  def forward(self, input, hidden, encodeOutputs):\n",
        "    embedded = self.embedding(input).view(1,1,-1)\n",
        "    embedded = self.dropout(embedded)\n",
        "    \n",
        "    attentionWeights = F.softmax(self.attention(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
        "    print(attentionWeights)\n",
        "    attentionApplied = torch.bmm(attentionWeights.unsqueeze(0), encodeOutputs)\n",
        "    print(attentionApplied)\n",
        "    output = torch.cat((embedded[0], attentionApplied[0]), 1)\n",
        "    output = self.attentionCombine(output).unsqueeze(0)\n",
        "    \n",
        "    output = F.relu(output)\n",
        "    otuput, hidden = self.gru(output, hidden)\n",
        "    \n",
        "    output = F.log_softmax(self.out(output[0]), dim=1)\n",
        "    return output, hidden, attentionWeights\n",
        "  \n",
        "  def initHidden(self):\n",
        "    return torch.zeros(1,1,self.hidden_size, device=device)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSP2cJ_UBqpw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#학습 데이터 준비\n",
        "\n",
        "def indexesFromSentence(lang, sentence):\n",
        "  return [lang.wordToIndex[word] for word in sentence.split(' ')]\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "  indexes = indexesFromSentence(lang, sentence)\n",
        "  indexes.append(EOS_token)\n",
        "  return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "def tensorFromPair(pair):\n",
        "  inputTensor = tensorFromSentence(input_lang, pair[0])\n",
        "  targetTensor = tensorFromSentence(output_lang, pair[1])\n",
        "  return (inputTensor, targetTensor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Ep2ok_ECRnP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#teacher forcing : 디코더의 예측대신 실제 목표 출력을 다음 입력으로 사용,\n",
        "#  수렴이 빠르지만 학습된 네트워크가 잘못 사용될 때 불안함\n",
        "\n",
        "teacher_forcing_ratio = 0.5\n",
        "\n",
        "def train(inputTensor, targetTensor, encoder, decoder, encodeOptimizer,\n",
        "         decodeOptimizer, criterion, max_length=MAX_LENGTH):\n",
        "  encodeHidden = encoder.initHidden()\n",
        "  encodeOptimizer.zero_grad()\n",
        "  decodeOptimizer.zero_grad()\n",
        "  \n",
        "  inputLength = inputTensor.size(0)\n",
        "  targetLength = targetTensor.size(0)\n",
        "  \n",
        "  encodeOutputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "  \n",
        "  loss = 0\n",
        "  \n",
        "  for t in range(inputLength):\n",
        "    encodeOutput, encodeHidden = encoder(inputTensor[t], encodeHidden)\n",
        "    encodeOutputs[t] = encodeOutput[0,0]\n",
        "    \n",
        "  decodeInput = torch.tensor([[SOS_token]], device=device)\n",
        "  decodeHidden = encodeHidden\n",
        "  \n",
        "  use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "  \n",
        "  if use_teacher_forcing:\n",
        "    for t in range(targetLength):\n",
        "      decodeOutput, decodeHidden, decodeAttention = decoder(\n",
        "        decodeInput, decodeHidden, encodeOutputs\n",
        "      )\n",
        "      loss += criterion(decodeOutput, targetTensor[t])\n",
        "      decodeInput = targetTensor[t]\n",
        "      \n",
        "  else:\n",
        "    for t in range(targetLength):\n",
        "      decodeOutput, decodeHidden, decodeAttention = decoder(decodeInput, decodeHidden, encodeOutputs)\n",
        "      topv, topi = decodeOutput.topk(1)\n",
        "      decodeInput = topi.squeeze().detach()\n",
        "      loss += criterion(decodeOutput, targetTensor[t])\n",
        "      if decodeInput.item() == EOS_token: break;\n",
        "  \n",
        "  loss.backward()\n",
        "  encodeOptimizer.step()\n",
        "  decodeOptimizer.step()\n",
        "  \n",
        "  return loss.item()/ targetLength"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXbXiSHdG_wi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 시간 출력\n",
        "\n",
        "import time\n",
        "import math\n",
        "\n",
        "def printMinutes(s):\n",
        "  m = math.floor(s/60)\n",
        "  s -= m*60\n",
        "  return '%dm %ds' % (m, s)\n",
        "\n",
        "def timeSince(since, percent):\n",
        "  now = time.time()\n",
        "  s = now - since\n",
        "  es = s / percent\n",
        "  rs = es - s\n",
        "  return '%s ( - %s)' % (printMinutes(s), primtMinutes(rs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4M0Pzt0oHYAF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#학습과정\n",
        "#1. 타이머\n",
        "#2. optimizer, criterion 초기화\n",
        "#3. 학습 쌍 세트 생성\n",
        "#4. loss\n",
        "\n",
        "#여러 번 train을 호출하여 진행률과 평균손실 출력\n",
        "\n",
        "def trainIters(encoder, decoder, nIters, printEvery=1000, plotEvery=100, learningRate=0.01):\n",
        "  start = time.time()\n",
        "  plotLosses = []\n",
        "  printLossTotal = 0\n",
        "  plotLossTotal = 0\n",
        "  \n",
        "  encodeOptimizer = optim.SGD(encoder.parameters(), lr=learningRate)\n",
        "  decodeOptimizer = optim.SGD(decoder.parameters(), lr=learningRate)\n",
        "  trainingPairs = [tensorFromPair(random.choice(pairs)) for i in range(nIters)]\n",
        "  criterion = nn.NLLLoss()\n",
        "  \n",
        "  for iter in range(1, nIters+1):\n",
        "    trainingPair = trainingPairs[iter-1]\n",
        "    inputTensor = trainingPair[0]\n",
        "    targetTensor = trainingPair[1]\n",
        "    \n",
        "    loss = train(inputTensor, targetTensor, encoder, decoder,\n",
        "                encodeOptimizer, decodeOptimizer, criterion)\n",
        "    printLossTotal += loss\n",
        "    plotLossTotal += loss\n",
        "    \n",
        "    if iter % printEvery == 0:\n",
        "      printLossAvg = printLossTotal / printEvery\n",
        "      printLossTotal = 0\n",
        "      print('%s (%d %d%%) %.4f' % (timeSince(start, iter / nIters), iter, iter/nIters * 100,\n",
        "           printLossAvg))\n",
        "\n",
        "    if iter % plotEvery == 0:\n",
        "      plotLossAvg = plotLossTotal / plotEvery\n",
        "      plotLosses.append(plotLossAvg)\n",
        "      plotLossTotal = 0\n",
        "      \n",
        "  showPlot(plotLosses)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmRj7-43KOXa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "\n",
        "def showPlot(points):\n",
        "  plt.figure()\n",
        "  fig, ax = plt.subplots()\n",
        "  loc = ticker.MultipleLocator(base=0.2)\n",
        "  ax.yaxis.set_major_locator(loc)\n",
        "  plt.plot(points)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TIOX8DfKgvo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#각 단계마다 디코더의 예측을 되돌려 전달, 예측할 때마다 단어를 출력\n",
        "# EOS토큰 예측 시, 멈춤\n",
        "\n",
        "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
        "  with torch.no_grad():\n",
        "    inputTensor = tensorFromSentence(input_lang, sentence)\n",
        "    inputLength = inputTensor.size()[0]\n",
        "    encodeHidden = encoder.initHidden()\n",
        "    \n",
        "    encodeOutputs = torch.zeros(max_length, encoder.hiddenSize, device=device)\n",
        "    \n",
        "    for t in range(inputLength):\n",
        "      encodeOutput, encodeHidden = encoder(inputTensor[t], encodeHidden)\n",
        "      encodeOutputs[t] += encodeOutput[0,0]\n",
        "      \n",
        "    decodeInput = torch.tensor([[SOS_token]], device=device)\n",
        "    decodeHidden = encodeHidden\n",
        "    \n",
        "    decodedWords = []\n",
        "    decodeAttentions = torch.zeros(max_length, max_length)\n",
        "    \n",
        "    for t in range(max_length):\n",
        "      decodeOutput, decodeHidden, decodeAttention = decoder(\n",
        "        decodeInput, decodeHidden, encodeOutput)\n",
        "      decodeAttentions[t] = decodeAttention.data\n",
        "      topv, topi = decodeOutput.data.topk(1)\n",
        "      if topi.item() == EOS_token:\n",
        "        decodedWords.append('<EOS>')\n",
        "        break\n",
        "      else: decodedWord.append(output_lang.indexToWord[topi.item()])\n",
        "        \n",
        "      decodeInput = topi.squeeze().detach()\n",
        "      \n",
        "    return decodedWords, decodeAttentions[:t + 1]\n",
        "  \n",
        "def evaluateRandom(encoder, decoder, n=10):\n",
        "  for i in range(n):\n",
        "    pair = random.choice(pairs)\n",
        "    print('>', pair[0])\n",
        "    print('=', pair[1])\n",
        "    outputWords, attentions = evaluate(encoder, decoder, pair[0])\n",
        "    outputSentence = ''.join(outputWords)\n",
        "    print('<', outputSentence)\n",
        "    print('')\n",
        "    \n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EutyGLuRPypX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hidden_size = 256\n",
        "encoder1 = EncodeRNN(input_lang.n_words, hidden_size).to(device)\n",
        "attndecoder1 = AttentionDecodeRNN(hidden_size, output_lang.n_words, dropoutP=0.1).to(device)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}