{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from datetime import datetime\n",
    "from utils_local import *\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "char2index = dict()\n",
    "index2char = dict()\n",
    "SOS_token = 0\n",
    "EOS_token = 0\n",
    "PAD_token = 0\n",
    "\n",
    "DATASET_PATH = 'D:/nsml-dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 6\n",
    "num_thread = 4\n",
    "num_mels = 160\n",
    "num_hidden_enc = 1024\n",
    "num_hidden_dec = 512\n",
    "num_hidden_seq = 1024\n",
    "num_layers = 6\n",
    "lr_1 = 1e-4\n",
    "lr_2 = 1e-4\n",
    "train_ratio = .6\n",
    "nsc_in_ms = 40\n",
    "loss_lim = 0.03\n",
    "max_epochs = 100\n",
    "ref_repeat = 1\n",
    "\n",
    "filename = './model_saved/nsml_local_6_layer_residual'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "char2index, index2char = load_label_local(os.path.join(DATASET_PATH, 'hackathon.labels'))\n",
    "SOS_token = char2index['<s>']  # '<sos>' or '<s>'\n",
    "EOS_token = char2index['</s>']  # '<eos>' or '</s>'\n",
    "PAD_token = char2index['_']  # '-' or '_'\n",
    "\n",
    "unicode_jamo_list = My_Unicode_Jamo_v2()\n",
    "\n",
    "tokenizer = Tokenizer(unicode_jamo_list)\n",
    "jamo_tokens = tokenizer.word2num(unicode_jamo_list)\n",
    " \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mel2SeqNet_General_Residual(\n",
      "  (encoder): Encoder_General_Residual(\n",
      "    (fc): Linear(in_features=160, out_features=1024, bias=True)\n",
      "    (relu): ReLU()\n",
      "    (dropout): Dropout(p=0.2, inplace=False)\n",
      "    (gru_layers): ModuleList(\n",
      "      (0): Residual_GRU(\n",
      "        (gru): GRU(1024, 512, batch_first=True, bidirectional=True)\n",
      "      )\n",
      "      (1): Residual_GRU(\n",
      "        (gru): GRU(1024, 512, batch_first=True, bidirectional=True)\n",
      "      )\n",
      "      (2): Residual_GRU(\n",
      "        (gru): GRU(1024, 512, batch_first=True, bidirectional=True)\n",
      "      )\n",
      "      (3): Residual_GRU(\n",
      "        (gru): GRU(1024, 512, batch_first=True, bidirectional=True)\n",
      "      )\n",
      "      (4): Residual_GRU(\n",
      "        (gru): GRU(1024, 512, batch_first=True, bidirectional=True)\n",
      "      )\n",
      "      (5): Residual_GRU(\n",
      "        (gru): GRU(1024, 512, batch_first=True, bidirectional=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): CTC_Decoder_General_Residual(\n",
      "    (fc_embed): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    (relu_embed): ReLU()\n",
      "    (dropout_embed): Dropout(p=0.2, inplace=False)\n",
      "    (gru_layers): ModuleList(\n",
      "      (0): GRU(1024, 512, batch_first=True)\n",
      "      (1): Residual_GRU(\n",
      "        (gru): GRU(512, 512, batch_first=True)\n",
      "      )\n",
      "      (2): Residual_GRU(\n",
      "        (gru): GRU(512, 512, batch_first=True)\n",
      "      )\n",
      "      (3): Residual_GRU(\n",
      "        (gru): GRU(512, 512, batch_first=True)\n",
      "      )\n",
      "      (4): Residual_GRU(\n",
      "        (gru): GRU(512, 512, batch_first=True)\n",
      "      )\n",
      "      (5): Residual_GRU(\n",
      "        (gru): GRU(512, 512, batch_first=True)\n",
      "      )\n",
      "    )\n",
      "    (fc): Linear(in_features=512, out_features=76, bias=True)\n",
      "    (log_softmax): LogSoftmax()\n",
      "  )\n",
      ")\n",
      "Seq2SeqNet_v2(\n",
      "  (embedding_layer): Embedding(76, 1024)\n",
      "  (embedding_layer_2): Embedding(820, 1024)\n",
      "  (encoder): EncoderRNN(\n",
      "    (gru): GRU(1024, 512, bidirectional=True)\n",
      "  )\n",
      "  (decoder): AttnDecoderRNN(\n",
      "    (attn): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "    (attn_combine): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (gru): GRU(1024, 1024)\n",
      "    (out): Linear(in_features=1024, out_features=820, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = Mel2SeqNet_General_Residual(num_mels, num_hidden_enc, num_hidden_dec, len(unicode_jamo_list), num_layers, device)\n",
    "net_optimizer = optim.Adam(net.parameters(), lr=lr_1)\n",
    "ctc_loss = nn.CTCLoss().to(device)\n",
    "\n",
    "net_B = Seq2SeqNet_v2(num_hidden_seq, jamo_tokens, char2index, device)\n",
    "net_B_optimizer = optim.Adam(net_B.parameters(), lr=lr_2)\n",
    "net_B_criterion = nn.NLLLoss(reduction='none').to(device)\n",
    "\n",
    "print(net)\n",
    "print(net_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wav_paths len: 29805\n",
      "script_paths len: 29805\n",
      "korean_script_paths len: 29805\n",
      "Korean script 0: 예약하고 싶은데 어떻게 해야하나요?\n",
      "Korean script 0 length: 19\n",
      "Jamo script 0: 예약하고 싶은데 어떻게 해야하나요?\n",
      "Jamo script 0 length: 38\n"
     ]
    }
   ],
   "source": [
    "wav_paths, script_paths, korean_script_paths = get_paths(DATASET_PATH)\n",
    "\n",
    "print('wav_paths len: {}'.format(len(wav_paths)))\n",
    "print('script_paths len: {}'.format(len(script_paths)))\n",
    "print('korean_script_paths len: {}'.format(len(korean_script_paths)))\n",
    "\n",
    "korean_script_list, jamo_script_list = get_korean_and_jamo_list_v2_local(korean_script_paths)\n",
    "\n",
    "print('Korean script 0: {}'.format(korean_script_list[0]))\n",
    "print('Korean script 0 length: {}'.format(len(korean_script_list[0])))\n",
    "print('Jamo script 0: {}'.format(jamo_script_list[0]))\n",
    "print('Jamo script 0 length: {}'.format(len(jamo_script_list[0])))\n",
    "\n",
    "script_path_list = get_script_list(script_paths, SOS_token, EOS_token)\n",
    "\n",
    "ground_truth_list = [(tokenizer.word2num(['<s>'] + list(jamo_script_list[i]) + ['</s>'])) for i in\n",
    "                     range(len(jamo_script_list))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Ratio: 0.6\n",
      "Total:Train:Eval = 29805:17883:11922\n"
     ]
    }
   ],
   "source": [
    "print('Train Ratio: {}'.format(train_ratio))\n",
    "split_index = int(train_ratio * len(wav_paths))\n",
    "\n",
    "wav_path_list_train = wav_paths[:split_index]\n",
    "ground_truth_list_train = ground_truth_list[:split_index]\n",
    "korean_script_list_train = korean_script_list[:split_index]\n",
    "script_path_list_train = script_path_list[:split_index]\n",
    "\n",
    "wav_path_list_eval = wav_paths[split_index:]\n",
    "ground_truth_list_eval = ground_truth_list[split_index:]\n",
    "korean_script_list_eval = korean_script_list[split_index:]\n",
    "script_path_list_eval = script_path_list[split_index:]\n",
    "\n",
    "print('Total:Train:Eval = {}:{}:{}'.format(len(wav_paths), len(wav_path_list_train), len(wav_path_list_eval)))\n",
    "\n",
    "preloader_train = Threading_Batched_Preloader_v2(wav_path_list_train, ground_truth_list_train,\n",
    "                                                 script_path_list_train, korean_script_list_train, batch_size,\n",
    "                                                 num_mels, nsc_in_ms, is_train=True)\n",
    "\n",
    "preloader_eval = Threading_Batched_Preloader_v2(wav_path_list_eval, ground_truth_list_eval, script_path_list_eval,\n",
    "                                                korean_script_list_eval, batch_size, num_mels, nsc_in_ms,\n",
    "                                                is_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_loss = 1e10\n",
    "best_eval_cer = 1e10\n",
    "\n",
    "# load all target scripts for reducing disk i/o\n",
    "target_path = os.path.join(DATASET_PATH, 'train_label')\n",
    "load_targets(target_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No previous data on ./model_saved/nsml_local_6_layer_residual\n",
      "start\n",
      "10-06 16:59:05\n",
      "4471\n",
      "batch initialized\n",
      "Initialized Training Preloader\n",
      "Train: Count 198 | 혹시 브레이크 타임이 있다면  언제 인가요?  => 혹시  레이크 임이       인인가요 \n",
      "Train: Count 198 | 혹시 브레이크 타임이 있다면  언제 인가요?  => <s>ㅏ요?</s> => None\n",
      "Train: Count 396 | 삼성카드 할인 몇퍼센트인가요?  => 사사카드 할인인 몇 시인인가? \n",
      "Train: Count 396 | 삼성카드 할인 몇퍼센트인가요?  => <s>싸요?</s> => None\n",
      "Train: Count 594 | 학생할인받고 멤버십할인도 받을수 있나요?  => 학생할인인가   버다        있나나요      \n",
      "Train: Count 594 | 학생할인받고 멤버십할인도 받을수 있나요?  => <s>ㅣ나요?</s> => None\n",
      "Train: Count 792 | 런치 특별 세트나 도시락 등 있나요?  => 런치 트트   트      있있요?  \n",
      "Train: Count 792 | 런치 특별 세트나 도시락 등 있나요?  => <s>ㅣㅏㄴ나요?</s> => None\n",
      "Train: Count 990 | 아이들이 먹을 수 있는 전용 메뉴가 있을까요?  => 아이이이 먹을  있는 있는  메뉴뉴가 있있요???\n",
      "Train: Count 990 | 아이들이 먹을 수 있는 전용 메뉴가 있을까요?  => <s>ㅇ이나요?</s> => None\n",
      "Train: Count 1188 | 얼마나 기다려야 돼요?  => 마마 가리다려  되요? \n",
      "Train: Count 1188 | 얼마나 기다려야 돼요?  => <s>미나요?</s> => None\n",
      "Train: Count 1386 | 오후 3시 경에 가려고 하는데 혹시 브레이크 타임인가요?  => 오후 3시  에 가려고하하하데  레이이크    인가요??\n",
      "Train: Count 1386 | 오후 3시 경에 가려고 하는데 혹시 브레이크 타임인가요?  => <s>있나요?</s> => None\n"
     ]
    }
   ],
   "source": [
    "loss_train_history = list()\n",
    "seq2seq_loss_train_history = list()\n",
    "seq2seq_loss_train_ref_history = list()\n",
    "\n",
    "loss_eval_history = list()\n",
    "seq2seq_loss_eval_history = list()\n",
    "seq2seq_loss_eval_ref_history = list()\n",
    "\n",
    "try:\n",
    "    loss_train_history = list(np.load(os.path.join(filename, 'loss_train_history.npy')))\n",
    "    seq2seq_loss_train_history = list(np.load(os.path.join(filename, 'seq2seq_loss_train_history.npy')))\n",
    "    seq2seq_loss_train_ref_history = list(np.load(os.path.join(filename, 'loss_train_history.npy')))\n",
    "\n",
    "    loss_eval_history = list(np.load(os.path.join(filename, 'loss_eval_history.npy')))\n",
    "    seq2seq_loss_eval_history = list(np.load(os.path.join(filename, 'seq2seq_loss_eval_history.npy')))\n",
    "    seq2seq_loss_eval_ref_history = list(np.load(os.path.join(filename, 'seq2seq_loss_eval_ref_history.npy')))\n",
    "\n",
    "    state = torch.load(os.path.join(filename, 'modelA.pt'))\n",
    "    net.load_state_dict(state['model'])\n",
    "    net_optimizer.load_state_dict(state['optimizer'])\n",
    "\n",
    "    state = torch.load(os.path.join(filename, 'modelB.pt'))\n",
    "    net_B.load_state_dict(state['model'])\n",
    "    net_B_optimizer.load_state_dict(state['optimizer'])\n",
    "    \n",
    "    print(\"Loaded from {}\".format(filename))\n",
    "    \n",
    "except:\n",
    "    print(\"No previous data on {}\".format(filename))\n",
    "\n",
    "print('start')\n",
    "\n",
    "train_begin = time.time()\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "\n",
    "    print((datetime.now().strftime('%m-%d %H:%M:%S')))\n",
    "\n",
    "    net.train()\n",
    "    net_B.train()\n",
    "\n",
    "    preloader_train.initialize_batch(num_thread)\n",
    "    loss_list_train = list()\n",
    "    seq2seq_loss_list_train = list()\n",
    "    seq2seq_loss_list_train_ref = list()\n",
    "\n",
    "    print(\"Initialized Training Preloader\")\n",
    "    count = 0\n",
    "\n",
    "    total_dist = 0\n",
    "    total_length = 1\n",
    "    total_dist_ref = 0\n",
    "    total_length_ref = 1\n",
    "\n",
    "    while not preloader_train.end_flag:\n",
    "        batch = preloader_train.get_batch()\n",
    "        if batch is not None:\n",
    "            tensor_input, ground_truth, loss_mask, length_list, batched_num_script, batched_num_script_loss_mask = batch\n",
    "            pred_tensor, loss = train(net, net_optimizer, ctc_loss, tensor_input.to(device),\n",
    "                                      ground_truth.to(device), length_list.to(device), device)\n",
    "            loss_list_train.append(loss)\n",
    "            jamo_result = Decode_Prediction_No_Filtering(pred_tensor, tokenizer)\n",
    "            true_string_list = Decode_Num_Script(batched_num_script.detach().cpu().numpy(), index2char)\n",
    "\n",
    "            for i in range(ref_repeat):\n",
    "                lev_input_ref = ground_truth\n",
    "\n",
    "                lev_pred_ref, attentions_ref, seq2seq_loss_ref = net_B.net_train(lev_input_ref.to(device),\n",
    "                                                                                 batched_num_script.to(device),\n",
    "                                                                                 batched_num_script_loss_mask.to(\n",
    "                                                                                     device),\n",
    "                                                                                 net_B_optimizer,\n",
    "                                                                                 net_B_criterion)\n",
    "\n",
    "                pred_string_list_ref = Decode_Lev_Prediction(lev_pred_ref, index2char)\n",
    "                seq2seq_loss_list_train_ref.append(seq2seq_loss_ref)\n",
    "                dist_ref, length_ref = char_distance_list(true_string_list, pred_string_list_ref)\n",
    "\n",
    "                pred_string_list = [None]\n",
    "\n",
    "                dist = 0\n",
    "                length = 0\n",
    "\n",
    "                if (loss < loss_lim):\n",
    "                    lev_input = Decode_CTC_Prediction_And_Batch(pred_tensor)\n",
    "                    lev_pred, attentions, seq2seq_loss = net_B.net_train(lev_input.to(device),\n",
    "                                                                         batched_num_script.to(device),\n",
    "                                                                         batched_num_script_loss_mask.to(device),\n",
    "                                                                         net_B_optimizer, net_B_criterion)\n",
    "                    pred_string_list = Decode_Lev_Prediction(lev_pred, index2char)\n",
    "                    seq2seq_loss_list_train.append(seq2seq_loss)\n",
    "                    dist, length = char_distance_list(true_string_list, pred_string_list)\n",
    "\n",
    "            total_dist_ref += dist_ref\n",
    "            total_length_ref += length_ref\n",
    "\n",
    "            total_dist += dist\n",
    "            total_length += length\n",
    "\n",
    "            count += 1\n",
    "\n",
    "            if count % (int(len(wav_path_list_train) / batch_size / 15)) == 0:\n",
    "                print(\"Train: Count {} | {} => {}\".format(count, true_string_list[0], pred_string_list_ref[0]))\n",
    "\n",
    "                print(\"Train: Count {} | {} => {} => {}\".format(count, true_string_list[0], jamo_result[0],\n",
    "                                                                      pred_string_list[0]))\n",
    "\n",
    "        else:\n",
    "            print(\"Training Batch is None\")\n",
    "\n",
    "    train_loss = np.mean(np.asarray(loss_list_train))\n",
    "    train_cer = np.mean(np.asarray(total_dist / total_length))\n",
    "    train_cer_ref = np.mean(np.asarray(total_dist_ref / total_length_ref))\n",
    "\n",
    "    print(\"Mean Train Loss: {}\".format(train_loss))\n",
    "    print(\"Total Train CER: {}\".format(train_cer))\n",
    "    print(\"Total Train Reference CER: {}\".format(train_cer_ref))\n",
    "\n",
    "    preloader_eval.initialize_batch(num_thread)\n",
    "    loss_list_eval = list()\n",
    "    seq2seq_loss_list_eval = list()\n",
    "    seq2seq_loss_list_eval_ref = list()\n",
    "\n",
    "    print(\"Initialized Evaluation Preloader\")\n",
    "\n",
    "    count = 0\n",
    "    total_dist = 0\n",
    "    total_length = 1\n",
    "    total_dist_ref = 0\n",
    "    total_length_ref = 1\n",
    "\n",
    "    net.eval()\n",
    "    net_B.eval()\n",
    "\n",
    "    while not preloader_eval.end_flag:\n",
    "        batch = preloader_eval.get_batch()\n",
    "        if batch is not None:\n",
    "            tensor_input, ground_truth, loss_mask, length_list, batched_num_script, batched_num_script_loss_mask = batch\n",
    "            pred_tensor, loss = evaluate(net, ctc_loss, tensor_input.to(device), ground_truth.to(device),\n",
    "                                         length_list.to(device), device)\n",
    "            loss_list_eval.append(loss)\n",
    "\n",
    "            jamo_result = Decode_Prediction_No_Filtering(pred_tensor, tokenizer)\n",
    "\n",
    "            true_string_list = Decode_Num_Script(batched_num_script.detach().cpu().numpy(), index2char)\n",
    "\n",
    "            lev_input_ref = ground_truth\n",
    "            lev_pred_ref, attentions_ref, seq2seq_loss_ref = net_B.net_eval(lev_input_ref.to(device),\n",
    "                                                                            batched_num_script.to(device),\n",
    "                                                                            batched_num_script_loss_mask.to(device),\n",
    "                                                                            net_B_criterion)\n",
    "\n",
    "            pred_string_list_ref = Decode_Lev_Prediction(lev_pred_ref, index2char)\n",
    "            seq2seq_loss_list_train_ref.append(seq2seq_loss_ref)\n",
    "            dist_ref, length_ref = char_distance_list(true_string_list, pred_string_list_ref)\n",
    "\n",
    "            pred_string_list = [None]\n",
    "\n",
    "            dist = 0\n",
    "            length = 0\n",
    "\n",
    "            if (loss < loss_lim):\n",
    "                lev_input = Decode_CTC_Prediction_And_Batch(pred_tensor)\n",
    "                lev_pred, attentions, seq2seq_loss = net_B.net_eval(lev_input.to(device),\n",
    "                                                                    batched_num_script.to(device),\n",
    "                                                                    batched_num_script_loss_mask.to(device),\n",
    "                                                                    net_B_criterion)\n",
    "                pred_string_list = Decode_Lev_Prediction(lev_pred, index2char)\n",
    "                seq2seq_loss_list_train.append(seq2seq_loss)\n",
    "                dist, length = char_distance_list(true_string_list, pred_string_list)\n",
    "\n",
    "            total_dist_ref += dist_ref\n",
    "            total_length_ref += length_ref\n",
    "\n",
    "            total_dist += dist\n",
    "            total_length += length\n",
    "\n",
    "            count += 1\n",
    "\n",
    "            if count % (int(len(wav_path_list_eval) / batch_size / 15)) == 0:\n",
    "                print(\"Eval: Count {} | {} => {}\".format(count, true_string_list[0], pred_string_list_ref[0]))\n",
    "\n",
    "                print(\"Eval: Count {} | {} => {} => {}\".format(count, true_string_list[0], jamo_result[0],\n",
    "                                                                     pred_string_list[0]))\n",
    "\n",
    "        else:\n",
    "            print(\"Training Batch is None\")\n",
    "\n",
    "    eval_cer = total_dist / total_length\n",
    "    eval_cer_ref = total_dist_ref / total_length_ref\n",
    "    eval_loss = np.mean(np.asarray(loss_list_eval))\n",
    "\n",
    "    print(\"Mean Evaluation Loss: {}\".format(eval_loss))\n",
    "    print(\"Total Evaluation CER: {}\".format(eval_cer))\n",
    "    print(\"Total Evaluation Reference CER: {}\".format(eval_cer_ref))\n",
    "    \n",
    "    loss_train_history.append(train_loss)\n",
    "    seq2seq_loss_train_history.append(train_cer)\n",
    "    seq2seq_loss_train_ref_history.append(train_cer_ref)\n",
    "\n",
    "    loss_eval_history.append(eval_loss)\n",
    "    seq2seq_loss_eval_history.append(eval_cer)\n",
    "    seq2seq_loss_eval_ref_history.append(eval_cer_ref)\n",
    "    \n",
    "    f, (ax1, ax2, ax3) = plt.subplots(1, 3)\n",
    "    ax1.plot(loss_train_history)\n",
    "    ax1.plot(loss_eval_history)\n",
    "    \n",
    "    ax2.plot(seq2seq_loss_train_history)\n",
    "    ax2.plot(seq2seq_loss_eval_history)\n",
    "    \n",
    "    ax3.plot(seq2seq_loss_train_ref_history)\n",
    "    ax3.plot(seq2seq_loss_eval_ref_history)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    if not os.path.exists(filename):\n",
    "        os.makedirs(filename)\n",
    "\n",
    "    np.save(os.path.join(filename, 'loss_train_history.npy'), loss_train_history)\n",
    "    np.save(os.path.join(filename, 'seq2seq_loss_train_history.npy'), seq2seq_loss_train_history)\n",
    "    np.save(os.path.join(filename, 'loss_train_history.npy'), seq2seq_loss_train_ref_history)\n",
    "\n",
    "    np.save(os.path.join(filename, 'loss_eval_history.npy'), loss_eval_history)\n",
    "    np.save(os.path.join(filename, 'seq2seq_loss_eval_history.npy'), seq2seq_loss_eval_history)\n",
    "    np.save(os.path.join(filename, 'seq2seq_loss_eval_ref_history.npy'), seq2seq_loss_eval_ref_history)\n",
    "\n",
    "    state = {\n",
    "        'model': net.state_dict(),\n",
    "        'optimizer': net_optimizer.state_dict()\n",
    "    }\n",
    "    torch.save(state, os.path.join(filename, 'modelA.pt'))\n",
    "\n",
    "    state = {\n",
    "        'model': net_B.state_dict(),\n",
    "        'optimizer': net_B_optimizer.state_dict()\n",
    "    }\n",
    "    torch.save(state, os.path.join(filename, 'modelB.pt'))\n",
    "\n",
    "    best_model = (eval_cer < best_eval_cer)\n",
    "    \n",
    "    if best_model:\n",
    "        state = {\n",
    "            'model': net.state_dict(),\n",
    "            'optimizer': net_optimizer.state_dict()\n",
    "        }\n",
    "        torch.save(state, os.path.join(filename, 'modelA_best.pt'))\n",
    "\n",
    "        state = {\n",
    "            'model': net_B.state_dict(),\n",
    "            'optimizer': net_B_optimizer.state_dict()\n",
    "        }\n",
    "        torch.save(state, os.path.join(filename, 'modelB_best.pt'))\n",
    "\n",
    "        best_eval_cer = eval_cer   \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
