{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from datetime import datetime\n",
    "from utils_local import *\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "char2index = dict()\n",
    "index2char = dict()\n",
    "SOS_token = 0\n",
    "EOS_token = 0\n",
    "PAD_token = 0\n",
    "\n",
    "DATASET_PATH = 'D:/nsml-dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "num_thread = 4\n",
    "num_mels = 160\n",
    "num_hidden_enc = 1024\n",
    "num_hidden_dec = 512\n",
    "num_hidden_seq = 1024\n",
    "num_layers = 4\n",
    "lr_1 = 1e-5\n",
    "lr_2 = 1e-5\n",
    "train_ratio = .7\n",
    "nsc_in_ms = 40\n",
    "loss_lim = 0.03\n",
    "max_epochs = 100\n",
    "ref_repeat = 1\n",
    "\n",
    "filename = './model_saved/nsml_local_4_layer_residual'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "char2index, index2char = load_label_local(os.path.join(DATASET_PATH, 'hackathon.labels'))\n",
    "SOS_token = char2index['<s>']  # '<sos>' or '<s>'\n",
    "EOS_token = char2index['</s>']  # '<eos>' or '</s>'\n",
    "PAD_token = char2index['_']  # '-' or '_'\n",
    "\n",
    "unicode_jamo_list = My_Unicode_Jamo_v2()\n",
    "\n",
    "tokenizer = Tokenizer(unicode_jamo_list)\n",
    "jamo_tokens = tokenizer.word2num(unicode_jamo_list)\n",
    " \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mel2SeqNet_General_Residual(\n",
      "  (encoder): Encoder_General_Residual(\n",
      "    (fc): Linear(in_features=160, out_features=1024, bias=True)\n",
      "    (relu): ReLU()\n",
      "    (dropout): Dropout(p=0.2, inplace=False)\n",
      "    (gru_layers): ModuleList(\n",
      "      (0): Residual_GRU(\n",
      "        (gru): GRU(1024, 512, batch_first=True, bidirectional=True)\n",
      "      )\n",
      "      (1): Residual_GRU(\n",
      "        (gru): GRU(1024, 512, batch_first=True, bidirectional=True)\n",
      "      )\n",
      "      (2): Residual_GRU(\n",
      "        (gru): GRU(1024, 512, batch_first=True, bidirectional=True)\n",
      "      )\n",
      "      (3): Residual_GRU(\n",
      "        (gru): GRU(1024, 512, batch_first=True, bidirectional=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): CTC_Decoder_General_Residual(\n",
      "    (fc_embed): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    (relu_embed): ReLU()\n",
      "    (dropout_embed): Dropout(p=0.2, inplace=False)\n",
      "    (gru_layers): ModuleList(\n",
      "      (0): GRU(1024, 512, batch_first=True)\n",
      "      (1): Residual_GRU(\n",
      "        (gru): GRU(512, 512, batch_first=True)\n",
      "      )\n",
      "      (2): Residual_GRU(\n",
      "        (gru): GRU(512, 512, batch_first=True)\n",
      "      )\n",
      "      (3): Residual_GRU(\n",
      "        (gru): GRU(512, 512, batch_first=True)\n",
      "      )\n",
      "    )\n",
      "    (fc): Linear(in_features=512, out_features=76, bias=True)\n",
      "    (log_softmax): LogSoftmax()\n",
      "  )\n",
      ")\n",
      "Seq2SeqNet_v2(\n",
      "  (embedding_layer): Embedding(76, 1024)\n",
      "  (embedding_layer_2): Embedding(820, 1024)\n",
      "  (encoder): EncoderRNN(\n",
      "    (gru): GRU(1024, 512, bidirectional=True)\n",
      "  )\n",
      "  (decoder): AttnDecoderRNN(\n",
      "    (attn): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "    (attn_combine): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (gru): GRU(1024, 1024)\n",
      "    (out): Linear(in_features=1024, out_features=820, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = Mel2SeqNet_General_Residual(num_mels, num_hidden_enc, num_hidden_dec, len(unicode_jamo_list), num_layers, device)\n",
    "net_optimizer = optim.Adam(net.parameters(), lr=lr_1)\n",
    "ctc_loss = nn.CTCLoss().to(device)\n",
    "\n",
    "net_B = Seq2SeqNet_v2(num_hidden_seq, jamo_tokens, char2index, device)\n",
    "net_B_optimizer = optim.Adam(net_B.parameters(), lr=lr_2)\n",
    "net_B_criterion = nn.NLLLoss(reduction='none').to(device)\n",
    "\n",
    "print(net)\n",
    "print(net_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wav_paths len: 29805\n",
      "script_paths len: 29805\n",
      "korean_script_paths len: 29805\n",
      "Korean script 0: 예약하고 싶은데 어떻게 해야하나요?\n",
      "Korean script 0 length: 19\n",
      "Jamo script 0: 예약하고 싶은데 어떻게 해야하나요?\n",
      "Jamo script 0 length: 38\n"
     ]
    }
   ],
   "source": [
    "wav_paths, script_paths, korean_script_paths = get_paths(DATASET_PATH)\n",
    "\n",
    "print('wav_paths len: {}'.format(len(wav_paths)))\n",
    "print('script_paths len: {}'.format(len(script_paths)))\n",
    "print('korean_script_paths len: {}'.format(len(korean_script_paths)))\n",
    "\n",
    "korean_script_list, jamo_script_list = get_korean_and_jamo_list_v2_local(korean_script_paths)\n",
    "\n",
    "print('Korean script 0: {}'.format(korean_script_list[0]))\n",
    "print('Korean script 0 length: {}'.format(len(korean_script_list[0])))\n",
    "print('Jamo script 0: {}'.format(jamo_script_list[0]))\n",
    "print('Jamo script 0 length: {}'.format(len(jamo_script_list[0])))\n",
    "\n",
    "script_path_list = get_script_list(script_paths, SOS_token, EOS_token)\n",
    "\n",
    "ground_truth_list = [(tokenizer.word2num(['<s>'] + list(jamo_script_list[i]) + ['</s>'])) for i in\n",
    "                     range(len(jamo_script_list))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Ratio: 0.7\n",
      "Total:Train:Eval = 29805:20863:8942\n"
     ]
    }
   ],
   "source": [
    "print('Train Ratio: {}'.format(train_ratio))\n",
    "split_index = int(train_ratio * len(wav_paths))\n",
    "\n",
    "wav_path_list_train = wav_paths[:split_index]\n",
    "ground_truth_list_train = ground_truth_list[:split_index]\n",
    "korean_script_list_train = korean_script_list[:split_index]\n",
    "script_path_list_train = script_path_list[:split_index]\n",
    "\n",
    "wav_path_list_eval = wav_paths[split_index:]\n",
    "ground_truth_list_eval = ground_truth_list[split_index:]\n",
    "korean_script_list_eval = korean_script_list[split_index:]\n",
    "script_path_list_eval = script_path_list[split_index:]\n",
    "\n",
    "print('Total:Train:Eval = {}:{}:{}'.format(len(wav_paths), len(wav_path_list_train), len(wav_path_list_eval)))\n",
    "\n",
    "preloader_train = Threading_Batched_Preloader_v2_local(wav_path_list_train, ground_truth_list_train,\n",
    "                                                 script_path_list_train, korean_script_list_train, batch_size,\n",
    "                                                 num_mels, nsc_in_ms, is_train=True)\n",
    "\n",
    "preloader_eval = Threading_Batched_Preloader_v2_local(wav_path_list_eval, ground_truth_list_eval, script_path_list_eval,\n",
    "                                                korean_script_list_eval, batch_size, num_mels, nsc_in_ms,\n",
    "                                                is_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_loss = 1e10\n",
    "best_eval_cer = 1e10\n",
    "\n",
    "# load all target scripts for reducing disk i/o\n",
    "target_path = os.path.join(DATASET_PATH, 'train_label')\n",
    "load_targets(target_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train history loaded\n",
      "Evaluation history loaded\n",
      "No previous data on ./model_saved/nsml_local_4_layer_residual\n",
      "start\n",
      "10-06 23:42:25\n",
      "5216\n",
      "batch initialized\n",
      "Initialized Training Preloader\n",
      "Train: Count 173 | 혹시 아웃백에서 제휴하는 카드가 뭐가 있나요?  => 혹시 아웃백에서 제    카      요 ?\n",
      "Train: Count 173 | 혹시 아웃백에서 제휴하는 카드가 뭐가 있나요?  => <s>혹시 아웃백에서제핼하는 가드가 뭐가 있나요?</s> => 혹시 아웃백에서 제제는  가     요요? \n",
      "Train: Count 346 | 런치타임에 주차비 있나요?  => 런치타임에 주차비 있나요? \n",
      "Train: Count 346 | 런치타임에 주차비 있나요?  => <s>런치타임이 주차비 있나요?</s> => 런치타임이 주차비  있나요?  \n",
      "Train: Count 519 | 네 감사합니다  => 네 감사합니다 \n",
      "Train: Count 519 | 네 감사합니다  => <s>네 감사합니다.</s> => 네 감사합니다 \n",
      "Train: Count 692 | 오늘 몇 시에 오픈해서 몇 시에 닫나요?  => 오늘 몇 시에 오픈해서  시에  나나요??\n",
      "Train: Count 692 | 오늘 몇 시에 오픈해서 몇 시에 닫나요?  => <s>오늘 몇시에 오픈헤서 몇시에 닫나요?</s> => 오늘 몇시시에 오픈  시시에  나나요??\n",
      "Train: Count 865 | 특정 통신사 카드 할인이 되는지 궁금합니다  => 특정 통신사 다 할인  는 지지금금금합니다  \n",
      "Train: Count 865 | 특정 통신사 카드 할인이 되는지 궁금합니다  => <s>상동신서 카려하연이되는지 궁금합니ㅏㅏ.</s> => 동동신서 다려려  는는  궁금금금금 합   \n",
      "Train: Count 1038 | 점장님과 통화 가능할까요?  => 점심님과  과 가능할할할까요    \n",
      "Train: Count 1038 | 점장님과 통화 가능할까요?  => <s>전장림과 퐁화 가능할까요?</s> => 전지님과 포   가능할할할까요    \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-6a5be6a3ea81>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     99\u001b[0m                                                                          \u001b[0mbatched_num_script\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m                                                                          \u001b[0mbatched_num_script_loss_mask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m                                                                          net_B_optimizer, net_B_criterion)\n\u001b[0m\u001b[0;32m    102\u001b[0m                     \u001b[0mpred_string_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDecode_Lev_Prediction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlev_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex2char\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m                     \u001b[0mseq2seq_loss_list_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseq2seq_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Github\\korean-stt\\song\\utils_local.py\u001b[0m in \u001b[0;36mnet_train\u001b[1;34m(self, input_tensor, target_tensor, loss_mask, optimizer, criterion)\u001b[0m\n\u001b[0;32m   2140\u001b[0m             \u001b[0mdecoder_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecoder_output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2142\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2144\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    116\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m         \"\"\"\n\u001b[1;32m--> 118\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss_train_history = list()\n",
    "seq2seq_loss_train_history = list()\n",
    "seq2seq_loss_train_ref_history = list()\n",
    "\n",
    "loss_eval_history = list()\n",
    "seq2seq_loss_eval_history = list()\n",
    "seq2seq_loss_eval_ref_history = list()\n",
    "\n",
    "try:\n",
    "    loss_train_history = list(np.load(os.path.join(filename, 'loss_train_history.npy')))\n",
    "    seq2seq_loss_train_history = list(np.load(os.path.join(filename, 'seq2seq_loss_train_history.npy')))\n",
    "    seq2seq_loss_train_ref_history = list(np.load(os.path.join(filename, 'loss_train_history.npy')))\n",
    "\n",
    "    print(\"Train history loaded\")\n",
    "    \n",
    "    loss_eval_history = list(np.load(os.path.join(filename, 'loss_eval_history.npy')))\n",
    "    seq2seq_loss_eval_history = list(np.load(os.path.join(filename, 'seq2seq_loss_eval_history.npy')))\n",
    "    seq2seq_loss_eval_ref_history = list(np.load(os.path.join(filename, 'seq2seq_loss_eval_ref_history.npy')))\n",
    "\n",
    "    print(\"Evaluation history loaded\")\n",
    "    \n",
    "    state = torch.load(os.path.join(filename, 'modelA.pt'))\n",
    "    net.load_state_dict(state['model'])\n",
    "    net_optimizer.load_state_dict(state['optimizer'])\n",
    "    \n",
    "    print('Model A loaded')\n",
    "\n",
    "    state = torch.load(os.path.join(filename, 'modelB.pt'))\n",
    "    net_B.load_state_dict(state['model'])\n",
    "    net_B_optimizer.load_state_dict(state['optimizer'])\n",
    "    \n",
    "    print('Model B loaded')\n",
    "    \n",
    "    for g in net_optimizer.param_groups:\n",
    "        g['lr'] = lr_1\n",
    "        print('Learning rate of the net: {}'.format(g['lr']))\n",
    "\n",
    "    for g in net_B_optimizer.param_groups:\n",
    "        g['lr'] = lr_2\n",
    "        print('Learning rate of the net B: {}'.format(g['lr']))\n",
    "    \n",
    "    print(\"Loaded from {}\".format(filename))\n",
    "    \n",
    "except:\n",
    "    print(\"No previous data on {}\".format(filename))\n",
    "\n",
    "print('start')\n",
    "\n",
    "train_begin = time.time()\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "\n",
    "    print((datetime.now().strftime('%m-%d %H:%M:%S')))\n",
    "\n",
    "    net.train()\n",
    "    net_B.train()\n",
    "\n",
    "    preloader_train.initialize_batch(num_thread)\n",
    "    loss_list_train = list()\n",
    "    seq2seq_loss_list_train = list()\n",
    "    seq2seq_loss_list_train_ref = list()\n",
    "\n",
    "    print(\"Initialized Training Preloader\")\n",
    "    count = 0\n",
    "\n",
    "    total_dist = 0\n",
    "    total_length = 1\n",
    "    total_dist_ref = 0\n",
    "    total_length_ref = 1\n",
    "\n",
    "    while not preloader_train.end_flag:\n",
    "        batch = preloader_train.get_batch()\n",
    "        if batch is not None:\n",
    "            tensor_input, ground_truth, loss_mask, length_list, batched_num_script, batched_num_script_loss_mask = batch\n",
    "            pred_tensor, loss = train(net, net_optimizer, ctc_loss, tensor_input.to(device),\n",
    "                                      ground_truth.to(device), length_list.to(device), device)\n",
    "            loss_list_train.append(loss)\n",
    "            jamo_result = Decode_Prediction_No_Filtering(pred_tensor, tokenizer)\n",
    "            true_string_list = Decode_Num_Script(batched_num_script.detach().cpu().numpy(), index2char)\n",
    "\n",
    "            for i in range(ref_repeat):\n",
    "                lev_input_ref = ground_truth\n",
    "\n",
    "                lev_pred_ref, attentions_ref, seq2seq_loss_ref = net_B.net_train(lev_input_ref.to(device),\n",
    "                                                                                 batched_num_script.to(device),\n",
    "                                                                                 batched_num_script_loss_mask.to(\n",
    "                                                                                     device),\n",
    "                                                                                 net_B_optimizer,\n",
    "                                                                                 net_B_criterion)\n",
    "\n",
    "                pred_string_list_ref = Decode_Lev_Prediction(lev_pred_ref, index2char)\n",
    "                seq2seq_loss_list_train_ref.append(seq2seq_loss_ref)\n",
    "                dist_ref, length_ref = char_distance_list(true_string_list, pred_string_list_ref)\n",
    "\n",
    "                pred_string_list = [None]\n",
    "\n",
    "                dist = 0\n",
    "                length = 0\n",
    "\n",
    "                if (loss < loss_lim):\n",
    "                    lev_input = Decode_CTC_Prediction_And_Batch(pred_tensor)\n",
    "                    lev_pred, attentions, seq2seq_loss = net_B.net_train(lev_input.to(device),\n",
    "                                                                         batched_num_script.to(device),\n",
    "                                                                         batched_num_script_loss_mask.to(device),\n",
    "                                                                         net_B_optimizer, net_B_criterion)\n",
    "                    pred_string_list = Decode_Lev_Prediction(lev_pred, index2char)\n",
    "                    seq2seq_loss_list_train.append(seq2seq_loss)\n",
    "                    dist, length = char_distance_list(true_string_list, pred_string_list)\n",
    "\n",
    "            total_dist_ref += dist_ref\n",
    "            total_length_ref += length_ref\n",
    "\n",
    "            total_dist += dist\n",
    "            total_length += length\n",
    "\n",
    "            count += 1\n",
    "\n",
    "            if count % (int(len(wav_path_list_train) / batch_size / 15)) == 0:\n",
    "                print(\"Train: Count {} | {} => {}\".format(count, true_string_list[0], pred_string_list_ref[0]))\n",
    "\n",
    "                print(\"Train: Count {} | {} => {} => {}\".format(count, true_string_list[0], jamo_result[0],\n",
    "                                                                      pred_string_list[0]))\n",
    "\n",
    "        else:\n",
    "            print(\"Training Batch is None\")\n",
    "\n",
    "    train_loss = np.mean(np.asarray(loss_list_train))\n",
    "    train_cer = np.mean(np.asarray(total_dist / total_length))\n",
    "    train_cer_ref = np.mean(np.asarray(total_dist_ref / total_length_ref))\n",
    "\n",
    "    print(\"Mean Train Loss: {}\".format(train_loss))\n",
    "    print(\"Total Train CER: {}\".format(train_cer))\n",
    "    print(\"Total Train Reference CER: {}\".format(train_cer_ref))\n",
    "\n",
    "    preloader_eval.initialize_batch(num_thread)\n",
    "    loss_list_eval = list()\n",
    "    seq2seq_loss_list_eval = list()\n",
    "    seq2seq_loss_list_eval_ref = list()\n",
    "\n",
    "    print(\"Initialized Evaluation Preloader\")\n",
    "\n",
    "    count = 0\n",
    "    total_dist = 0\n",
    "    total_length = 1\n",
    "    total_dist_ref = 0\n",
    "    total_length_ref = 1\n",
    "\n",
    "    net.eval()\n",
    "    net_B.eval()\n",
    "\n",
    "    while not preloader_eval.end_flag:\n",
    "        batch = preloader_eval.get_batch()\n",
    "        if batch is not None:\n",
    "            tensor_input, ground_truth, loss_mask, length_list, batched_num_script, batched_num_script_loss_mask = batch\n",
    "            pred_tensor, loss = evaluate(net, ctc_loss, tensor_input.to(device), ground_truth.to(device),\n",
    "                                         length_list.to(device), device)\n",
    "            loss_list_eval.append(loss)\n",
    "\n",
    "            jamo_result = Decode_Prediction_No_Filtering(pred_tensor, tokenizer)\n",
    "\n",
    "            true_string_list = Decode_Num_Script(batched_num_script.detach().cpu().numpy(), index2char)\n",
    "\n",
    "            lev_input_ref = ground_truth\n",
    "            lev_pred_ref, attentions_ref, seq2seq_loss_ref = net_B.net_eval(lev_input_ref.to(device),\n",
    "                                                                            batched_num_script.to(device),\n",
    "                                                                            batched_num_script_loss_mask.to(device),\n",
    "                                                                            net_B_criterion)\n",
    "\n",
    "            pred_string_list_ref = Decode_Lev_Prediction(lev_pred_ref, index2char)\n",
    "            seq2seq_loss_list_train_ref.append(seq2seq_loss_ref)\n",
    "            dist_ref, length_ref = char_distance_list(true_string_list, pred_string_list_ref)\n",
    "\n",
    "            pred_string_list = [None]\n",
    "\n",
    "            dist = 0\n",
    "            length = 0\n",
    "\n",
    "            if (loss < loss_lim):\n",
    "                lev_input = Decode_CTC_Prediction_And_Batch(pred_tensor)\n",
    "                lev_pred, attentions, seq2seq_loss = net_B.net_eval(lev_input.to(device),\n",
    "                                                                    batched_num_script.to(device),\n",
    "                                                                    batched_num_script_loss_mask.to(device),\n",
    "                                                                    net_B_criterion)\n",
    "                pred_string_list = Decode_Lev_Prediction(lev_pred, index2char)\n",
    "                seq2seq_loss_list_train.append(seq2seq_loss)\n",
    "                dist, length = char_distance_list(true_string_list, pred_string_list)\n",
    "\n",
    "            total_dist_ref += dist_ref\n",
    "            total_length_ref += length_ref\n",
    "\n",
    "            total_dist += dist\n",
    "            total_length += length\n",
    "\n",
    "            count += 1\n",
    "\n",
    "            if count % (int(len(wav_path_list_eval) / batch_size / 15)) == 0:\n",
    "                print(\"Eval: Count {} | {} => {}\".format(count, true_string_list[0], pred_string_list_ref[0]))\n",
    "\n",
    "                print(\"Eval: Count {} | {} => {} => {}\".format(count, true_string_list[0], jamo_result[0],\n",
    "                                                                     pred_string_list[0]))\n",
    "\n",
    "        else:\n",
    "            print(\"Training Batch is None\")\n",
    "\n",
    "    eval_cer = total_dist / total_length\n",
    "    eval_cer_ref = total_dist_ref / total_length_ref\n",
    "    eval_loss = np.mean(np.asarray(loss_list_eval))\n",
    "\n",
    "    print(\"Mean Evaluation Loss: {}\".format(eval_loss))\n",
    "    print(\"Total Evaluation CER: {}\".format(eval_cer))\n",
    "    print(\"Total Evaluation Reference CER: {}\".format(eval_cer_ref))\n",
    "    \n",
    "    loss_train_history.append(train_loss)\n",
    "    seq2seq_loss_train_history.append(train_cer)\n",
    "    seq2seq_loss_train_ref_history.append(train_cer_ref)\n",
    "\n",
    "    loss_eval_history.append(eval_loss)\n",
    "    seq2seq_loss_eval_history.append(eval_cer)\n",
    "    seq2seq_loss_eval_ref_history.append(eval_cer_ref)\n",
    "    \n",
    "    f, (ax1, ax2, ax3) = plt.subplots(1, 3)\n",
    "    ax1.plot(loss_train_history)\n",
    "    ax1.plot(loss_eval_history)\n",
    "    \n",
    "    ax2.plot(seq2seq_loss_train_history)\n",
    "    ax2.plot(seq2seq_loss_eval_history)\n",
    "    \n",
    "    ax3.plot(seq2seq_loss_train_ref_history)\n",
    "    ax3.plot(seq2seq_loss_eval_ref_history)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    if not os.path.exists(filename):\n",
    "        os.makedirs(filename)\n",
    "\n",
    "    np.save(os.path.join(filename, 'loss_train_history.npy'), loss_train_history)\n",
    "    np.save(os.path.join(filename, 'seq2seq_loss_train_history.npy'), seq2seq_loss_train_history)\n",
    "    np.save(os.path.join(filename, 'loss_train_history.npy'), seq2seq_loss_train_ref_history)\n",
    "\n",
    "    np.save(os.path.join(filename, 'loss_eval_history.npy'), loss_eval_history)\n",
    "    np.save(os.path.join(filename, 'seq2seq_loss_eval_history.npy'), seq2seq_loss_eval_history)\n",
    "    np.save(os.path.join(filename, 'seq2seq_loss_eval_ref_history.npy'), seq2seq_loss_eval_ref_history)\n",
    "\n",
    "    state = {\n",
    "        'model': net.state_dict(),\n",
    "        'optimizer': net_optimizer.state_dict()\n",
    "    }\n",
    "    torch.save(state, os.path.join(filename, 'modelA.pt'))\n",
    "\n",
    "    state = {\n",
    "        'model': net_B.state_dict(),\n",
    "        'optimizer': net_B_optimizer.state_dict()\n",
    "    }\n",
    "    torch.save(state, os.path.join(filename, 'modelB.pt'))\n",
    "\n",
    "    best_model = (eval_cer < best_eval_cer)\n",
    "    \n",
    "    if best_model:\n",
    "        state = {\n",
    "            'model': net.state_dict(),\n",
    "            'optimizer': net_optimizer.state_dict()\n",
    "        }\n",
    "        torch.save(state, os.path.join(filename, 'modelA_best.pt'))\n",
    "\n",
    "        state = {\n",
    "            'model': net_B.state_dict(),\n",
    "            'optimizer': net_B_optimizer.state_dict()\n",
    "        }\n",
    "        torch.save(state, os.path.join(filename, 'modelB_best.pt'))\n",
    "\n",
    "        best_eval_cer = eval_cer   \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
