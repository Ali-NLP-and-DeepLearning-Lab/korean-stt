{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import IPython.display as ipd\n",
    "import re\n",
    "import jamotools\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import scipy as sp\n",
    "\n",
    "import random\n",
    "import copy\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'D:/aihub/ETRI_metadata.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = np.load(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_mels = 80\n",
    "fs = 16000\n",
    "frame_length_ms = 50\n",
    "frame_shift_ms = 25\n",
    "nsc = int(fs * frame_length_ms / 1000)\n",
    "nov = nsc - int(fs * frame_shift_ms / 1000)\n",
    "nhop = int(fs * frame_shift_ms / 1000)\n",
    "eps = 1e-8\n",
    "db_ref = 160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "620799\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea39481c643849debfb142abf7c1252b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(len(metadata))\n",
    "\n",
    "mel_path_list = list()\n",
    "script_list = list()\n",
    "\n",
    "for i, data in tqdm(enumerate(metadata)):\n",
    "    pcm_path = data[0]\n",
    "    txt_data = data[1]\n",
    "    \n",
    "    mel_dir = '\\\\'.join(pcm_path.replace('aihub\\\\', 'aihub\\\\mel\\\\').split('\\\\')[:-1])\n",
    "    mel_path = pcm_path.replace('aihub\\\\', 'aihub\\\\mel\\\\').replace('.pcm', '.npy')\n",
    "    \n",
    "    mel_path_list.append(mel_path)\n",
    "    script_list.append(txt_data)\n",
    "#     if not os.path.exists(mel_dir):\n",
    "#         os.makedirs(mel_dir)\n",
    "    \n",
    "#     if not os.path.isfile(mel_path):\n",
    "        \n",
    "#         try:\n",
    "#             with open(pcm_path, 'rb') as pcm_file:\n",
    "#                 pcm_data = np.fromfile(pcm_file, dtype=np.int16)\n",
    "#                 y = pcm_data / 2 ** 14\n",
    "\n",
    "#                 f, t, Zxx = sp.signal.stft(y, fs=fs, nperseg=nsc, noverlap=nov)\n",
    "\n",
    "#                 Sxx = np.abs(Zxx)\n",
    "\n",
    "#                 mel_filters = librosa.filters.mel(sr=fs, n_fft=nsc, n_mels=n_mels)\n",
    "#                 mel_specgram = np.matmul(mel_filters, Sxx)\n",
    "\n",
    "#                 log_mel_specgram = 20 * np.log10(np.maximum(mel_specgram, eps))\n",
    "#                 norm_log_mel_specgram = (log_mel_specgram + db_ref) / db_ref\n",
    "\n",
    "#                 np.save(mel_path, norm_log_mel_specgram)\n",
    "\n",
    "# #             plt.figure(figsize=(10,10))\n",
    "# #             plt.imshow(norm_log_mel_specgram, origin='lower')\n",
    "# #             plt.colorbar()\n",
    "# #             plt.show()\n",
    "\n",
    "#         except:\n",
    "#             print(\"Error found in {}\".format(pcm_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "korean = re.compile(u'[^, .?!\\u1100-\\u115e\\u1161-\\u11A7\\u11a8-\\u11ff]+') \n",
    "\n",
    "no_korean = np.asarray([len(korean.findall(script)) for script in script_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_idxs = np.where(no_korean == 0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_path_list = [mel_path_list[idx] for idx in valid_idxs]\n",
    "script_list = [script_list[idx] for idx in valid_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create true sentence list, <eos> is added to the end\n",
    "ground_truth_list = [(tokenizer.word2num(list(script_list[i]) + ['<eos>'])) for i in range(len(script_list))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "613636\n",
      "613636\n",
      "490908\n",
      "490908\n",
      "122728\n"
     ]
    }
   ],
   "source": [
    "print(len(mel_path_list))\n",
    "\n",
    "print(len(ground_truth_list))\n",
    "\n",
    "# 80% of the data will be used as train\n",
    "split_index = int(0.8 * len(mel_path_list))\n",
    "\n",
    "# Split index is the number stands for 80%\n",
    "print(split_index)\n",
    "\n",
    "# Split index is the number stands for 80%\n",
    "mel_path_list_train = mel_path_list[:split_index]\n",
    "ground_truth_list_train = ground_truth_list[:split_index]\n",
    "\n",
    "print(len(mel_path_list_train))\n",
    "\n",
    "mel_path_list_eval = mel_path_list[split_index:]\n",
    "ground_truth_list_eval = ground_truth_list[split_index:]\n",
    "\n",
    "print(len(mel_path_list_eval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['-', ' ', '!', ',', '.', '<eos>', '<sos>', '?', 'ᄀ', 'ᄁ', 'ᄂ', 'ᄃ', 'ᄄ', 'ᄅ', 'ᄆ', 'ᄇ', 'ᄈ', 'ᄉ', 'ᄊ', 'ᄋ', 'ᄌ', 'ᄍ', 'ᄎ', 'ᄏ', 'ᄐ', 'ᄑ', 'ᄒ', 'ᅡ', 'ᅢ', 'ᅣ', 'ᅤ', 'ᅥ', 'ᅦ', 'ᅧ', 'ᅨ', 'ᅩ', 'ᅪ', 'ᅫ', 'ᅬ', 'ᅭ', 'ᅮ', 'ᅯ', 'ᅰ', 'ᅱ', 'ᅲ', 'ᅳ', 'ᅴ', 'ᅵ', 'ᆨ', 'ᆩ', 'ᆪ', 'ᆫ', 'ᆬ', 'ᆭ', 'ᆮ', 'ᆯ', 'ᆰ', 'ᆱ', 'ᆲ', 'ᆳ', 'ᆴ', 'ᆵ', 'ᆶ', 'ᆷ', 'ᆸ', 'ᆹ', 'ᆺ', 'ᆻ', 'ᆼ', 'ᆽ', 'ᆾ', 'ᆿ', 'ᇀ', 'ᇁ', 'ᇂ']\n",
      "75\n"
     ]
    }
   ],
   "source": [
    "unicode_jamo_list = list() # List of total hanguel jamos + [' ', ',', '<eos>', 'sos', '!', '?', '-']\n",
    "\n",
    "# 초성\n",
    "for unicode in range(0x1100, 0x1113):\n",
    "    unicode_jamo_list.append(chr(unicode)) # chr: Change hexadecimal to unicode\n",
    "    \n",
    "# 중성\n",
    "for unicode in range(0x1161, 0x1176):\n",
    "    unicode_jamo_list.append(chr(unicode))\n",
    "    \n",
    "# 종성\n",
    "for unicode in range(0x11A8, 0x11C3):\n",
    "    unicode_jamo_list.append(chr(unicode))\n",
    "    \n",
    "unicode_jamo_list += [' ', '!', ',', '.', '?', '<sos>', '<eos>']\n",
    "    \n",
    "\n",
    "unicode_jamo_list.sort()\n",
    "\n",
    "# '-' symbol represents \"blank\" in CTC loss system, \"blank\" has to be the index 0\n",
    "unicode_jamo_list = ['-'] + unicode_jamo_list\n",
    "\n",
    "# Check the symbols\n",
    "print(unicode_jamo_list)\n",
    "\n",
    "# Check the total number of symbols\n",
    "print(len(unicode_jamo_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer maps numbers to characters, 8 -> 'ㄱ', 10 -> 'ㄴ'\n",
    "class Tokenizer():\n",
    "    def __init__(self, vocabs):\n",
    "        self.vocabs = vocabs\n",
    "        \n",
    "    def word2num(self, sentence):\n",
    "        tokens = list()\n",
    "        for char in sentence:\n",
    "            tokens.append(self.vocabs.index(char))    \n",
    "        return tokens\n",
    "        \n",
    "    def word2vec(self, sentence):\n",
    "        vectors = np.zeros((len(sentence), len(self.vocabs)))\n",
    "        for i, char in enumerate(sentence):\n",
    "            vectors[i, self.vocabs.index(char)] = 1   \n",
    "        return vectors\n",
    "    \n",
    "    def num2word(self, num):\n",
    "        output = list()\n",
    "        for i in num:\n",
    "            output.append(self.vocabs[i])\n",
    "        return output\n",
    "    \n",
    "    def num2vec(self, numbers):\n",
    "        vectors = np.zeros((len(numbers), len(self.vocabs)))\n",
    "        for i, num in enumerate(numbers):\n",
    "            vectors[i, num] = 1   \n",
    "        return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tokenizer, put the whole symbols in and check the output \n",
    "tokenizer = Tokenizer(unicode_jamo_list)\n",
    "jamo_tokens = tokenizer.word2num(unicode_jamo_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, D_in, H):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.fc = torch.nn.Linear(D_in, H)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        \n",
    "        self.gru = nn.GRU(H, int(H/2), bidirectional=True, batch_first=True)\n",
    "\n",
    "    def forward(self, input_tensor):\n",
    "         \n",
    "        # (B, T, F)\n",
    "        output_tensor = self.fc(input_tensor)\n",
    "        output_tensor = self.relu(output_tensor)\n",
    "        output_tensor = self.dropout(output_tensor)\n",
    "                \n",
    "        \n",
    "        # (B, T, H)\n",
    "        \n",
    "        output_tensor, _ = self.gru(output_tensor)\n",
    "        \n",
    "        # (B, T, 2 * H/2)\n",
    "        \n",
    "        return output_tensor\n",
    "    \n",
    "class CTC_Decoder(nn.Module):\n",
    "    def __init__(self, H, D_out):\n",
    "        super(CTC_Decoder, self).__init__()\n",
    "        \n",
    "        self.fc_embed = nn.Linear(H, H)\n",
    "        self.relu_embed = torch.nn.ReLU()\n",
    "        self.dropout_embed = nn.Dropout(p=0.5)\n",
    "        \n",
    "        self.gru = nn.GRU(H, D_out, batch_first=True)\n",
    "        \n",
    "        self.fc = nn.Linear(D_out, 75)\n",
    "        self.log_softmax = nn.LogSoftmax(dim=2)\n",
    "\n",
    "    def forward(self, input_tensor):\n",
    "\n",
    "        # (B, T, 2 * H/2)\n",
    "        output_tensor = self.fc_embed(input_tensor)\n",
    "        output_tensor = self.relu_embed(output_tensor)\n",
    "        output_tensor = self.dropout_embed(output_tensor)\n",
    "        \n",
    "        # (B, T, H)\n",
    "        output_tensor,_ = self.gru(input_tensor)\n",
    "        \n",
    "        # (B, T, H)\n",
    "        output_tensor = self.fc(output_tensor)\n",
    "        \n",
    "        \n",
    "        # (B, T, 75)\n",
    "        prediction_tensor = self.log_softmax(output_tensor)\n",
    "\n",
    "        return prediction_tensor\n",
    "\n",
    "class Mel2SeqNet():\n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        super(Mel2SeqNet, self).__init__()\n",
    "        \n",
    "        # Use GPU if GPU is available \n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "        self.encoder = Encoder(D_in, H).to(device)\n",
    "        self.decoder = CTC_Decoder(H, D_out).to(device)\n",
    "\n",
    "        self.encoder_optimizer = optim.Adam(self.encoder.parameters(), lr=0.001)\n",
    "        self.decoder_optimizer = optim.Adam(self.decoder.parameters(), lr=0.001)\n",
    "\n",
    "        self.ctc_loss = nn.CTCLoss().to(device)\n",
    "        \n",
    "        # Initialize weights with random uniform numbers with range\n",
    "        for param in self.encoder.parameters():\n",
    "            param.data.uniform_(-0.1, 0.1)\n",
    "        for param in self.decoder.parameters():\n",
    "            param.data.uniform_(-0.1, 0.1)\n",
    "\n",
    "    def train(self, input_tensor, ground_truth, loss_mask, target_lengths):\n",
    "        \n",
    "        # Shape of the input tensor (B, T, F)\n",
    "        # B: Number of a batch (8, 16, or 64 ...)\n",
    "        # T: Temporal length of an input\n",
    "        # F: Number of frequency band, 80\n",
    "        \n",
    "        batch_size = input_tensor.shape[0]\n",
    "\n",
    "        self.encoder_optimizer.zero_grad()\n",
    "        self.decoder_optimizer.zero_grad()\n",
    "\n",
    "        # (B, T, F) -> (B, T, H)\n",
    "        encoded_tensor = self.encoder(input_tensor)\n",
    "\n",
    "        # (B, T, H) -> (B, T, 75)\n",
    "        pred_tensor = self.decoder(encoded_tensor)\n",
    "            \n",
    "        # Cast true sentence as Long data type, since CTC loss takes long tensor only\n",
    "        # Shape (B, S)\n",
    "        # S: Max length among true sentences \n",
    "        truth = ground_truth\n",
    "        truth = truth.type(torch.cuda.LongTensor)\n",
    "        \n",
    "        # CTC loss function takes tensor of the form (T, B, 75)\n",
    "        # Permute function changes axes of a tensor T <-> B\n",
    "        pred_tensor = pred_tensor.permute(1, 0, 2)\n",
    "        \n",
    "        # CTC loss need to know the lenght of the true sentence\n",
    "        input_lengths = torch.full(size=(batch_size,), fill_value=pred_tensor.shape[0], dtype=torch.long)\n",
    "        \n",
    "        # Calculate CTC Loss\n",
    "        loss = self.ctc_loss(pred_tensor, truth, input_lengths, target_lengths)\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss.backward()\n",
    "\n",
    "        # Update weights\n",
    "        self.encoder_optimizer.step()\n",
    "        self.decoder_optimizer.step()\n",
    "        \n",
    "        # Return loss divided by true length because loss is sum of the character losses\n",
    "        \n",
    "        return pred_tensor, loss.item() / ground_truth.shape[1]\n",
    "    \n",
    "    \n",
    "    def test(self, input_tensor, ground_truth, loss_mask, target_lengths):\n",
    "        \n",
    "        # Shape of the input tensor (B, T, F)\n",
    "        # B: Number of a batch (8, 16, or 64 ...)\n",
    "        # T: Temporal length of an input\n",
    "        # F: Number of frequency band, 80\n",
    "        \n",
    "        batch_size = input_tensor.shape[0]\n",
    "\n",
    "        # (B, T, F) -> (B, T, H)\n",
    "        encoded_tensor = self.encoder(input_tensor)\n",
    "\n",
    "        # (B, T, H) -> (B, T, 75)\n",
    "        pred_tensor = self.decoder(encoded_tensor)\n",
    "            \n",
    "        # Cast true sentence as Long data type, since CTC loss takes long tensor only\n",
    "        # Shape (B, S)\n",
    "        # S: Max length among true sentences \n",
    "        truth = ground_truth\n",
    "        truth = truth.type(torch.cuda.LongTensor)\n",
    "        \n",
    "        # CTC loss function takes tensor of the form (T, B, 75)\n",
    "        # Permute function changes axes of a tensor T <-> B\n",
    "        pred_tensor = pred_tensor.permute(1, 0, 2)\n",
    "        \n",
    "        # CTC loss need to know the lenght of the true sentence\n",
    "        input_lengths = torch.full(size=(batch_size,), fill_value=pred_tensor.shape[0], dtype=torch.long)\n",
    "        \n",
    "        # Calculate CTC Loss\n",
    "        loss = self.ctc_loss(pred_tensor, truth, input_lengths, target_lengths)\n",
    "        \n",
    "        # Return loss divided by true length because loss is sum of the character losses\n",
    "        \n",
    "        return pred_tensor, loss.item() / ground_truth.shape[1]\n",
    "    \n",
    "    def save(self, check_point_name):\n",
    "        torch.save({\n",
    "            'encoder_state_dict': self.encoder.state_dict(),\n",
    "            'decoder_state_dict': self.decoder.state_dict(),\n",
    "            'encoder_optimizer_state_dict': self.encoder_optimizer.state_dict(),\n",
    "            'decoder_optimizer_state_dict': self.decoder_optimizer.state_dict(),\n",
    "            }, check_point_name)\n",
    "    \n",
    "    def load(self, check_point_name):\n",
    "        checkpoint = torch.load(check_point_name)\n",
    "        self.encoder.load_state_dict(checkpoint['encoder_state_dict'])\n",
    "        self.decoder.load_state_dict(checkpoint['decoder_state_dict'])\n",
    "        self.encoder_optimizer.load_state_dict(checkpoint['encoder_optimizer_state_dict'])\n",
    "        self.decoder_optimizer.load_state_dict(checkpoint['decoder_optimizer_state_dict'])\n",
    "        \n",
    "    def set_mode(self, mode):\n",
    "        \n",
    "        # Must call .train() after loading if you want to train again\n",
    "        if mode == 'train':\n",
    "            self.encoder.train()\n",
    "            self.decoder.train()\n",
    "        \n",
    "        # Must call .eval() after loading if you do not want to use dropouts\n",
    "        elif mode == 'eval':\n",
    "            self.encoder.eval()\n",
    "            self.decoder.eval()\n",
    "            \n",
    "        else:\n",
    "            print(\"Invalid mode string: {}\".format(mode))\n",
    "    \n",
    "# net = Mel2SeqNet(80, 512, 256)\n",
    "\n",
    "net = Mel2SeqNet(80, 1024, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")      \n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Batched_Preloader():\n",
    "    def __init__(self, mel_path_list, ground_truth_list, batch_size):\n",
    "        super(Batched_Preloader).__init__()\n",
    "        self.mel_path_list = mel_path_list\n",
    "        self.total_num_input = len(mel_path_list)\n",
    "        self.tensor_input_list = [None] * self.total_num_input\n",
    "        self.ground_truth_list = ground_truth_list\n",
    "        self.sentence_length_list = np.asarray(list(map(len, ground_truth_list)))\n",
    "#         self.shuffle_step = 4\n",
    "        self.shuffle_step = 12\n",
    "        self.loading_sequence = None\n",
    "        self.end_flag = True\n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "    # Load the spectrogram image from the disk\n",
    "    def load(self, i):\n",
    "        norm_log_mel_specgram = np.load(self.mel_path_list[i])\n",
    "        \n",
    "        # (F, T) -> (T, F)\n",
    "        input_spectrogram = norm_log_mel_specgram.T\n",
    "        \n",
    "        # (T, F) -> (1, T, F)\n",
    "        # Inserted the first axis to make stacking easier\n",
    "        tensor_input = torch.tensor(input_spectrogram).view(1, input_spectrogram.shape[0], input_spectrogram.shape[1])\n",
    "        self.tensor_input_list[i] = tensor_input\n",
    "    \n",
    "    # Check if tensor number i is already loaded, if not load and returns the image\n",
    "    def get(self, i):\n",
    "        if type(self.tensor_input_list[i]) == type(None):\n",
    "            self.load(i)\n",
    "        return self.tensor_input_list[i]  \n",
    "    \n",
    "    # Try loading every images\n",
    "    def initialize_preloader(self):\n",
    "        for i in tqdm(range(self.total_num_input)):\n",
    "            self.load(i)\n",
    "        \n",
    "        return\n",
    "    \n",
    "    # Shuffle loading index and set end flag to false\n",
    "    def initialize_batch(self):\n",
    "        loading_sequence = np.argsort(self.sentence_length_list)\n",
    "        bundle = np.stack([self.sentence_length_list[loading_sequence], loading_sequence])\n",
    "        \n",
    "        for seq_len in range(self.shuffle_step, np.max(self.sentence_length_list), self.shuffle_step):\n",
    "            idxs = np.where((bundle[0, :] > seq_len) & (bundle[0, :] <= seq_len + self.shuffle_step))[0]\n",
    "            idxs_origin = copy.deepcopy(idxs)\n",
    "            random.shuffle(idxs)\n",
    "            bundle[:, idxs_origin] = bundle[:, idxs]\n",
    "            \n",
    "        loading_sequence = bundle[1, :]\n",
    "        \n",
    "        self.loading_sequence = loading_sequence\n",
    "        self.current_loading_index = 0\n",
    "        self.end_flag = False\n",
    "        \n",
    "        return\n",
    "    \n",
    "    # Get batch\n",
    "    def get_batch(self):\n",
    "        \n",
    "        tensor_list = list()\n",
    "        ground_truth_list = list()\n",
    "        tensor_size_list = list()\n",
    "        ground_truth_size_list = list()\n",
    "        \n",
    "        count = 0\n",
    "        max_seq_len = 0\n",
    "        max_sen_len = 0\n",
    "        \n",
    "        for i in range(self.batch_size):\n",
    "            \n",
    "            # If there is no more file, break and set end_flag true\n",
    "            if self.current_loading_index >= self.total_num_input:\n",
    "                self.end_flag = True\n",
    "                break\n",
    "            \n",
    "            tensor = self.get(self.loading_sequence[self.current_loading_index])\n",
    "            tensor_list.append(tensor)\n",
    "            tensor_size_list.append(tensor.shape[1])\n",
    "            \n",
    "            ground_truth = self.ground_truth_list[self.loading_sequence[self.current_loading_index]]\n",
    "            ground_truth_list.append(ground_truth)\n",
    "            ground_truth_size_list.append(len(ground_truth))\n",
    "            \n",
    "            \n",
    "            if (tensor.shape[1] > max_seq_len):\n",
    "                max_seq_len = tensor.shape[1]\n",
    "            if (len(ground_truth) > max_sen_len):\n",
    "                max_sen_len = len(ground_truth)  \n",
    "            \n",
    "            self.current_loading_index += 1\n",
    "            count += 1\n",
    "            \n",
    "        batched_tensor = torch.zeros(count, max_seq_len + 5, n_mels)\n",
    "        batched_ground_truth = torch.zeros(count, max_sen_len)\n",
    "        batched_loss_mask = torch.zeros(count, max_sen_len)\n",
    "        ground_truth_size_list = torch.tensor(np.asarray(ground_truth_size_list), dtype=torch.long)\n",
    "        \n",
    "        for order in range(count):\n",
    "            \n",
    "            target = tensor_list[order]\n",
    "        \n",
    "            pad_random = np.random.randint(0, 5)\n",
    "            \n",
    "            # Time shift, add zeros in front of an image\n",
    "            if pad_random > 0:\n",
    "                offset = torch.zeros(target.shape[0], pad_random, target.shape[2]).double()\n",
    "                target = torch.cat((offset, target.double()), 1)\n",
    "            \n",
    "            # Add random noise\n",
    "            target = target + torch.tensor((np.random.random(target.shape) - 0.5) / 20)\n",
    "        \n",
    "            # Value less than 0 or more than 1 is clamped to 0 and 1\n",
    "            target = torch.clamp(target, min=0.0, max=1.0)\n",
    "            \n",
    "            batched_tensor[order, :tensor_size_list[order] + pad_random, :] = target\n",
    "            batched_ground_truth[order, :ground_truth_size_list[order]] = torch.tensor(ground_truth_list[order])\n",
    "            \n",
    "            # You do not need to know what loss mask is \n",
    "            batched_loss_mask[order, :ground_truth_size_list[order]] = torch.ones(ground_truth_size_list[order])\n",
    "        \n",
    "        return batched_tensor, batched_ground_truth, batched_loss_mask, ground_truth_size_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "preloader_eval = Batched_Preloader(mel_path_list_eval, ground_truth_list_eval, batch_size)\n",
    "# preloader_eval.initialize_preloader()\n",
    "\n",
    "preloader_train = Batched_Preloader(mel_path_list_train, ground_truth_list_train, batch_size)\n",
    "# preloader_train.initialize_preloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that interprets the CTC prediction result\n",
    "\n",
    "def Decode_CTC_Prediction(prediction):\n",
    "    CTC_pred = prediction.detach().cpu().numpy()\n",
    "    result = list()\n",
    "    last_elem = 0\n",
    "    for i, elem in enumerate(CTC_pred):\n",
    "        if elem != last_elem and elem != 0:\n",
    "            result.append(elem)\n",
    "        \n",
    "        last_elem = elem\n",
    "        \n",
    "    \n",
    "    result = np.asarray(result)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Failed\n"
     ]
    }
   ],
   "source": [
    "# 'keyword' determines the save keyword\n",
    "# Change this keyword if you want to start training a new model\n",
    "keyword = 'ETRI'\n",
    "\n",
    "# List of loss values\n",
    "loss_history_train = list()\n",
    "loss_history_eval = list()\n",
    "\n",
    "try:\n",
    "    loss_history_train = np.load('model_saved/loss_history_train_{}.npy'.format(keyword)).tolist()\n",
    "    loss_history_eval = np.load('model_saved/loss_history_eval_{}.npy'.format(keyword)).tolist()\n",
    "except:\n",
    "    print(\"Loading Failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Error\n",
      "09-13 04:33:59\n",
      "09-13 04:34:11\n",
      "3200/490908\n",
      "09-13 04:34:23\n",
      "6400/490908\n",
      "09-13 04:35:26\n",
      "9600/490908\n",
      "09-13 04:36:53\n",
      "12800/490908\n",
      "09-13 04:38:21\n",
      "16000/490908\n",
      "09-13 04:39:50\n",
      "19200/490908\n"
     ]
    }
   ],
   "source": [
    "EPOCH = 3 * 60 * 4\n",
    "    \n",
    "# Load model if model weights already exists\n",
    "try:\n",
    "    net.load('model_saved/{}'.format(keyword))\n",
    "except:\n",
    "    print(\"Loading Error\")\n",
    "    \n",
    "for epoch in range(EPOCH):\n",
    "    \n",
    "    print(datetime.now().strftime('%m-%d %H:%M:%S'))\n",
    "    \n",
    "    net.set_mode('train')\n",
    "    preloader_train.initialize_batch()\n",
    "    loss_list_train = list()\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    while preloader_train.end_flag == False:\n",
    "        tensor_input, ground_truth, loss_mask, length_list = preloader_train.get_batch()\n",
    "        pred_tensor, loss = net.train(tensor_input.to(device), ground_truth.to(device), loss_mask.to(device), length_list.to(device))\n",
    "        loss_list_train.append(loss)\n",
    "        \n",
    "        count += 1\n",
    "        \n",
    "        if (count % 100 == 0):\n",
    "            print(datetime.now().strftime('%m-%d %H:%M:%S'))\n",
    "            print('{}/{}'.format(count * batch_size, len(mel_path_list_train)))\n",
    "\n",
    "    print(datetime.now().strftime('%m-%d %H:%M:%S'))\n",
    "    print(\"Mean Train Loss: {}\".format(np.mean(np.asarray(loss_list_train))))\n",
    "    loss_history_train.append(np.mean(np.asarray(loss_list_train)))\n",
    "    \n",
    "    net.set_mode('eval')\n",
    "    preloader_eval.initialize_batch()\n",
    "    loss_list_eval = list()\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    while preloader_eval.end_flag == False:\n",
    "        tensor_input, ground_truth_, loss_mask, length_list = preloader_eval.get_batch()\n",
    "        pred_tensor_, loss = net.test(tensor_input.to(device), ground_truth_.to(device), loss_mask.to(device), length_list.to(device))\n",
    "        loss_list_eval.append(loss)\n",
    "        \n",
    "        count += 1\n",
    "        \n",
    "        if (count % 100 == 0):\n",
    "            print(datetime.now().strftime('%m-%d %H:%M:%S'))\n",
    "            print('{}/{}'.format(count * batch_size, len(mel_path_list_eval)))\n",
    "\n",
    "\n",
    "    print(datetime.now().strftime('%m-%d %H:%M:%S'))\n",
    "    print(\"Mean Evaluation Loss: {}\".format(np.mean(np.asarray(loss_list_eval))))\n",
    "    loss_history_eval.append(np.mean(np.asarray(loss_list_eval)))\n",
    "    \n",
    "    \n",
    "    net.save('model_saved/{}'.format(keyword))\n",
    "    np.save('model_saved/loss_history_train_{}.npy'.format(keyword), loss_history_train)\n",
    "    np.save('model_saved/loss_history_eval_{}.npy'.format(keyword), loss_history_eval)\n",
    "    \n",
    "    \n",
    "#     if ((epoch != 0) and (epoch % 6 == 0)):\n",
    "        \n",
    "    plt.figure()\n",
    "    plt.plot(loss_history_train)\n",
    "    plt.plot(loss_history_eval)\n",
    "    plt.show()\n",
    "\n",
    "    # index is the position of the max probility of the first batch\n",
    "    # Shape of the pred_tensor: (T, B, 75)\n",
    "    # Shape of the index: (T)\n",
    "    _, index = pred_tensor[:, 0, :].max(-1)\n",
    "\n",
    "    # Change index numbers to character\n",
    "    sentence = tokenizer.num2word(index.view(-1))\n",
    "\n",
    "    # Change list to string\n",
    "    print(''.join(sentence))\n",
    "\n",
    "    # Remove \"blank\" and overlapping characters\n",
    "    index_ = Decode_CTC_Prediction(index)\n",
    "    sentence_ = tokenizer.num2word(index_)\n",
    "    print(''.join(sentence_))\n",
    "\n",
    "    true_sentence = tokenizer.num2word(ground_truth[0, :].detach().numpy().astype(int))\n",
    "    print(''.join(true_sentence))\n",
    "\n",
    "    # Plot image\n",
    "    # detach().cpu().numpy() transforms a tensor on gpu into a numpy matrix\n",
    "    plt.figure()\n",
    "    plt.imshow(pred_tensor[:, 0, :].detach().cpu().numpy())\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "\n",
    "    _, index = pred_tensor_[:, 0, :].max(-1)\n",
    "\n",
    "    sentence = tokenizer.num2word(index.view(-1))\n",
    "    print(''.join(sentence))\n",
    "    index_ = Decode_CTC_Prediction(index)\n",
    "    sentence_ = tokenizer.num2word(index_)\n",
    "    print(''.join(sentence_))\n",
    "    true_sentence = tokenizer.num2word(ground_truth_[0, :].detach().numpy().astype(int))\n",
    "    print(''.join(true_sentence))\n",
    "\n",
    "    plt.figure()\n",
    "    plt.imshow(pred_tensor_[:, 0, :].detach().cpu().numpy())\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "    print(\"-------------------------------------------------------------------------------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
