{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12853, 5)\n",
      "(12833, 5)\n"
     ]
    }
   ],
   "source": [
    "n_mels = 80\n",
    "fs = 44100\n",
    "frame_length_ms=50\n",
    "frame_shift_ms=25\n",
    "nsc = int(fs * frame_length_ms / 1000)\n",
    "nov = nsc - int(fs * frame_shift_ms / 1000)\n",
    "nhop = int(fs * frame_shift_ms / 1000)\n",
    "eps = 1e-8\n",
    "db_ref = 160\n",
    "\n",
    "meta_path = \"D:/korean-single-speaker-speech-dataset/transcript.v.1.2.txt\"\n",
    "data_folder = \"D:/korean-single-speaker-speech-dataset/kss\"\n",
    "\n",
    "with open(meta_path, encoding='utf-8') as f:\n",
    "    metadata = np.array([line.strip().split('|') for line in f])\n",
    "#     hours = sum((int(x[2]) for x in metadata)) * frame_shift_ms / (3600 * 1000)\n",
    "#     log('Loaded metadata for %d examples (%.2f hours)' % (len(metadata), hours))\n",
    "\n",
    "# metadata = metadata[:32, :2]\n",
    "\n",
    "max_sequence_len = max(list(map(len, metadata[:, 1])))\n",
    "\n",
    "error_jamos = [5868, 5998, 6046, 6155, 6202, \n",
    "               6654, 6890, 7486, 7502, 7744, \n",
    "               7765, 8267, 9069, 9927, 10437, \n",
    "               10515, 10533, 10606, 10610, 12777]\n",
    "\n",
    "print(metadata.shape)\n",
    "metadata = np.delete(metadata, error_jamos, axis = 0)\n",
    "print(metadata.shape)\n",
    "\n",
    "dataset_size = len(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "character_length = list()\n",
    "file_length = list()\n",
    "division_length = list()\n",
    "unicode_jamo_list = list()\n",
    "\n",
    "for i in range(len(metadata)):\n",
    "    character_length.append(len(metadata[i, 3]))\n",
    "    file_length.append(float(metadata[i, 4]))\n",
    "    division_length.append(float(metadata[i, 4]) * 1000 / len(metadata[i, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "wave_name_list = []\n",
    "\n",
    "for data in metadata:\n",
    "    wave_name_list.append(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', '!', ',', '.', '<eos>', '<sos>', '?', 'ᄀ', 'ᄁ', 'ᄂ', 'ᄃ', 'ᄄ', 'ᄅ', 'ᄆ', 'ᄇ', 'ᄈ', 'ᄉ', 'ᄊ', 'ᄋ', 'ᄌ', 'ᄍ', 'ᄎ', 'ᄏ', 'ᄐ', 'ᄑ', 'ᄒ', 'ᅡ', 'ᅢ', 'ᅣ', 'ᅤ', 'ᅥ', 'ᅦ', 'ᅧ', 'ᅨ', 'ᅩ', 'ᅪ', 'ᅫ', 'ᅬ', 'ᅭ', 'ᅮ', 'ᅯ', 'ᅰ', 'ᅱ', 'ᅲ', 'ᅳ', 'ᅴ', 'ᅵ', 'ᆨ', 'ᆩ', 'ᆪ', 'ᆫ', 'ᆬ', 'ᆭ', 'ᆮ', 'ᆯ', 'ᆰ', 'ᆱ', 'ᆲ', 'ᆳ', 'ᆴ', 'ᆵ', 'ᆶ', 'ᆷ', 'ᆸ', 'ᆹ', 'ᆺ', 'ᆻ', 'ᆼ', 'ᆽ', 'ᆾ', 'ᆿ', 'ᇀ', 'ᇁ', 'ᇂ']\n",
      "74\n"
     ]
    }
   ],
   "source": [
    "unicode_jamo_list = list()\n",
    "for unicode in range(0x1100, 0x1113):\n",
    "    unicode_jamo_list.append(chr(unicode))\n",
    "    \n",
    "for unicode in range(0x1161, 0x1176):\n",
    "    unicode_jamo_list.append(chr(unicode))\n",
    "    \n",
    "for unicode in range(0x11A8, 0x11C3):\n",
    "    unicode_jamo_list.append(chr(unicode))\n",
    "    \n",
    "unicode_jamo_list += [' ', '!', ',', '.', '?', '<sos>', '<eos>']\n",
    "    \n",
    "unicode_jamo_list.sort()\n",
    "\n",
    "print(unicode_jamo_list)\n",
    "print(len(unicode_jamo_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer():\n",
    "    def __init__(self, vocabs):\n",
    "        self.vocabs = vocabs\n",
    "        \n",
    "    def word2num(self, sentence):\n",
    "        tokens = list()\n",
    "        for char in sentence:\n",
    "            tokens.append(self.vocabs.index(char))    \n",
    "        return tokens\n",
    "        \n",
    "    def word2vec(self, sentence):\n",
    "        vectors = np.zeros((len(sentence), len(self.vocabs)))\n",
    "        for i, char in enumerate(sentence):\n",
    "            vectors[i, self.vocabs.index(char)] = 1   \n",
    "        return vectors\n",
    "    \n",
    "    def num2word(self, num):\n",
    "        output = list()\n",
    "        for i in num:\n",
    "            output.append(self.vocabs[i])\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(unicode_jamo_list)\n",
    "jamo_tokens = tokenizer.word2num(unicode_jamo_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(jamo_tokens)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efd4acbf1d4b4ad6a1ccfd91ffd79d28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=12833), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mel_path_list = list()\n",
    "\n",
    "for i, wav_name in enumerate(tqdm(wave_name_list)):\n",
    "    \n",
    "    npy_name = wav_name.replace('.wav', '.npy')\n",
    "    wav_path = os.path.join(data_folder, wav_name)  \n",
    "    mel_path = os.path.join(data_folder + '/mel', npy_name)\n",
    "    mel_path_list.append(mel_path)\n",
    "    \n",
    "    if not os.path.isfile(mel_path):\n",
    "#         print(\"{}\".format(mel_path))\n",
    "        y, sr = librosa.core.load(wav_path)\n",
    "        f, t, Zxx = sp.signal.stft(y, fs=sr, nperseg=nsc, noverlap=nov)\n",
    "        Sxx = np.abs(Zxx)\n",
    "        Sxx = np.maximum(Sxx, eps)\n",
    "\n",
    "        # plt.figure(figsize=(20,20))\n",
    "        # plt.imshow(20*np.log10(Sxx), origin='lower')\n",
    "        # plt.colorbar()\n",
    "        # plt.show()\n",
    "\n",
    "        mel_filters = librosa.filters.mel(sr=fs, n_fft=nsc, n_mels=n_mels)\n",
    "        mel_specgram = np.matmul(mel_filters, Sxx)\n",
    "\n",
    "    #   log_specgram = 20*np.log10(Sxx)\n",
    "    #   norm_log_specgram = (log_specgram + db_ref) / db_ref\n",
    "\n",
    "        log_mel_specgram = 20 * np.log10(np.maximum(mel_specgram, eps))\n",
    "        norm_log_mel_specgram = (log_mel_specgram + db_ref) / db_ref\n",
    "\n",
    "    #   np.save(specgram_path, norm_log_specgram)\n",
    "        np.save(mel_path, norm_log_mel_specgram)\n",
    "    #   np.save(specgram_path, Sxx)\n",
    "\n",
    "    #     print(norm_log_mel_specgram.shape[1])\n",
    "\n",
    "    #     if i % 1000 == 0:\n",
    "    #         plt.figure(figsize=(8, 4))\n",
    "    #         plt.imshow(20 * np.log10(Sxx), origin='lower', aspect='auto')\n",
    "    #         plt.colorbar()\n",
    "    #         plt.show()\n",
    "\n",
    "    #         plt.figure(figsize=(8, 4))\n",
    "    #         plt.imshow(norm_log_mel_specgram, origin='lower', aspect='auto')\n",
    "    #         plt.colorbar()\n",
    "    #         plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding_layer = nn.Embedding(len(jamo_tokens), 256)\n",
    "\n",
    "# print(metadata[5031, 3])\n",
    "# print(metadata[5031, 2])\n",
    "# print(len(metadata[5031, 3]))\n",
    "\n",
    "# input_token = tokenizer.word2num(metadata[5031, 3])\n",
    "# input_tensor = torch.tensor(input_token)\n",
    "# plt.imshow(embedding_layer(input_tensor).detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.H = H\n",
    "        self.fc = torch.nn.Linear(D_in, H)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        \n",
    "        self.fc_2 = torch.nn.Linear(H, H)\n",
    "        self.relu_2 = torch.nn.ReLU()\n",
    "        \n",
    "        self.gru = nn.GRU(H, D_out, num_layers=3, bidirectional=True)\n",
    "        self.relu_gru = torch.nn.ReLU()\n",
    "\n",
    "    def forward(self, input_tensor):\n",
    "        output_tensor = self.fc(input_tensor)\n",
    "        output_tensor = self.relu(output_tensor)\n",
    "        \n",
    "        output_tensor, _ = self.gru(output_tensor)\n",
    "        output_tensor = self.relu_gru(output_tensor)\n",
    "        \n",
    "        output_tensor = self.fc_2(output_tensor)\n",
    "        output_tensor = self.relu_2(output_tensor)\n",
    "        return output_tensor\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, H, D_out):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.H = H\n",
    "        self.fc_embed = nn.Linear(256, 1024)\n",
    "        self.gru = nn.GRU(2 * H, H)\n",
    "        self.attention = AttentionModule(D_out * 2)\n",
    "        self.fc = nn.Linear(1024, 74)\n",
    "        self.softmax = nn.Softmax(dim=2)\n",
    "\n",
    "    def forward(self, input_tensor, hidden_tensor, query):\n",
    "        output_tensor = self.fc_embed(input_tensor)\n",
    "        output_tensor, hidden_tensor = self.gru(output_tensor, hidden_tensor)\n",
    "        context_vector = self.attention(query, output_tensor)\n",
    "        output_tensor = torch.cat([output_tensor, context_vector], dim=2)\n",
    "#         print('output_tensor: {}'.format(output_tensor.shape))\n",
    "#         print('output_tensor: {}'.format(context_vector.shape))\n",
    "        output_tensor = self.fc(output_tensor)\n",
    "        prediction_tensor = self.softmax(output_tensor)\n",
    "\n",
    "        return prediction_tensor, hidden_tensor, context_vector\n",
    "\n",
    "class AttentionModule(torch.nn.Module):\n",
    "    def __init__(self, H):\n",
    "        super(AttentionModule, self).__init__()\n",
    "        self.fc_alpha = nn.Linear(H, 1)\n",
    "        self.W = nn.Linear(H, H)\n",
    "        self.V = nn.Linear(H, H)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, query, key):\n",
    "        output_tensor = torch.tanh(torch.add(self.W(query), self.V(key)))\n",
    "        e = self.fc_alpha(output_tensor)\n",
    "        e_sig = self.sigmoid(e)\n",
    "        alpha = self.softmax(e_sig).transpose(1, 2)\n",
    "        context_vector = torch.bmm(alpha, query)\n",
    "        \n",
    "        return context_vector\n",
    "\n",
    "class Mel2SeqNet():\n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        super(Mel2SeqNet, self).__init__()\n",
    "        self.H = H\n",
    "        self.encoder = Encoder(D_in, H, D_out) \n",
    "        self.embedding_layer = nn.Embedding(len(jamo_tokens), 256)\n",
    "        self.decoder = Decoder(H, D_out)\n",
    "        self.encoder_optimizer = optim.SGD(self.encoder.parameters(), lr=0.01)\n",
    "        self.decoder_optimizer = optim.SGD(self.decoder.parameters(), lr=0.01)\n",
    "        self.embedding_optimizer = optim.SGD(self.embedding_layer.parameters(), lr=0.01)\n",
    "        \n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    def train(self, input_tensor, ground_truth):\n",
    "\n",
    "        self.encoder_optimizer.zero_grad()\n",
    "        self.decoder_optimizer.zero_grad()\n",
    "        self.embedding_optimizer.zero_grad()\n",
    "\n",
    "        encoded_tensor = self.encoder(input_tensor)\n",
    "        decoder_hidden = encoded_tensor[:, -1, :].view(1, 1, self.H)\n",
    "        \n",
    "        pred_tensor_list = list()\n",
    "        context_vector_list = list()\n",
    "        \n",
    "        loss = 0\n",
    "        \n",
    "        decoder_input = self.embedding_layer(torch.tensor(tokenizer.word2num(['<sos>']))).view([1, 1, -1])\n",
    "        \n",
    "        for i in range(len(ground_truth)):\n",
    "            \n",
    "            pred_tensor, decoder_hidden, context_vector = self.decoder(decoder_input, decoder_hidden, encoded_tensor)\n",
    "            pred_tensor_list.append(pred_tensor)\n",
    "            context_vector_list.append(context_vector)\n",
    "            \n",
    "            loss += self.criterion(pred_tensor.view([1, -1]), ground_truth[i].view(1))\n",
    "            decoder_input = self.embedding_layer(ground_truth[i]).view([1, 1, -1])\n",
    "            \n",
    "        loss.backward()\n",
    "\n",
    "        self.encoder_optimizer.step()\n",
    "        self.decoder_optimizer.step()\n",
    "        self.embedding_optimizer.step()\n",
    "\n",
    "        pred_tensor = torch.cat(pred_tensor_list, dim=1)\n",
    "        context_matrix = torch.cat(context_vector_list, dim=1)\n",
    "        \n",
    "        return pred_tensor, context_matrix, loss.item() / len(ground_truth)\n",
    "    \n",
    "    def save(self, check_point_name):\n",
    "        torch.save({\n",
    "            'embedding_layer_state_dict': self.embedding_layer.state_dict(),\n",
    "            'encoder_state_dict': self.encoder.state_dict(),\n",
    "            'decoder_state_dict': self.decoder.state_dict(),\n",
    "            'embedding_optimizer_state_dict': self.embedding_optimizer.state_dict(),\n",
    "            'encoder_optimizer_state_dict': self.encoder_optimizer.state_dict(),\n",
    "            'decoder_optimizer_state_dict': self.decoder_optimizer.state_dict(),\n",
    "            }, check_point_name)\n",
    "    \n",
    "    def load(self, check_point_name):\n",
    "        checkpoint = torch.load(check_point_name)\n",
    "        self.embedding_layer.load_state_dict(checkpoint['embedding_layer_state_dict'])\n",
    "        self.encoder.load_state_dict(checkpoint['encoder_state_dict'])\n",
    "        self.decoder.load_state_dict(checkpoint['decoder_state_dict'])\n",
    "        self.embedding_optimizer.load_state_dict(checkpoint['embedding_optimizer_state_dict'])\n",
    "        self.encoder_optimizer.load_state_dict(checkpoint['encoder_optimizer_state_dict'])\n",
    "        self.decoder_optimizer.load_state_dict(checkpoint['decoder_optimizer_state_dict'])\n",
    "    \n",
    "        self.embedding_layer.eval()\n",
    "        self.encoder.eval()\n",
    "        self.decoder.eval()\n",
    "    \n",
    "net = Mel2SeqNet(80, 512, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2da9cda45e74f75a03dfcda1b785daa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=12833), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 0: 4.304347991943359\n",
      "Loss 10: 4.303143045176631\n",
      "Loss 20: 4.302452087402344\n",
      "Loss 30: 4.302085876464844\n",
      "Loss 40: 4.302023397909628\n",
      "Loss 50: 4.301064742238898\n",
      "Loss 60: 4.299983433314732\n",
      "Loss 70: 4.3025255705180925\n",
      "Loss 80: 4.294474283854167\n",
      "Loss 90: 4.29112663269043\n",
      "Loss 100: 4.26954943068484\n",
      "Loss 110: 4.26636474609375\n",
      "Loss 120: 4.25541741507394\n",
      "Loss 130: 4.223692950080423\n",
      "Loss 140: 4.209004720052083\n",
      "Loss 150: 4.1992978696469905\n",
      "Loss 160: 4.0850168863932295\n",
      "Loss 170: 4.1365113869691505\n",
      "Loss 180: 4.199428947604432\n",
      "Loss 190: 4.1050635049509445\n",
      "Loss 200: 4.121079736826371\n",
      "Loss 210: 4.100560701810396\n",
      "Loss 220: 4.139442599549586\n",
      "Loss 230: 4.073041915893555\n",
      "Loss 240: 4.08807373046875\n",
      "Loss 250: 4.082726218483665\n",
      "Loss 260: 4.109728622436523\n",
      "Loss 270: 4.1711476643880205\n",
      "Loss 280: 4.1013389120296555\n",
      "Loss 290: 4.063277859157986\n",
      "Loss 300: 4.025575637817383\n",
      "Loss 310: 4.046474729265485\n",
      "Loss 320: 4.097513372247869\n",
      "Loss 330: 4.010381525213068\n",
      "Loss 340: 4.096340603298611\n",
      "Loss 350: 4.035656553326231\n",
      "Loss 360: 4.115152459395559\n",
      "Loss 370: 4.024824391240659\n",
      "Loss 380: 4.041965208191803\n",
      "Loss 390: 4.110468762986203\n",
      "Loss 400: 4.074734841623614\n",
      "Loss 410: 4.108522131087932\n",
      "Loss 420: 4.018738184219751\n",
      "Loss 430: 4.040721045600043\n",
      "Loss 440: 3.9950503394717263\n",
      "Loss 450: 4.144067764282227\n",
      "Loss 460: 4.054110559923895\n",
      "Loss 470: 4.09718257822889\n",
      "Loss 480: 4.1390329996744795\n",
      "Loss 490: 4.021886356541367\n",
      "Loss 500: 4.082375351263552\n",
      "Loss 510: 3.9660004406440548\n",
      "Loss 520: 4.142142684371383\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-a0aa37c82499>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mground_truth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword2num\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'<eos>'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mpred_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mground_truth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m10\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-dff77827d0fb>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, input_tensor, ground_truth)\u001b[0m\n\u001b[0;32m    101\u001b[0m             \u001b[0mdecoder_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mground_truth\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder_optimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    116\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m         \"\"\"\n\u001b[1;32m--> 118\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPOCH = 1\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    for i in tqdm(range(len(metadata))):\n",
    "        norm_log_mel_specgram = np.load(mel_path_list[i])\n",
    "        input_spectrogram = norm_log_mel_specgram.T\n",
    "        tensor_input = torch.tensor(input_spectrogram).view(1, input_spectrogram.shape[0], input_spectrogram.shape[1])\n",
    "        ground_truth = torch.tensor(tokenizer.word2num(list(metadata[i, 3]) + ['<eos>']))\n",
    "\n",
    "        pred_tensor, context_matrix, loss = net.train(tensor_input, ground_truth)\n",
    "        \n",
    "        if (i % 10 == 0):\n",
    "            print('Loss {}: {}'.format(i, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0e483d05edb441ea7a47ca565c0df03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=12833), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 0: 4.035584767659505\n",
      "Loss 10: 4.019740892493206\n",
      "Loss 20: 3.981843619511045\n",
      "Loss 30: 3.9866839599609376\n",
      "Loss 40: 4.050534634976773\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-a0aa37c82499>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mground_truth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword2num\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'<eos>'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mpred_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mground_truth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m10\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-28-dff77827d0fb>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, input_tensor, ground_truth)\u001b[0m\n\u001b[0;32m    101\u001b[0m             \u001b[0mdecoder_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mground_truth\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder_optimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    116\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m         \"\"\"\n\u001b[1;32m--> 118\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPOCH = 1\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    for i in tqdm(range(len(metadata))):\n",
    "        norm_log_mel_specgram = np.load(mel_path_list[i])\n",
    "        input_spectrogram = norm_log_mel_specgram.T\n",
    "        tensor_input = torch.tensor(input_spectrogram).view(1, input_spectrogram.shape[0], input_spectrogram.shape[1])\n",
    "        ground_truth = torch.tensor(tokenizer.word2num(list(metadata[i, 3]) + ['<eos>']))\n",
    "\n",
    "        pred_tensor, context_matrix, loss = net.train(tensor_input, ground_truth)\n",
    "        \n",
    "        if (i % 10 == 0):\n",
    "            print('Loss {}: {}'.format(i, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.save('check_point_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.load('check_point_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_input = torch.tensor(input_spectrogram).view(1, input_spectrogram.shape[0], input_spectrogram.shape[1])\n",
    "\n",
    "ground_truth = torch.tensor(tokenizer.word2num(list(metadata[12832, 3]) + ['<eos>']))\n",
    "\n",
    "pred_tensor, context_matrix, loss = net.train(tensor_input, ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "아  ᅡ 아아ᄋ아  아아ᄋ ᅡ 아ᄋ아ᄋ ᅡ ᅡ.<eos>\n",
      "초현실주의 회화는 어떤 사람에게는 색과 모양을 마구잡이로 섞어 놓은 것처럼 보일 수 있다.\n"
     ]
    }
   ],
   "source": [
    "_, index = pred_tensor.max(-1)\n",
    "# print(index.view(-1))\n",
    "sentence = tokenizer.num2word(index.view(-1))\n",
    "print(''.join(sentence))\n",
    "print(metadata[5031, 2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
