{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lNy2clEZPKAv"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa # librosa: Audio handling package\n",
    "import random\n",
    "import copy\n",
    "import re\n",
    "import jamotools\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm # tqdm: Pakage for progress bar visualization\n",
    "from datetime import datetime\n",
    "\n",
    "import threading\n",
    "import queue\n",
    "\n",
    "import Levenshtein as Lev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "SBaEfy86PKA1",
    "outputId": "4cde26f5-f3e4-4589-871e-e204684d376e"
   },
   "outputs": [],
   "source": [
    "n_mels = 80\n",
    "fs = 16000\n",
    "frame_length_ms=100\n",
    "frame_shift_ms=50\n",
    "nsc = int(fs * frame_length_ms / 1000)\n",
    "nov = nsc - int(fs * frame_shift_ms / 1000)\n",
    "nhop = int(fs * frame_shift_ms / 1000)\n",
    "eps = 1e-8\n",
    "db_ref = 160\n",
    "\n",
    "# meta_path = 'gdrive/My Drive/korean-single-speaker-speech-dataset/transcript.v.1.2.txt'\n",
    "# data_folder = 'gdrive/My Drive/korean-single-speaker-speech-dataset/kss'\n",
    "\n",
    "# meta_path = \"D:/korean-single-speaker-speech-dataset/transcript.v.1.2.txt\"\n",
    "# data_folder = \"D:/korean-single-speaker-speech-dataset/kss\"\n",
    "\n",
    "data_folder = \"D:/nsml-dataset/train_data/\"\n",
    "label_path = \"D:/nsml-dataset/hackathon.labels\"\n",
    "\n",
    "data_list = glob.glob(data_folder + '*.csv')[0]\n",
    "\n",
    "wav_paths = list()\n",
    "script_paths = list()\n",
    "korean_script_paths = list()\n",
    "\n",
    "with open(data_list, 'r') as f:\n",
    "    for line in f:\n",
    "        # line: \"aaa.wav,aaa.label\"\n",
    "        wav_path, script_path = line.strip().split(',')\n",
    "        korean_script_path = script_path.replace('.label', '.script')\n",
    "        \n",
    "        wav_paths.append(os.path.join(data_folder, wav_path))\n",
    "        script_paths.append(os.path.join(data_folder, script_path))\n",
    "        korean_script_paths.append(os.path.join(data_folder, korean_script_path))\n",
    "\n",
    "dataset_size = len(wav_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(filepath, bos_id, eos_id):\n",
    "    key = filepath.split('/')[-1].split('.')[0]\n",
    "    script = target_dict[key]\n",
    "    tokens = script.split(' ')\n",
    "    result = list()\n",
    "    result.append(bos_id)\n",
    "    for i in range(len(tokens)):\n",
    "        if len(tokens[i]) > 0:\n",
    "            result.append(int(tokens[i]))\n",
    "    result.append(eos_id)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"wav_paths len: {}\".format(len(wav_paths)))\n",
    "print(\"script_paths len: {}\".format(len(script_paths)))\n",
    "print(\"korean_script_paths len: {}\".format(len(korean_script_paths)))\n",
    "\n",
    "print(wav_paths[0])\n",
    "print(script_paths[0])\n",
    "print(korean_script_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(script_paths[1]) as f:\n",
    "    line = f.read()\n",
    "    line = line.strip()\n",
    "    result = list(map(int, line.split(' ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_label(label_path):\n",
    "    char2index = dict() # [ch] = id\n",
    "    index2char = dict() # [id] = ch\n",
    "    with open(label_path, 'r', encoding='UTF-8') as f:\n",
    "    # with open(label_path, 'r') as f:\n",
    "        for no, line in enumerate(f):\n",
    "            if line[0] == '#': \n",
    "                continue\n",
    "\n",
    "            index, char, freq = line.strip().split('\\t')\n",
    "            char = char.strip()\n",
    "            if len(char) == 0:\n",
    "                char = ' '\n",
    "\n",
    "            char2index[char] = int(index)\n",
    "            index2char[int(index)] = char\n",
    "\n",
    "    return char2index, index2char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char2index, index2char = load_label(label_path)\n",
    "SOS_token = char2index['<s>']  # '<sos>' or '<s>'\n",
    "EOS_token = char2index['</s>']  # '<eos>' or '</s>'\n",
    "PAD_token = char2index['_']  # '-' or '_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "korean_script_list = list()\n",
    "jamo_script_list = list()\n",
    "\n",
    "jamo_regex = re.compile(u'[,_ ^.?!ï¼Ÿ~<>:;/%()+A-Za-z0-9\\u1100-\\u115e\\u1161-\\u11A7\\u11a8-\\u11ff]+')\n",
    "\n",
    "for file in tqdm(korean_script_paths):\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        line = f.read()\n",
    "        line = line.strip()\n",
    "        korean_script_list.append(line)\n",
    "        jamo = jamotools.split_syllables(line, 'JAMO')\n",
    "        jamo_filtered = ''.join(jamo_regex.findall(jamo))\n",
    "        jamo_script_list.append(jamo_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Threading_Batched_Preloader():\n",
    "    def __init__(self, wav_path_list, ground_truth_list, script_path_list, batch_size, is_train=True):\n",
    "        super(Threading_Batched_Preloader).__init__()\n",
    "        self.wav_path_list = wav_path_list\n",
    "        self.total_num_input = len(wav_path_list)\n",
    "        self.tensor_input_list = [None] * self.total_num_input\n",
    "        self.ground_truth_list = ground_truth_list\n",
    "        self.script_path_list = script_path_list\n",
    "        self.sentence_length_list = np.asarray(list(map(len, ground_truth_list)))\n",
    "        self.shuffle_step = 12\n",
    "        self.loading_sequence = None\n",
    "        self.end_flag = False\n",
    "        self.batch_size = batch_size\n",
    "        self.queue = queue.Queue(32)\n",
    "        self.thread_flags = list()\n",
    "        self.is_train = is_train\n",
    "    \n",
    "    # Shuffle loading index and set end flag to false\n",
    "    def initialize_batch(self, thread_num):\n",
    "        loading_sequence = np.argsort(self.sentence_length_list)\n",
    "        bundle = np.stack([self.sentence_length_list[loading_sequence], loading_sequence])\n",
    "\n",
    "        for seq_len in range(self.shuffle_step, np.max(self.sentence_length_list), self.shuffle_step):\n",
    "            idxs = np.where((bundle[0, :] > seq_len) & (bundle[0, :] <= seq_len + self.shuffle_step))[0]\n",
    "            idxs_origin = copy.deepcopy(idxs)\n",
    "            random.shuffle(idxs)\n",
    "            bundle[:, idxs_origin] = bundle[:, idxs]\n",
    "            \n",
    "        loading_sequence = bundle[1, :]\n",
    "        loading_sequence_len = len(loading_sequence)\n",
    "        \n",
    "#         print(\"Loading Sequence Length: {}\".format(loading_sequence_len))\n",
    "        \n",
    "        thread_size = int(np.ceil(loading_sequence_len / thread_num))\n",
    "\n",
    "        load_idxs_list = list()\n",
    "        for i in range(thread_num):\n",
    "            start_idx = i * thread_size\n",
    "            end_idx = (i + 1) * thread_size\n",
    "\n",
    "            if end_idx > loading_sequence_len:\n",
    "                end_idx = loading_sequence_len\n",
    "\n",
    "            load_idxs_list.append(loading_sequence[start_idx:end_idx])\n",
    "            \n",
    "#         for i in range(thread_num):\n",
    "#             print(len(load_idxs_list[i]))\n",
    "\n",
    "        self.end_flag = False\n",
    "        \n",
    "        self.queue = queue.Queue(32)\n",
    "        self.thread_flags = [False] * thread_num\n",
    "        \n",
    "        self.thread_list = [Batching_Thread(self.wav_path_list, self.ground_truth_list, self.script_path_list, load_idxs_list[i], self.queue, self.batch_size, self.thread_flags, i, self.is_train) for i in range(thread_num)]\n",
    "\n",
    "        for thread in self.thread_list:\n",
    "            thread.start()\n",
    "        return\n",
    "\n",
    "    def check_thread_flags(self):\n",
    "        for flag in self.thread_flags:\n",
    "            if flag == False:\n",
    "                return False\n",
    "        \n",
    "        if (self.queue.empty):\n",
    "            self.end_flag = True\n",
    "            return True\n",
    "\n",
    "        return False\n",
    "\n",
    "    def get_batch(self):\n",
    "        while not (self.check_thread_flags()):\n",
    "            batch = self.queue.get()\n",
    "\n",
    "            if (batch != None):\n",
    "                batched_tensor = batch[0]\n",
    "                batched_ground_truth = batch[1] \n",
    "                batched_loss_mask = batch[2]\n",
    "                ground_truth_size_list = batch[3]\n",
    "                lev_truth_list = batch[4]\n",
    "\n",
    "                return batched_tensor, batched_ground_truth, batched_loss_mask, ground_truth_size_list, lev_truth_list\n",
    "\n",
    "        return None\n",
    "\n",
    "class Batching_Thread(threading.Thread):\n",
    "\n",
    "    def __init__(self, wav_path_list, ground_truth_list, script_path_list, load_idxs_list, queue, batch_size, thread_flags, id, is_train=True):\n",
    "        \n",
    "        threading.Thread.__init__(self)\n",
    "        self.wav_path_list = wav_path_list\n",
    "        self.ground_truth_list = ground_truth_list\n",
    "        self.script_path_list = script_path_list\n",
    "        self.load_idxs_list = load_idxs_list\n",
    "        self.list_len = len(load_idxs_list)\n",
    "        self.cur_idx = 0\n",
    "        self.id = id\n",
    "        self.queue = queue\n",
    "        self.batch_size = batch_size \n",
    "        self.thread_flags = thread_flags\n",
    "        self.is_train = is_train\n",
    "\n",
    "    def run(self):\n",
    "\n",
    "        while(self.cur_idx < self.list_len):\n",
    "            batch = self.batch()\n",
    "            success = False\n",
    "            while success == False:\n",
    "                try:\n",
    "                    self.queue.put(batch, True)\n",
    "                    success = True\n",
    "                except:\n",
    "                    print(\"Batching Failed in Thread ID: {}\".format(self.id))\n",
    "                    sleep(1)\n",
    "\n",
    "        self.thread_flags[self.id] = True\n",
    "        \n",
    "#         print(\"Thread {} finished\".foramt(self.id))\n",
    "\n",
    "        return \n",
    "\n",
    "\n",
    "    def batch(self):\n",
    "\n",
    "        tensor_list = list()\n",
    "        ground_truth_list = list()\n",
    "        tensor_size_list = list()\n",
    "        ground_truth_size_list = list()\n",
    "        lev_truth_list = list()\n",
    "        \n",
    "        count = 0\n",
    "        max_seq_len = 0\n",
    "        max_sen_len = 0\n",
    "        \n",
    "        for i in range(self.batch_size):\n",
    "            \n",
    "            # If there is no more file, break and set end_flag true\n",
    "            if self.cur_idx >= self.list_len:\n",
    "                self.end_flag = True\n",
    "                break\n",
    "                \n",
    "            script_path = self.script_path_list[self.load_idxs_list[self.cur_idx]]\n",
    "            \n",
    "#             print(script_path)\n",
    "            \n",
    "            with open(script_path) as f:\n",
    "                line = f.read()\n",
    "                line = line.strip()\n",
    "                lev_truth = list(map(int, line.split(' ')))\n",
    "                \n",
    "            lev_truth_list.append(lev_truth)\n",
    "            \n",
    "            wav_path = self.wav_path_list[self.load_idxs_list[self.cur_idx]]\n",
    "\n",
    "            tensor = self.create_mel(wav_path)\n",
    "            tensor_list.append(tensor)\n",
    "            tensor_size_list.append(tensor.shape[1])\n",
    "            \n",
    "            ground_truth = self.ground_truth_list[self.load_idxs_list[self.cur_idx]]\n",
    "            ground_truth_list.append(ground_truth)\n",
    "            ground_truth_size_list.append(len(ground_truth))\n",
    "            \n",
    "            if (tensor.shape[1] > max_seq_len):\n",
    "                max_seq_len = tensor.shape[1]\n",
    "            if (len(ground_truth) > max_sen_len):\n",
    "                max_sen_len = len(ground_truth)  \n",
    "            \n",
    "            self.cur_idx += 1\n",
    "            count += 1\n",
    "            \n",
    "        batched_tensor = torch.zeros(count, max_seq_len + 5, n_mels)\n",
    "        batched_ground_truth = torch.zeros(count, max_sen_len)\n",
    "        batched_loss_mask = torch.zeros(count, max_sen_len)\n",
    "        ground_truth_size_list = torch.tensor(np.asarray(ground_truth_size_list), dtype=torch.long)\n",
    "        \n",
    "        for order in range(count):\n",
    "            \n",
    "            target = tensor_list[order]\n",
    "            \n",
    "            if self.is_train:\n",
    "                pad_random = np.random.randint(0, 5)\n",
    "                # Time shift, add zeros in front of an image\n",
    "                if pad_random > 0:\n",
    "                    offset = torch.zeros(target.shape[0], pad_random, target.shape[2])\n",
    "                    target = torch.cat((offset, target), 1)\n",
    "                # Add random noise\n",
    "                target = target + (torch.rand(target.shape) - 0.5) / 20\n",
    "                # Value less than 0 or more than 1 is clamped to 0 and 1\n",
    "                target = torch.clamp(target, min=0.0, max=1.0)\n",
    "                batched_tensor[order, :tensor_size_list[order] + pad_random, :] = target\n",
    "            else:\n",
    "                batched_tensor[order, :tensor_size_list[order], :] = target\n",
    "\n",
    "#           batched_tensor[order, :tensor_size_list[order], :] = target\n",
    "            batched_ground_truth[order, :ground_truth_size_list[order]] = torch.tensor(ground_truth_list[order])\n",
    "            \n",
    "            # You do not need to know what loss mask is \n",
    "            batched_loss_mask[order, :ground_truth_size_list[order]] = torch.ones(ground_truth_size_list[order])\n",
    "        \n",
    "        return [batched_tensor, batched_ground_truth, batched_loss_mask, ground_truth_size_list, lev_truth_list]\n",
    "    \n",
    "    def create_mel(self, wav_path):  \n",
    "        y, sr = librosa.core.load(wav_path, sr=fs) \n",
    "        f, t, Zxx = sp.signal.stft(y, fs=sr, nperseg=nsc, noverlap=nov)\n",
    "        Sxx = np.abs(Zxx)\n",
    "\n",
    "        # mel_filters: (n_fft, n_mels)\n",
    "        mel_filters = librosa.filters.mel(sr=fs, n_fft=nsc, n_mels=n_mels)\n",
    "        mel_specgram = np.matmul(mel_filters, Sxx)\n",
    "\n",
    "        # log10(0) is minus infinite, so replace mel_specgram values smaller than 'eps' as 'eps' (1e-8)\n",
    "        log_mel_specgram = 20 * np.log10(np.maximum(mel_specgram, eps))\n",
    "        \n",
    "        # 20 * log10(eps) = 20 * -8 = -160\n",
    "        # -160 is the smallest value\n",
    "        # Add 160 and divide by 160 => Normalize value between 0 and 1\n",
    "        norm_log_mel_specgram = (log_mel_specgram + db_ref) / db_ref        \n",
    "        \n",
    "        # (F, T) -> (T, F)\n",
    "        input_spectrogram = norm_log_mel_specgram.T\n",
    "        # (T, F) -> (1, T, F)\n",
    "        # Inserted the first axis to make stacking easier\n",
    "        tensor_input = torch.tensor(input_spectrogram).view(1, input_spectrogram.shape[0], input_spectrogram.shape[1])\n",
    "        return tensor_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer maps numbers to characters, 8 -> 'ã„±', 10 -> 'ã„´'\n",
    "class Tokenizer():\n",
    "    def __init__(self, vocabs):\n",
    "        self.vocabs = vocabs\n",
    "        \n",
    "    def word2num(self, sentence):\n",
    "        tokens = list()\n",
    "        for char in sentence:\n",
    "            tokens.append(self.vocabs.index(char))    \n",
    "        return tokens\n",
    "        \n",
    "    def word2vec(self, sentence):\n",
    "        vectors = np.zeros((len(sentence), len(self.vocabs)))\n",
    "        for i, char in enumerate(sentence):\n",
    "            vectors[i, self.vocabs.index(char)] = 1   \n",
    "        return vectors\n",
    "    \n",
    "    def num2word(self, num):\n",
    "        output = list()\n",
    "        for i in num:\n",
    "            output.append(self.vocabs[i])\n",
    "        return output\n",
    "    \n",
    "    def num2vec(self, numbers):\n",
    "        vectors = np.zeros((len(numbers), len(self.vocabs)))\n",
    "        for i, num in enumerate(numbers):\n",
    "            vectors[i, num] = 1   \n",
    "        return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "9gbjg0_LPKA8",
    "outputId": "b2b29359-e867-4df6-e305-83de989ceef3"
   },
   "outputs": [],
   "source": [
    "unicode_jamo_list = list()\n",
    "\n",
    "# ì´ˆì„±\n",
    "for unicode in range(0x1100, 0x1113):\n",
    "    unicode_jamo_list.append(chr(unicode))  # chr: Change hexadecimal to unicode\n",
    "# ì¤‘ì„±\n",
    "for unicode in range(0x1161, 0x1176):\n",
    "    unicode_jamo_list.append(chr(unicode))\n",
    "# ì¢…ì„±\n",
    "for unicode in range(0x11A8, 0x11C3):\n",
    "    unicode_jamo_list.append(chr(unicode))\n",
    "for unicode in range(ord('A'), ord('Z') + 1):\n",
    "    unicode_jamo_list.append(chr(unicode))\n",
    "for unicode in range(ord('a'), ord('z') + 1):\n",
    "    unicode_jamo_list.append(chr(unicode))\n",
    "for unicode in range(ord('0'), ord('9') + 1):\n",
    "    unicode_jamo_list.append(chr(unicode))\n",
    "\n",
    "unicode_jamo_list += [' ', '\\\\', '!', '~', '^', '<', '>', ',', '.', \"'\", '?', 'ï¼Ÿ', '/', '%', '(', ')', ':', ';', '+',\n",
    "                      '-', '<s>', '</s>']\n",
    "unicode_jamo_list.sort()\n",
    "# '_' symbol represents \"blank\" in CTC loss system, \"blank\" has to be the index 0\n",
    "unicode_jamo_list = ['_'] + unicode_jamo_list\n",
    "\n",
    "tokenizer = Tokenizer(unicode_jamo_list)\n",
    "jamo_tokens = tokenizer.word2num(unicode_jamo_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_list = [(tokenizer.word2num(['<s>'] + list(jamo_script_list[i]) + ['</s>'])) for i in range(len(jamo_script_list))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 90% of the data will be used as train\n",
    "split_index = int(0.9 * len(wav_paths))\n",
    "\n",
    "wav_path_list_train = wav_paths[:split_index]\n",
    "ground_truth_list_train = ground_truth_list[:split_index]\n",
    "script_path_list_train = script_paths[:split_index]\n",
    "\n",
    "wav_path_list_eval = wav_paths[split_index:]\n",
    "ground_truth_list_eval = ground_truth_list[split_index:]\n",
    "script_path_list_eval = script_paths[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "num_thread = 3\n",
    "\n",
    "preloader_eval = Threading_Batched_Preloader(wav_path_list_eval, ground_truth_list_eval, script_path_list_eval, batch_size, is_train=False)\n",
    "preloader_train = Threading_Batched_Preloader(wav_path_list_train, ground_truth_list_train, script_path_list_train, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, optimizer, ctc_loss, input_tensor, ground_truth, loss_mask, target_lengths):\n",
    "\n",
    "    # Shape of the input tensor (B, T, F)\n",
    "    # B: Number of a batch (8, 16, or 64 ...)\n",
    "    # T: Temporal length of an input\n",
    "    # F: Number of frequency band, 80\n",
    "\n",
    "    net.train()\n",
    "    \n",
    "    batch_size = input_tensor.shape[0]\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    pred_tensor = net(input_tensor)\n",
    "    \n",
    "    # Cast true sentence as Long data type, since CTC loss takes long tensor only\n",
    "    # Shape (B, S)\n",
    "    # S: Max length among true sentences \n",
    "    truth = ground_truth\n",
    "    truth = truth.type(torch.cuda.LongTensor)\n",
    "\n",
    "    input_lengths = torch.full(size=(batch_size,), fill_value=pred_tensor.shape[0], dtype=torch.long)\n",
    "\n",
    "    loss = ctc_loss(pred_tensor, truth, input_lengths, target_lengths)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Return loss divided by true length because loss is sum of the character losses\n",
    "\n",
    "    return pred_tensor, loss.item() / ground_truth.shape[1]\n",
    "\n",
    "\n",
    "def evaluate(net, ctc_loss, input_tensor, ground_truth, loss_mask, target_lengths):\n",
    "\n",
    "    # Shape of the input tensor (B, T, F)\n",
    "    # B: Number of a batch (8, 16, or 64 ...)\n",
    "    # T: Temporal length of an input\n",
    "    # F: Number of frequency band, 80\n",
    "\n",
    "    net.eval()\n",
    "    \n",
    "    batch_size = input_tensor.shape[0]\n",
    "    \n",
    "    pred_tensor = net(input_tensor)\n",
    "    \n",
    "    # Cast true sentence as Long data type, since CTC loss takes long tensor only\n",
    "    # Shape (B, S)\n",
    "    # S: Max length among true sentences \n",
    "    truth = ground_truth\n",
    "    truth = truth.type(torch.cuda.LongTensor)\n",
    "\n",
    "    input_lengths = torch.full(size=(batch_size,), fill_value=pred_tensor.shape[0], dtype=torch.long)\n",
    "\n",
    "    loss = ctc_loss(pred_tensor, truth, input_lengths, target_lengths)\n",
    "\n",
    "    # Return loss divided by true length because loss is sum of the character losses\n",
    "\n",
    "    return pred_tensor, loss.item() / ground_truth.shape[1]\n",
    "\n",
    "def save(model, optimizer, check_point_name):\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        }, check_point_name)\n",
    "\n",
    "def load(model, optimizer, check_point_name):\n",
    "    checkpoint = torch.load(check_point_name)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OG2yNubVPKBM"
   },
   "outputs": [],
   "source": [
    "# Use GPU if GPU is available \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, D_in, H):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.fc = torch.nn.Linear(D_in, H)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.gru = nn.GRU(H, int(H/2), bidirectional=True, batch_first=True)\n",
    "\n",
    "    def forward(self, input_tensor):\n",
    "        # (B, T, F)\n",
    "        output_tensor = self.fc(input_tensor)\n",
    "        output_tensor = self.relu(output_tensor)\n",
    "        output_tensor = self.dropout(output_tensor)\n",
    "        # (B, T, H)\n",
    "        output_tensor, _ = self.gru(output_tensor)\n",
    "        return output_tensor\n",
    "    \n",
    "class CTC_Decoder(nn.Module):\n",
    "    def __init__(self, H, D_out, num_chars):\n",
    "        super(CTC_Decoder, self).__init__()\n",
    "        self.fc_embed = nn.Linear(H, H)\n",
    "        self.relu_embed = torch.nn.ReLU()\n",
    "        self.dropout_embed = nn.Dropout(p=0.5) \n",
    "        self.gru = nn.GRU(H, D_out, batch_first=True)\n",
    "        self.fc = nn.Linear(D_out, num_chars)\n",
    "        self.log_softmax = nn.LogSoftmax(dim=2)\n",
    "\n",
    "    def forward(self, input_tensor):\n",
    "        # (B, T, 2 * H/2)\n",
    "        output_tensor = self.fc_embed(input_tensor)\n",
    "        output_tensor = self.relu_embed(output_tensor)\n",
    "        output_tensor = self.dropout_embed(output_tensor) \n",
    "        # (B, T, H)\n",
    "        output_tensor,_ = self.gru(input_tensor)\n",
    "        # (B, T, H)\n",
    "        output_tensor = self.fc(output_tensor)\n",
    "        # (B, T, 75)\n",
    "        prediction_tensor = self.log_softmax(output_tensor)\n",
    "\n",
    "        return prediction_tensor\n",
    "\n",
    "class Mel2SeqNet(nn.Module):\n",
    "    def __init__(self, D_in, H, D_out, num_chars, device):\n",
    "        super(Mel2SeqNet, self).__init__()\n",
    "        \n",
    "        self.encoder = Encoder(D_in, H).to(device)\n",
    "        self.decoder = CTC_Decoder(H, D_out, num_chars).to(device)\n",
    "        \n",
    "        # Initialize weights with random uniform numbers with range\n",
    "        for param in self.encoder.parameters():\n",
    "            param.data.uniform_(-0.1, 0.1)\n",
    "        for param in self.decoder.parameters():\n",
    "            param.data.uniform_(-0.1, 0.1)\n",
    "            \n",
    "    def forward(self, input_tensor):\n",
    "        batch_size = input_tensor.shape[0]\n",
    "        # (B, T, F) -> (B, T, H)\n",
    "        encoded_tensor = self.encoder(input_tensor)\n",
    "        # (B, T, H) -> (B, T, 75)\n",
    "        pred_tensor = self.decoder(encoded_tensor)\n",
    "        pred_tensor = pred_tensor.permute(1, 0, 2)\n",
    "        \n",
    "        return pred_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that interprets the CTC prediction result\n",
    "\n",
    "def Decode_CTC_Prediction(prediction):\n",
    "    CTC_pred = prediction.detach().cpu().numpy()\n",
    "    result = list()\n",
    "    last_elem = 0\n",
    "    for i, elem in enumerate(CTC_pred):\n",
    "        if elem != last_elem and elem != 0:\n",
    "            result.append(elem)\n",
    "        \n",
    "        last_elem = elem\n",
    "\n",
    "    result = np.asarray(result)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def label_to_string(labels):\n",
    "#     if len(labels.shape) == 1:\n",
    "#         sent = str()\n",
    "#         for i in labels:\n",
    "#             if i.item() == EOS_token:\n",
    "#                 break\n",
    "#             sent += index2char[i.item()]\n",
    "#         return sent\n",
    "\n",
    "#     elif len(labels.shape) == 2:\n",
    "#         sents = list()\n",
    "#         for i in labels:\n",
    "#             sent = str()\n",
    "#             for j in i:\n",
    "#                 if j.item() == EOS_token:\n",
    "#                     break\n",
    "#                 sent += index2char[j.item()]\n",
    "#             sents.append(sent)\n",
    "\n",
    "#         return sents\n",
    "    \n",
    "def lev_num_to_lev_string(lev_num_list, index2char):\n",
    "    lev_str_list = list()\n",
    "    for num_list in lev_num_list:\n",
    "        \n",
    "        temp = list()\n",
    "        for num in num_list:\n",
    "            temp.append(index2char[num])\n",
    "        \n",
    "        lev_str_list.append(''.join(temp))\n",
    "\n",
    "    return lev_str_list\n",
    "\n",
    "def char_distance(ref, hyp):\n",
    "    ref = ref.replace(' ', '') \n",
    "    hyp = hyp.replace(' ', '') \n",
    "\n",
    "    dist = Lev.distance(hyp, ref)\n",
    "    length = len(ref.replace(' ', ''))\n",
    "\n",
    "    return dist, length \n",
    "\n",
    "def char_distance_list(ref_list, hyp_list):\n",
    "\n",
    "    sum_dist = 0\n",
    "    sum_length = 0\n",
    "    \n",
    "    for ref, hyp in zip(ref_list, hyp_list):\n",
    "        dist, length = char_distance(ref, hyp)\n",
    "        sum_dist += dist\n",
    "        sum_length += length\n",
    "\n",
    "    return sum_dist, sum_length \n",
    "\n",
    "# def get_distance(ref_labels, hyp_labels, display=False):\n",
    "#     total_dist = 0\n",
    "#     total_length = 0\n",
    "#     for i in range(len(ref_labels)):\n",
    "#         ref = label_to_string(ref_labels[i])\n",
    "#         hyp = label_to_string(hyp_labels[i])\n",
    "#         dist, length = char_distance(ref, hyp)\n",
    "#         total_dist += dist\n",
    "#         total_length += length \n",
    "#         if display:\n",
    "#             cer = total_dist / total_length\n",
    "#             print('%d (%0.4f)\\n(%s)\\n(%s)' % (i, cer, ref, hyp))\n",
    "#     return total_dist, total_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def c2i_decoding(c2i, sentence):\n",
    "#     tokens = list()\n",
    "#     for char in sentence:\n",
    "#         try:\n",
    "#             tokens.append(c2i[char])   \n",
    "#         except:\n",
    "# #             print(char)\n",
    "#             pass\n",
    "#     return tokens\n",
    "\n",
    "def Decode_Prediction(pred_tensor, tokenizer, char2index):\n",
    "    decoded_list = list()\n",
    "    for i in range(pred_tensor.shape[1]):\n",
    "        _, CTC_index = pred_tensor[:, i, :].max(-1)\n",
    "        index = Decode_CTC_Prediction(CTC_index)\n",
    "        jamos = tokenizer.num2word(index)\n",
    "        sentence = jamotools.join_jamos(''.join(jamos))\n",
    "        \n",
    "        not_com_jamo = re.compile(u'[^\\u3130-\\u3190]')\n",
    "        filtered_sentence = ''.join(not_com_jamo.findall(sentence))\n",
    "        filtered_sentence = filtered_sentence.replace('<s>', '')\n",
    "        filtered_sentence = filtered_sentence.replace('</s>', '')\n",
    "#         filtered_sentence = filtered_sentence.replace('<eos>', '')\n",
    "#         final_prediction = c2i_decoding(char2index, filtered_sentence)\n",
    "        \n",
    "        decoded_list.append(filtered_sentence)\n",
    "    return decoded_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "Y9t1zv6cHp7y",
    "outputId": "e08fd2c2-ea3e-4479-e4c6-fe6dbe4e2a7a",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "EPOCH = 12 * 6     \n",
    "           \n",
    "# net = Mel2SeqNet(80, 512, 256)\n",
    "\n",
    "net = Mel2SeqNet(80, 1024, 512, len(unicode_jamo_list), device)\n",
    "\n",
    "net_optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "ctc_loss = nn.CTCLoss().to(device)\n",
    "\n",
    "keyword = 'NSML_100ms'\n",
    "\n",
    "train_loss_history = list()\n",
    "eval_loss_history = list()\n",
    "\n",
    "train_cer_history = list()\n",
    "eval_cer_history = list()\n",
    "\n",
    "try:\n",
    "    train_cer_history = list(np.load('model_saved/train_cer_history{}.npy'.format(keyword)))\n",
    "    eval_cer_history = list(np.load('model_saved/eval_cer_history{}.npy'.format(keyword)))\n",
    "except:\n",
    "    print(\"No CER Record\")\n",
    "\n",
    "try:\n",
    "    load(net, net_optimizer, 'model_saved/{}'.format(keyword))\n",
    "    train_loss_history = list(np.load('model_saved/train_loss_history_{}.npy'.format(keyword)))\n",
    "    eval_loss_history = list(np.load('model_saved/eval_loss_history_{}.npy'.format(keyword)))\n",
    "except:\n",
    "    print(\"Loading {} Error\".format(keyword))\n",
    "\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "\n",
    "    print((datetime.now().strftime('%m-%d %H:%M:%S')))\n",
    "\n",
    "    preloader_train.initialize_batch(num_thread)\n",
    "    loss_list_train = list()\n",
    "\n",
    "    total_dist = 0\n",
    "    total_length = 0\n",
    "#     count = 0\n",
    "    while preloader_train.end_flag == False:\n",
    "        batch = preloader_train.get_batch()\n",
    "        # logger.info(\"Got Batch\")\n",
    "        if batch != None:\n",
    "            tensor_input, ground_truth, loss_mask, length_list, lev_truth_list = batch\n",
    "            pred_tensor, loss = train(net, net_optimizer, ctc_loss, tensor_input.to(device),\n",
    "                                      ground_truth.to(device), loss_mask.to(device), length_list.to(device))\n",
    "            loss_list_train.append(loss)\n",
    "            \n",
    "            lev_pred_list = Decode_Prediction(pred_tensor, tokenizer, char2index)\n",
    "            lev_str_list = lev_num_to_lev_string(lev_truth_list, index2char)\n",
    "            dist, length = char_distance_list(lev_str_list, lev_pred_list)\n",
    "            total_dist += dist\n",
    "            total_length += length\n",
    "            \n",
    "#             print(\"Loss: {}\".format(loss))\n",
    "#             count += 1\n",
    "#             print(\"Train {}/{}\".format(count, int(np.ceil(len(wav_path_list_train)/batch_size))))\n",
    "#             # logger.info(\"Training\")\n",
    "\n",
    "    train_cer = total_dist / total_length\n",
    "    train_loss = np.mean(np.asarray(loss_list_train))\n",
    "    print((datetime.now().strftime('%m-%d %H:%M:%S')))\n",
    "    print(\"Mean Train Loss: {}\".format(train_loss))\n",
    "    print(\"Train CER: {}\".format(train_cer))\n",
    "    train_loss_history.append(train_loss)\n",
    "    train_cer_history.append(train_cer)\n",
    "    \n",
    "    preloader_eval.initialize_batch(num_thread)\n",
    "    loss_list_eval = list()\n",
    "\n",
    "    total_dist = 0\n",
    "    total_length = 0\n",
    "    \n",
    "    while preloader_eval.end_flag == False:\n",
    "        batch = preloader_eval.get_batch()\n",
    "        if batch != None:\n",
    "            tensor_input, ground_truth_, loss_mask, length_list, lev_truth_list_ = batch\n",
    "            pred_tensor_, loss = evaluate(net, ctc_loss, tensor_input.to(device), ground_truth_.to(device),\n",
    "                                          loss_mask.to(device), length_list.to(device))\n",
    "            loss_list_eval.append(loss)\n",
    "            \n",
    "            lev_pred_list = Decode_Prediction(pred_tensor_, tokenizer, char2index)\n",
    "            lev_str_list = lev_num_to_lev_string(lev_truth_list_, index2char)\n",
    "            dist, length = char_distance_list(lev_str_list, lev_pred_list)\n",
    "            total_dist += dist\n",
    "            total_length += length\n",
    "            \n",
    "    eval_cer = total_dist / total_length\n",
    "    eval_loss = np.mean(np.asarray(loss_list_eval))\n",
    "    print((datetime.now().strftime('%m-%d %H:%M:%S')))\n",
    "    print(\"Mean Evaluation Loss: {}\".format(eval_loss))\n",
    "    print(\"Evaluation CER: {}\".format(eval_cer))\n",
    "    eval_loss_history.append(eval_loss)\n",
    "    eval_cer_history.append(eval_cer)\n",
    "    \n",
    "    #####\n",
    "    \n",
    "    save(net, net_optimizer, 'model_saved/{}'.format(keyword))\n",
    "    np.save('model_saved/train_loss_history_{}'.format(keyword), train_loss_history)\n",
    "    np.save('model_saved/eval_loss_history_{}'.format(keyword), eval_loss_history)\n",
    "    np.save('model_saved/train_cer_history{}'.format(keyword), train_cer_history)\n",
    "    np.save('model_saved/eval_cer_history{}'.format(keyword), eval_cer_history)\n",
    "            \n",
    "    #####    \n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(train_loss_history)\n",
    "    plt.plot(eval_loss_history)\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(train_cer_history)\n",
    "    plt.plot(eval_cer_history)\n",
    "    plt.show()\n",
    "\n",
    "    # index is the position of the max probility of the first batch\n",
    "    # Shape of the pred_tensor: (T, B, 75)\n",
    "    # Shape of the index: (T)\n",
    "    _, index = pred_tensor[:, 0, :].max(-1)\n",
    "\n",
    "    # Change index numbers to character\n",
    "    sentence = tokenizer.num2word(index.view(-1))\n",
    "\n",
    "    # Change list to string\n",
    "    print(''.join(sentence))\n",
    "\n",
    "    # Remove \"blank\" and overlapping characters\n",
    "    index_ = Decode_CTC_Prediction(index)\n",
    "    sentence_ = tokenizer.num2word(index_)\n",
    "    print(''.join(sentence_))\n",
    "\n",
    "    true_sentence = tokenizer.num2word(ground_truth[0, :].detach().numpy().astype(int))\n",
    "    print(''.join(true_sentence))\n",
    "\n",
    "    # Plot image\n",
    "    # detach().cpu().numpy() transforms a tensor on gpu into a numpy matrix\n",
    "    plt.figure()\n",
    "    plt.imshow(pred_tensor[:, 0, :].detach().cpu().numpy())\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "\n",
    "    _, index = pred_tensor_[:, 0, :].max(-1)\n",
    "\n",
    "    sentence = tokenizer.num2word(index.view(-1))\n",
    "    print(''.join(sentence))\n",
    "    index_ = Decode_CTC_Prediction(index)\n",
    "    sentence_ = tokenizer.num2word(index_)\n",
    "    print(''.join(sentence_))\n",
    "    true_sentence = tokenizer.num2word(ground_truth_[0, :].detach().numpy().astype(int))\n",
    "    print(''.join(true_sentence))\n",
    "\n",
    "    plt.figure()\n",
    "    plt.imshow(pred_tensor_[:, 0, :].detach().cpu().numpy())\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "        \n",
    "    print(\"-------------------------------------------------------------------------------------------------------\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "CTC_best_result_on_Colab.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
