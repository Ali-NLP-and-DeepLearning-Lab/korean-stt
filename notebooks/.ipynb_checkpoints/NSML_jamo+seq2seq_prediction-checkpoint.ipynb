{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lNy2clEZPKAv"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa # librosa: Audio handling package\n",
    "import random\n",
    "import copy\n",
    "import re\n",
    "import jamotools\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm # tqdm: Pakage for progress bar visualization\n",
    "from datetime import datetime\n",
    "\n",
    "import threading\n",
    "import queue\n",
    "\n",
    "import Levenshtein as Lev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "SBaEfy86PKA1",
    "outputId": "4cde26f5-f3e4-4589-871e-e204684d376e"
   },
   "outputs": [],
   "source": [
    "n_mels = 80\n",
    "fs = 16000\n",
    "frame_length_ms=100\n",
    "frame_shift_ms=50\n",
    "nsc = int(fs * frame_length_ms / 1000)\n",
    "nov = nsc - int(fs * frame_shift_ms / 1000)\n",
    "nhop = int(fs * frame_shift_ms / 1000)\n",
    "eps = 1e-8\n",
    "db_ref = 160\n",
    "\n",
    "# meta_path = 'gdrive/My Drive/korean-single-speaker-speech-dataset/transcript.v.1.2.txt'\n",
    "# data_folder = 'gdrive/My Drive/korean-single-speaker-speech-dataset/kss'\n",
    "\n",
    "# meta_path = \"D:/korean-single-speaker-speech-dataset/transcript.v.1.2.txt\"\n",
    "# data_folder = \"D:/korean-single-speaker-speech-dataset/kss\"\n",
    "\n",
    "data_folder = \"D:/nsml-dataset/train_data/\"\n",
    "label_path = \"D:/nsml-dataset/hackathon.labels\"\n",
    "\n",
    "data_list = glob.glob(data_folder + '*.csv')[0]\n",
    "\n",
    "wav_paths = list()\n",
    "script_paths = list()\n",
    "korean_script_paths = list()\n",
    "\n",
    "with open(data_list, 'r') as f:\n",
    "    for line in f:\n",
    "        # line: \"aaa.wav,aaa.label\"\n",
    "        wav_path, script_path = line.strip().split(',')\n",
    "        korean_script_path = script_path.replace('.label', '.script')\n",
    "        \n",
    "        wav_paths.append(os.path.join(data_folder, wav_path))\n",
    "        script_paths.append(os.path.join(data_folder, script_path))\n",
    "        korean_script_paths.append(os.path.join(data_folder, korean_script_path))\n",
    "\n",
    "dataset_size = len(wav_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(filepath, bos_id, eos_id):\n",
    "    key = filepath.split('/')[-1].split('.')[0]\n",
    "    script = target_dict[key]\n",
    "    tokens = script.split(' ')\n",
    "    result = list()\n",
    "    result.append(bos_id)\n",
    "    for i in range(len(tokens)):\n",
    "        if len(tokens[i]) > 0:\n",
    "            result.append(int(tokens[i]))\n",
    "    result.append(eos_id)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wav_paths len: 29805\n",
      "script_paths len: 29805\n",
      "korean_script_paths len: 29805\n",
      "D:/nsml-dataset/train_data/41_0601_211_0_07930_02.wav\n",
      "D:/nsml-dataset/train_data/41_0601_211_0_07930_02.label\n",
      "D:/nsml-dataset/train_data/41_0601_211_0_07930_02.script\n"
     ]
    }
   ],
   "source": [
    "print(\"wav_paths len: {}\".format(len(wav_paths)))\n",
    "print(\"script_paths len: {}\".format(len(script_paths)))\n",
    "print(\"korean_script_paths len: {}\".format(len(korean_script_paths)))\n",
    "\n",
    "print(wav_paths[0])\n",
    "print(script_paths[0])\n",
    "print(korean_script_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(script_paths[1]) as f:\n",
    "    line = f.read()\n",
    "    line = line.strip()\n",
    "    result = list(map(int, line.split(' ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_label(label_path):\n",
    "    char2index = dict() # [ch] = id\n",
    "    index2char = dict() # [id] = ch\n",
    "    with open(label_path, 'r', encoding='UTF-8') as f:\n",
    "    # with open(label_path, 'r') as f:\n",
    "        for no, line in enumerate(f):\n",
    "            if line[0] == '#': \n",
    "                continue\n",
    "\n",
    "            index, char, freq = line.strip().split('\\t')\n",
    "            char = char.strip()\n",
    "            if len(char) == 0:\n",
    "                char = ' '\n",
    "\n",
    "            char2index[char] = int(index)\n",
    "            index2char[int(index)] = char\n",
    "\n",
    "    return char2index, index2char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "char2index, index2char = load_label(label_path)\n",
    "SOS_token = char2index['<s>']  # '<sos>' or '<s>'\n",
    "EOS_token = char2index['</s>']  # '<eos>' or '</s>'\n",
    "PAD_token = char2index['_']  # '-' or '_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f0eeabfb4344f7a807b3d62f7c3357d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=29805), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예약하고 싶은데 어떻게 해야하나요?\n",
      "예약하고 싶은데 어떻게 해야하나요?\n",
      "이 카드로 할인 되나요?\n",
      "이 카드로 할인 되나요?\n",
      "오늘 점심때 예약 가능한가요?\n",
      "오늘 점심때 예약 가능한가요?\n",
      "내일 오후 여덟시에 예약 가능할까요?\n",
      "내일 오후 여덟시에 예약 가능할까요?\n",
      "주차 공간이 좁던데 지금 주차 가능한가요?\n",
      "주차 공간이 좁던데 지금 주차 가능한가요?\n",
      "아웃백에 가려면 지하철 몇 번 출구로 나와야 하나요?\n",
      "아웃백에 가려면 지하철 몇 번 출구로 나와야 하나요?\n",
      "생일 할인 되나요?\n",
      "생일 할인 되나요?\n",
      "저기 부쉬맨빵 4개 정도 더 주시고 스테이크 소스도 좀 더 주실 수 있나요?\n",
      "저기 부쉬맨빵 *개 정도 더 주시고 스테이크 소스도 좀 더 주실 수 있나요?\n",
      "런치타임에 할인 되는 메뉴는 어떤게 잇조?\n",
      "런치타임에 할인 되는 메뉴는 어떤게 잇조?\n",
      "앙웃백 경남에도 있나요?\n",
      "앙웃백 경남에도 있나요?\n",
      "학생할인이 있나요?\n",
      "학생할인이 있나요?\n",
      "점장님 출근하셨으면 통화가능할까요?\n",
      "점장님 출근하셨으면 통화가능할까요?\n",
      "투움바 안심 파스타 2개 베이비백립 3개 감자튀김 2개요.\n",
      "투움바 안심 파스타 *개 베이비백립 *개 감자튀김 *개요.\n",
      "몇시까지 해요?\n",
      "몇시까지 해요?\n",
      "아기가 먹을 수 있는 음식이 있나요?\n",
      "아기가 먹을 수 있는 음식이 있나요?\n",
      "내일 찾아가려고 하는데 몇 시까지 영업하나요?\n",
      "내일 찾아가려고 하는데 몇 시까지 영업하나요?\n",
      "주차를 무료로 이용할 수 있나요?\n",
      "주차를 무료로 이용할 수 있나요?\n",
      "단체석 있어요?\n",
      "단체석 있어요?\n",
      "아웃백에서 카드 할인을 가능한 많이 받고 싶습니다.\n",
      "아웃백에서 카드 할인을 가능한 많이 받고 싶습니다.\n",
      "몇시에 마감인가요?\n",
      "몇시에 마감인가요?\n",
      "현재 자리 있는지 확인 가능한가요?\n",
      "현재 자리 있는지 확인 가능한가요?\n",
      "단체할인을 받고 또 다른 멤버십 할인을 받을 수 있나요?\n",
      "단체할인을 받고 또 다른 멤버십 할인을 받을 수 있나요?\n",
      "케익도 파나요\n",
      "케익도 파나요\n",
      "아웃백제휴카드는 없나요?\n",
      "아웃백제휴카드는 없나요?\n",
      "성인 10명 어린이 5명 모임 가지려는데 추천 세트 메뉴 있나요?\n",
      "성인 *명 어린이 *명 모임 가지려는데 추천 세트 메뉴 있나요?\n",
      "버스 어느 역에서 내리면되나요?\n",
      "버스 어느 역에서 내리면되나요?\n",
      "오픈했는지요?\n",
      "오픈했는지요?\n",
      "이번 달은 언제 언제 쉬어요?\n",
      "이번 달은 언제 언제 쉬어요?\n",
      "아이 셋이랑 같이 갈건데 테이블이 있을까요?\n",
      "아이 셋이랑 같이 갈건데 테이블이 있을까요?\n",
      "투움바 파스타도 두 종류라는데 어떤 거 있어요?\n",
      "투움바 파스타도 두 종류라는데 어떤 거 있어요?\n",
      "모든 메뉴가 다 배달 가능할까요?\n",
      "모든 메뉴가 다 배달 가능할까요?\n",
      "할인카드는 무엇있나요?\n",
      "할인카드는 무엇있나요?\n",
      "예약은 몇일 전부터 가능한가요?\n",
      "예약은 몇일 전부터 가능한가요?\n",
      "보통 몇 시에 여세요?\n",
      "보통 몇 시에 여세요?\n",
      "전화로 예약 돼죠?\n",
      "전화로 예약 돼죠?\n",
      "같이 오는 일행이 주차가 서툰데 발레파킹 가능한가요?\n",
      "같이 오는 일행이 주차가 서툰데 발레파킹 가능한가요?\n",
      "단체는 몇명부터 가능한거죠?\n",
      "단체는 몇명부터 가능한거죠?\n",
      "혹시 할인되는 제휴 카드 뭐 있어요?\n",
      "혹시 할인되는 제휴 카드 뭐 있어요?\n",
      "아! 그렇군요. 그럼 다음에 다시 주문할께요.\n",
      "아! 그렇군요. 그럼 다음에 다시 주문할께요.\n",
      "제휴카드 중복할인 되나요?\n",
      "제휴카드 중복할인 되나요?\n",
      "내일 예약 취소 되나요?\n",
      "내일 예약 취소 되나요?\n",
      "예약이 당일 취소도 가능한가요?\n",
      "예약이 당일 취소도 가능한가요?\n",
      "아웃백 매장마다 메뉴가 다 똑같나요?\n",
      "아웃백 매장마다 메뉴가 다 똑같나요?\n",
      "미리 주문해놔도 되나요?\n",
      "미리 주문해놔도 되나요?\n",
      "네. 그럼 제가 다시 연락은 안드려도 되는 거죠?\n",
      "네. 그럼 제가 다시 연락은 안드려도 되는 거죠?\n",
      "가격은 매장 가격과 동일한 가요?\n",
      "가격은 매장 가격과 동일한 가요?\n",
      "매장 바닥에 음료수를 흘려서 그런지 끈적거리네요\n",
      "매장 바닥에 음료수를 흘려서 그런지 끈적거리네요\n",
      "몇시부터 몇시까지죠?\n",
      "몇시부터 몇시까지죠?\n",
      "예약한 날짜에 제 핸드폰으로 예약 시간을 한번 더 보내주실수 있나요?\n",
      "예약한 날짜에 제 핸드폰으로 예약 시간을 한번 더 보내주실수 있나요?\n",
      "20명 단체 예약자리있나요?\n",
      "*명 단체 예약자리있나요?\n",
      "통신사 할인 최대 금액이 얼마죠?\n",
      "통신사 할인 최대 금액이 얼마죠?\n",
      "도시락 같은 메뉴도 있나요?\n",
      "도시락 같은 메뉴도 있나요?\n",
      "발렛파킹은 얼마인가요?\n",
      "발렛파킹은 얼마인가요?\n",
      "베이비 백립 메뉴는 몇 인 용인가요?\n",
      "베이비 백립 메뉴는 몇 인 용인가요?\n",
      "아기의자에 벨트가 부착되어져 있을까요?\n",
      "아기의자에 벨트가 부착되어져 있을까요?\n",
      "오늘 예약 이번주 토요일로 변경가능한가요?\n",
      "오늘 예약 이번주 토요일로 변경가능한가요?\n",
      "파스타 가격이 어떻게 되죠?\n",
      "파스타 가격이 어떻게 되죠?\n",
      "주차요금은 따로 받나요\n",
      "주차요금은 따로 받나요\n",
      "어디까지 배달가능하나요?\n",
      "어디까지 배달가능하나요?\n",
      "가장 안쪽에 있는 자리 예약가능한가요?\n",
      "가장 안쪽에 있는 자리 예약가능한가요?\n",
      "혹시 예약자리가 나면 전화좀 주실 수 있으세요?\n",
      "혹시 예약자리가 나면 전화좀 주실 수 있으세요?\n",
      "네명이 차 두 대를 주차해도 되나요?\n",
      "네명이 차 두 대를 주차해도 되나요?\n",
      "추석에도 영업 시간 똑같아요?\n",
      "추석에도 영업 시간 똑같아요?\n",
      "가족 모임을 위한 방이 따로 있나요?\n",
      "가족 모임을 위한 방이 따로 있나요?\n",
      "여기 브레이크 타임이 언제죠~?\n",
      "여기 브레이크 타임이 언제죠*?\n",
      "피자에 과일 들어가나요?\n",
      "피자에 과일 들어가나요?\n",
      "창가 자리 예약 가능 한가요?\n",
      "창가 자리 예약 가능 한가요?\n",
      "예약 시간보다 일찍 도착하면 기다려야하나요?\n",
      "예약 시간보다 일찍 도착하면 기다려야하나요?\n",
      "웨이팅 있나요?\n",
      "웨이팅 있나요?\n",
      "창가 자리로 예약해주세요.\n",
      "창가 자리로 예약해주세요.\n",
      "영업시간이 바뀌었내요~?\n",
      "영업시간이 바뀌었내요*?\n",
      "블랙라벨 스테이크 아직도 판매해요?\n",
      "블랙라벨 스테이크 아직도 판매해요?\n",
      "지금 가고 있는데 예약할 수 있나요?\n",
      "지금 가고 있는데 예약할 수 있나요?\n",
      "식사시 영수증 제시하면 주차비는 무료인가요?\n",
      "식사시 영수증 제시하면 주차비는 무료인가요?\n",
      "최근 새로 나온 메뉴가 있나요?\n",
      "최근 새로 나온 메뉴가 있나요?\n",
      "여름인데 빙수류 디저트 있을까요?\n",
      "여름인데 빙수류 디저트 있을까요?\n",
      "런치메뉴는 런치시간에 배달가능하나요?\n",
      "런치메뉴는 런치시간에 배달가능하나요?\n",
      "오늘 6시에 10명 예약 되나요?\n",
      "오늘 *시에 *명 예약 되나요?\n",
      "할인 카드 뭐가 되나요?\n",
      "할인 카드 뭐가 되나요?\n",
      "토요일에 단체 예약 되나요?\n",
      "토요일에 단체 예약 되나요?\n",
      "예약안하고 방문해도 되나요?\n",
      "예약안하고 방문해도 되나요?\n",
      "몇 시 오픈인가요?\n",
      "몇 시 오픈인가요?\n",
      "행사 쿠폰을 사용해서 배달 할 수 있는 메뉴가 어떤게 있나요?\n",
      "행사 쿠폰을 사용해서 배달 할 수 있는 메뉴가 어떤게 있나요?\n",
      "4명 저녁 예약하고 싶어서요\n",
      "*명 저녁 예약하고 싶어서요\n",
      "역에서 얼마나 걸리나요?\n",
      "역에서 얼마나 걸리나요?\n",
      "케이크 가지고 방문해도 될까요?\n",
      "케이크 가지고 방문해도 될까요?\n",
      "예약 좀 하려고 하는데요\n",
      "예약 좀 하려고 하는데요\n",
      "투움바 파스타 하나만 배달해주세요.\n",
      "투움바 파스타 하나만 배달해주세요.\n",
      "생일인 사람에게 제공되는 쿠폰이 있나요?\n",
      "생일인 사람에게 제공되는 쿠폰이 있나요?\n",
      "석촌호수요.\n",
      "석촌호수요.\n",
      "아웃백 위치가 어떻게 되나요?\n",
      "아웃백 위치가 어떻게 되나요?\n",
      "아..그럼 그냥 예약 취소해주세요.\n",
      "아..그럼 그냥 예약 취소해주세요.\n",
      "1분만 기다려주세요.\n",
      "*분만 기다려주세요.\n",
      "중복 할인 가능한 경우가 있나요?\n",
      "중복 할인 가능한 경우가 있나요?\n",
      "이번주 주말 6시 4명 예약하려고 하는데 가능한가요?\n",
      "이번주 주말 *시 *명 예약하려고 하는데 가능한가요?\n",
      "주중과 주말 런치 메뉴 구성이 다른가요?\n",
      "주중과 주말 런치 메뉴 구성이 다른가요?\n",
      "혹시 주차공간이 충분히 있나요\n",
      "혹시 주차공간이 충분히 있나요\n",
      "내일 저녁 6시 예약 가능한가요?\n",
      "내일 저녁 *시 예약 가능한가요?\n",
      "어르신들이 좋아할 만한 메뉴가 있나요?\n",
      "어르신들이 좋아할 만한 메뉴가 있나요?\n",
      "데리야끼치킨라이스 미리 예약할 수 있나요?\n",
      "데리야끼치킨라이스 미리 예약할 수 있나요?\n",
      "아기 돌잔치를 할 장소를 찾고 있어요 아웃백에서 돌잔치 서비스를 제공하나요?\n",
      "아기 돌잔치를 할 장소를 찾고 있어요 아웃백에서 돌잔치 서비스를 제공하나요?\n",
      "1호선으로 가는방법이있나요?\n",
      "*호선으로 가는방법이있나요?\n",
      "죄송한데 예약 변경좀 가능할까요?\n",
      "죄송한데 예약 변경좀 가능할까요?\n",
      "찾아가려고 하는데 대중교통은 어떤걸 이용해야하나요?\n",
      "찾아가려고 하는데 대중교통은 어떤걸 이용해야하나요?\n",
      "예약할 때 혹시 선불해야하나요?\n",
      "예약할 때 혹시 선불해야하나요?\n",
      "아웃백 보라매에 있는 것 맞나요?\n",
      "아웃백 보라매에 있는 것 맞나요?\n",
      "할인과 포인트를 중복혜택가능한가요?\n",
      "할인과 포인트를 중복혜택가능한가요?\n",
      "다시말해주실래요?\n",
      "다시말해주실래요?\n",
      "어르신들에게 추천할 메뉴 있나요?\n",
      "어르신들에게 추천할 메뉴 있나요?\n",
      "8시에 예약 되나요?\n",
      "*시에 예약 되나요?\n",
      "쉬는 날이 언제죠?\n",
      "쉬는 날이 언제죠?\n",
      "죄송합니다 다시 말해주세요\n",
      "죄송합니다 다시 말해주세요\n",
      "당일 예약이 가능한가요?\n",
      "당일 예약이 가능한가요?\n",
      "할인 받은게 그거?\n",
      "할인 받은게 그거?\n",
      "영업은 몇시에 끝나요?\n",
      "영업은 몇시에 끝나요?\n",
      "제휴 할인 카드에 어떤게 있는지 궁금해서요.\n",
      "제휴 할인 카드에 어떤게 있는지 궁금해서요.\n",
      "하우스와인도 있는지 궁금해서 전화드렸습니다?\n",
      "하우스와인도 있는지 궁금해서 전화드렸습니다?\n",
      "예약 가능한가요?\n",
      "예약 가능한가요?\n",
      "금요일 오후 9시에 주문되나요?\n",
      "금요일 오후 *시에 주문되나요?\n",
      "오늘 영업 시간이 언제부터인가요?\n",
      "오늘 영업 시간이 언제부터인가요?\n",
      "크리스마스에 쉬나요?\n",
      "크리스마스에 쉬나요?\n",
      "생일 할인이랑 멤버십이랑 같이 쓸 수 있어요?\n",
      "생일 할인이랑 멤버십이랑 같이 쓸 수 있어요?\n",
      "연말 모임에서 먹을 배달메뉴 뭐가 있을까요?\n",
      "연말 모임에서 먹을 배달메뉴 뭐가 있을까요?\n",
      "몇시부터 몇시까지 오픈하나요?\n",
      "몇시부터 몇시까지 오픈하나요?\n",
      "런치 세트 주문 가능한 시간이 언제인가요?\n",
      "런치 세트 주문 가능한 시간이 언제인가요?\n",
      "주차비 유로면 얼마인가요?\n",
      "주차비 유로면 얼마인가요?\n",
      "지금 아기안고 들어가는 3명 보이는데 거기 맞나요?\n",
      "지금 아기안고 들어가는 *명 보이는데 거기 맞나요?\n",
      "영업 안하는 날 있나요?\n",
      "영업 안하는 날 있나요?\n",
      "혹시 당일 예약 취소 가능하면 전화나 문자해주실 수 있나요?\n",
      "혹시 당일 예약 취소 가능하면 전화나 문자해주실 수 있나요?\n",
      "지난주말 카운터에 계시던 직원과 통화 가능한가요?\n",
      "지난주말 카운터에 계시던 직원과 통화 가능한가요?\n",
      "스테이크 제일 싼게 얼마인가요?\n",
      "스테이크 제일 싼게 얼마인가요?\n",
      "창가자리로 예약이 가능한가요?\n",
      "창가자리로 예약이 가능한가요?\n",
      "군인 할인 있나요?\n",
      "군인 할인 있나요?\n",
      "그럼 40분뒤에 찾으러 갈께요~\n",
      "그럼 *분뒤에 찾으러 갈께요*\n",
      "kt몇 %할인되죠?\n",
      "*몇 *할인되죠?\n",
      "창가자리도 따로 있나요?\n",
      "창가자리도 따로 있나요?\n",
      "이번주 금요일 아이1명과 어른2명 김은지로 예약해주세요.\n",
      "이번주 금요일 아이*명과 어른*명 김은지로 예약해주세요.\n",
      "주차도장은 몇시까지 유효한가요?\n",
      "주차도장은 몇시까지 유효한가요?\n",
      "혹시 아침 10시에도 영업 하나요?\n",
      "혹시 아침 *시에도 영업 하나요?\n",
      "아기가 먹을수있는 메뉴가 있나요?\n",
      "아기가 먹을수있는 메뉴가 있나요?\n",
      "몇시부터 몇시까지 해요?\n",
      "몇시부터 몇시까지 해요?\n",
      "오늘 식사가능한가요?\n",
      "오늘 식사가능한가요?\n",
      "프로스팅 커스터마이징 되나요?\n",
      "프로스팅 커스터마이징 되나요?\n",
      "이번주 토요일에 점심 예약 가능한가요?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이번주 토요일에 점심 예약 가능한가요?\n",
      "일요일에도 정상 영업 하시죠?\n",
      "일요일에도 정상 영업 하시죠?\n",
      "어린이날 아이랑 밥을 먹을려고 하는데 가능한가요?\n",
      "어린이날 아이랑 밥을 먹을려고 하는데 가능한가요?\n",
      "유성구청에서 버스 타고 아웃백에 갈 수 있나요?\n",
      "유성구청에서 버스 타고 아웃백에 갈 수 있나요?\n",
      "점심 1시쯤 이요.\n",
      "점심 *시쯤 이요.\n",
      "삼성카드 할인 돼요?\n",
      "삼성카드 할인 돼요?\n",
      "아~ 혹시 시간도 2시반으로 변경 부탁드려요~\n",
      "아* 혹시 시간도 *시반으로 변경 부탁드려요*\n",
      "몇시부터 오픈하나요?\n",
      "몇시부터 오픈하나요?\n",
      "비건 전용 메뉴가 있나요?\n",
      "비건 전용 메뉴가 있나요?\n",
      "어린이 할인이랑 생일할인 동시에 할인받을수있나요~?\n",
      "어린이 할인이랑 생일할인 동시에 할인받을수있나요*?\n",
      "아 그럼 포장 되나요? 제가 찾으러 갈께요.\n",
      "아 그럼 포장 되나요? 제가 찾으러 갈께요.\n",
      "몇시부터 몇시까지에요?\n",
      "몇시부터 몇시까지에요?\n",
      "스테이크 2인분 배달해주세요\n",
      "스테이크 *인분 배달해주세요\n",
      "lg카드 할인 되나요?\n",
      "*카드 할인 되나요?\n",
      "할인카드 어떤카드가 되죠?\n",
      "할인카드 어떤카드가 되죠?\n",
      "좀 느끼한 게 끌리는데 기름지고 느끼한 파스타 추천해주시겠어요?\n",
      "좀 느끼한 게 끌리는데 기름지고 느끼한 파스타 추천해주시겠어요?\n",
      "할인되는 제휴 카드 종류 뭐 있어요?\n",
      "할인되는 제휴 카드 종류 뭐 있어요?\n",
      "콩에 알러지가 있는데 그건 빼고 주문가능할까요? 지금 1월에 할인하거나 추천하는 메뉴는 뭐가 있어요? 사이드 메뉴 바꿀수 있나요? 스테이크 고기는 냉동인가요? 냉장인가요?\n",
      "콩에 알러지가 있는데 그건 빼고 주문가능할까요? 지금 *월에 할인하거나 추천하는 메뉴는 뭐가 있어요? 사이드 메뉴 바꿀수 있나요? 스테이크 고기는 냉동인가요? 냉장인가요?\n",
      "주차할 수 있는 공간이 따로 있나요?\n",
      "주차할 수 있는 공간이 따로 있나요?\n",
      "어린이 할인은 몇 살까지 가능한가요?\n",
      "어린이 할인은 몇 살까지 가능한가요?\n",
      "돌아오는 수요일 오후 4시 15분에 8명 룸으로 예약 가능한가요?\n",
      "돌아오는 수요일 오후 *시 *분에 *명 룸으로 예약 가능한가요?\n",
      "알뜰폰통신사도 할인되나요?\n",
      "알뜰폰통신사도 할인되나요?\n",
      "좌석 지정 예약이 가능하다면 알려주실 수 있나요?\n",
      "좌석 지정 예약이 가능하다면 알려주실 수 있나요?\n",
      "어른들이 많이 찾는 메뉴 좀 알려 주세요\n",
      "어른들이 많이 찾는 메뉴 좀 알려 주세요\n",
      "오늘 예약 가능할까요?\n",
      "오늘 예약 가능할까요?\n",
      "넵 그럼  블랙라벨 커플세트에 투움바 파스타로 선택요\n",
      "넵 그럼  블랙라벨 커플세트에 투움바 파스타로 선택요\n",
      "센트럴시티 점도 주차 무료인가요?\n",
      "센트럴시티 점도 주차 무료인가요?\n",
      "베이비 백 립 먹고싶은데 오늘 다 팔렸나요?\n",
      "베이비 백 립 먹고싶은데 오늘 다 팔렸나요?\n",
      "발렌타인데이날 행사하는게 있나요?\n",
      "발렌타인데이날 행사하는게 있나요?\n",
      "배달 가능한 메뉴가 따로 있나요?\n",
      "배달 가능한 메뉴가 따로 있나요?\n",
      "오랜만에 오는데 새로 적용되는 할인 이벤트가 있나요?\n",
      "오랜만에 오는데 새로 적용되는 할인 이벤트가 있나요?\n",
      "지금 토마호크 스테이크 파나요?\n",
      "지금 토마호크 스테이크 파나요?\n",
      "나이 드신 분들의 입맛에 맞는 메뉴가 있나요?\n",
      "나이 드신 분들의 입맛에 맞는 메뉴가 있나요?\n",
      "지금 식사를 하고싶은데 영업 중인가요?\n",
      "지금 식사를 하고싶은데 영업 중인가요?\n",
      "제가 아직 초보 운전인데 발레파킹있나요?\n",
      "제가 아직 초보 운전인데 발레파킹있나요?\n",
      "할인 카드는 어디서 알 수 있나요?\n",
      "할인 카드는 어디서 알 수 있나요?\n",
      "모바일 교환권을 선물 받았는데 사용 가능한가요?\n",
      "모바일 교환권을 선물 받았는데 사용 가능한가요?\n",
      "파스타 메뉴 포장되나요\n",
      "파스타 메뉴 포장되나요\n",
      "오늘 예약이 꽉 찼다고 하는데 혹시 비면 연락 좀 주실 수 있을까요?\n",
      "오늘 예약이 꽉 찼다고 하는데 혹시 비면 연락 좀 주실 수 있을까요?\n",
      "10시에 식사 가능할까요?\n",
      "*시에 식사 가능할까요?\n",
      "연세 있으신 어른들이 먹을만한 메뉴가 있나요?\n",
      "연세 있으신 어른들이 먹을만한 메뉴가 있나요?\n",
      "생일파티를 위한 메뉴가 있나요?\n",
      "생일파티를 위한 메뉴가 있나요?\n",
      "1인당 평균 비용이 어느정도 나오나요?\n",
      "*인당 평균 비용이 어느정도 나오나요?\n",
      "얼마나 기다려야 돼요?\n",
      "얼마나 기다려야 돼요?\n",
      "화장실에 기저귀가는 시설이 있나요?\n",
      "화장실에 기저귀가는 시설이 있나요?\n",
      "발렛 할 수 있나요?\n",
      "발렛 할 수 있나요?\n",
      "배달비가 따로 있다면 제가 포장주문했을 경우엔 할인이 있나요?\n",
      "배달비가 따로 있다면 제가 포장주문했을 경우엔 할인이 있나요?\n",
      "패밀리세트로 할께요.\n",
      "패밀리세트로 할께요.\n",
      "각 지점마다 영업시간이 다른가요?\n",
      "각 지점마다 영업시간이 다른가요?\n",
      "통신사 할인 정보 알려주실 수 있나요?\n",
      "통신사 할인 정보 알려주실 수 있나요?\n",
      "네 식사 예약을 하려고 하는데요.\n",
      "네 식사 예약을 하려고 하는데요.\n",
      "영업시간이 주말엔 어떻게 되죠?\n",
      "영업시간이 주말엔 어떻게 되죠?\n",
      "아 네 배달주문하고 방문포장예약에 대해서 안내 받고 싶은데요.\n",
      "아 네 배달주문하고 방문포장예약에 대해서 안내 받고 싶은데요.\n",
      "주차장이 따로 있나요?\n",
      "주차장이 따로 있나요?\n",
      "할인 어떤거 하나요?\n",
      "할인 어떤거 하나요?\n",
      "혹시 휴일과 평일에 영업시작시간이 다른가요 ?\n",
      "혹시 휴일과 평일에 영업시작시간이 다른가요 ?\n",
      "주말에는 언제가 주차하기 편한가요?\n",
      "주말에는 언제가 주차하기 편한가요?\n",
      "근처에 큰 건물 있나요?\n",
      "근처에 큰 건물 있나요?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "korean_script_list = list()\n",
    "jamo_script_list = list()\n",
    "\n",
    "true_jamo_regex_not  = re.compile(u'[^, .?!\\u1100-\\u115e\\u1161-\\u11A7\\u11a8-\\u11ff]+')\n",
    "\n",
    "valid_regex = re.compile(u'[,_ ^.?!？~<>:;/%()+A-Za-z0-9\\u1100-\\u115e\\u1161-\\u11A7\\u11a8-\\u11ff]+')\n",
    "\n",
    "count = 0\n",
    "\n",
    "for file in tqdm(korean_script_paths):\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        line = f.read()\n",
    "        line = line.strip()\n",
    "        korean_script_list.append(line)\n",
    "        jamo = jamotools.split_syllables(line, 'JAMO')\n",
    "        jamo_filtered = ''.join(true_jamo_regex.findall(jamo))\n",
    "        jamo_filtered = re.sub(true_jamo_regex_not, '*', jamo)\n",
    "        jamo_script_list.append(jamo_filtered)\n",
    "        \n",
    "        print(line)\n",
    "        print(jamo_filtered) \n",
    "        \n",
    "        if count == 200:\n",
    "            break\n",
    "        \n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Threading_Batched_Preloader():\n",
    "    def __init__(self, wav_path_list, ground_truth_list, script_path_list, batch_size, is_train=True):\n",
    "        super(Threading_Batched_Preloader).__init__()\n",
    "        self.wav_path_list = wav_path_list\n",
    "        self.total_num_input = len(wav_path_list)\n",
    "        self.tensor_input_list = [None] * self.total_num_input\n",
    "        self.ground_truth_list = ground_truth_list\n",
    "        self.script_path_list = script_path_list\n",
    "        self.sentence_length_list = np.asarray(list(map(len, ground_truth_list)))\n",
    "        self.shuffle_step = 12\n",
    "        self.loading_sequence = None\n",
    "        self.end_flag = False\n",
    "        self.batch_size = batch_size\n",
    "        self.queue = queue.Queue(32)\n",
    "        self.thread_flags = list()\n",
    "        self.is_train = is_train\n",
    "    \n",
    "    # Shuffle loading index and set end flag to false\n",
    "    def initialize_batch(self, thread_num):\n",
    "        loading_sequence = np.argsort(self.sentence_length_list)\n",
    "        bundle = np.stack([self.sentence_length_list[loading_sequence], loading_sequence])\n",
    "\n",
    "        for seq_len in range(self.shuffle_step, np.max(self.sentence_length_list), self.shuffle_step):\n",
    "            idxs = np.where((bundle[0, :] > seq_len) & (bundle[0, :] <= seq_len + self.shuffle_step))[0]\n",
    "            idxs_origin = copy.deepcopy(idxs)\n",
    "            random.shuffle(idxs)\n",
    "            bundle[:, idxs_origin] = bundle[:, idxs]\n",
    "            \n",
    "        loading_sequence = bundle[1, :]\n",
    "        loading_sequence_len = len(loading_sequence)\n",
    "        \n",
    "#         print(\"Loading Sequence Length: {}\".format(loading_sequence_len))\n",
    "        \n",
    "        thread_size = int(np.ceil(loading_sequence_len / thread_num))\n",
    "\n",
    "        load_idxs_list = list()\n",
    "        for i in range(thread_num):\n",
    "            start_idx = i * thread_size\n",
    "            end_idx = (i + 1) * thread_size\n",
    "\n",
    "            if end_idx > loading_sequence_len:\n",
    "                end_idx = loading_sequence_len\n",
    "\n",
    "            load_idxs_list.append(loading_sequence[start_idx:end_idx])\n",
    "            \n",
    "#         for i in range(thread_num):\n",
    "#             print(len(load_idxs_list[i]))\n",
    "\n",
    "        self.end_flag = False\n",
    "        \n",
    "        self.queue = queue.Queue(32)\n",
    "        self.thread_flags = [False] * thread_num\n",
    "        \n",
    "        self.thread_list = [Batching_Thread(self.wav_path_list, self.ground_truth_list, self.script_path_list, load_idxs_list[i], self.queue, self.batch_size, self.thread_flags, i, self.is_train) for i in range(thread_num)]\n",
    "\n",
    "        for thread in self.thread_list:\n",
    "            thread.start()\n",
    "        return\n",
    "\n",
    "    def check_thread_flags(self):\n",
    "        for flag in self.thread_flags:\n",
    "            if flag == False:\n",
    "                return False\n",
    "        \n",
    "        if (self.queue.empty):\n",
    "            self.end_flag = True\n",
    "            return True\n",
    "\n",
    "        return False\n",
    "\n",
    "    def get_batch(self):\n",
    "        while not (self.check_thread_flags()):\n",
    "            batch = self.queue.get()\n",
    "\n",
    "            if (batch != None):\n",
    "                batched_tensor = batch[0]\n",
    "                batched_ground_truth = batch[1] \n",
    "                batched_loss_mask = batch[2]\n",
    "                ground_truth_size_list = batch[3]\n",
    "                lev_truth_list = batch[4]\n",
    "\n",
    "                return batched_tensor, batched_ground_truth, batched_loss_mask, ground_truth_size_list, lev_truth_list\n",
    "\n",
    "        return None\n",
    "\n",
    "class Batching_Thread(threading.Thread):\n",
    "\n",
    "    def __init__(self, wav_path_list, ground_truth_list, script_path_list, load_idxs_list, queue, batch_size, thread_flags, id, is_train=True):\n",
    "        \n",
    "        threading.Thread.__init__(self)\n",
    "        self.wav_path_list = wav_path_list\n",
    "        self.ground_truth_list = ground_truth_list\n",
    "        self.script_path_list = script_path_list\n",
    "        self.load_idxs_list = load_idxs_list\n",
    "        self.list_len = len(load_idxs_list)\n",
    "        self.cur_idx = 0\n",
    "        self.id = id\n",
    "        self.queue = queue\n",
    "        self.batch_size = batch_size \n",
    "        self.thread_flags = thread_flags\n",
    "        self.is_train = is_train\n",
    "\n",
    "    def run(self):\n",
    "\n",
    "        while(self.cur_idx < self.list_len):\n",
    "            batch = self.batch()\n",
    "            success = False\n",
    "            while success == False:\n",
    "                try:\n",
    "                    self.queue.put(batch, True)\n",
    "                    success = True\n",
    "                except:\n",
    "                    print(\"Batching Failed in Thread ID: {}\".format(self.id))\n",
    "                    sleep(1)\n",
    "\n",
    "        self.thread_flags[self.id] = True\n",
    "        \n",
    "#         print(\"Thread {} finished\".foramt(self.id))\n",
    "\n",
    "        return \n",
    "\n",
    "\n",
    "    def batch(self):\n",
    "\n",
    "        tensor_list = list()\n",
    "        ground_truth_list = list()\n",
    "        tensor_size_list = list()\n",
    "        ground_truth_size_list = list()\n",
    "        lev_truth_list = list()\n",
    "        \n",
    "        count = 0\n",
    "        max_seq_len = 0\n",
    "        max_sen_len = 0\n",
    "        \n",
    "        for i in range(self.batch_size):\n",
    "            \n",
    "            # If there is no more file, break and set end_flag true\n",
    "            if self.cur_idx >= self.list_len:\n",
    "                self.end_flag = True\n",
    "                break\n",
    "                \n",
    "            script_path = self.script_path_list[self.load_idxs_list[self.cur_idx]]\n",
    "            \n",
    "#             print(script_path)\n",
    "            \n",
    "            with open(script_path) as f:\n",
    "                line = f.read()\n",
    "                line = line.strip()\n",
    "                lev_truth = list(map(int, line.split(' ')))\n",
    "                \n",
    "            lev_truth_list.append(lev_truth)\n",
    "            \n",
    "            wav_path = self.wav_path_list[self.load_idxs_list[self.cur_idx]]\n",
    "\n",
    "            tensor = self.create_mel(wav_path)\n",
    "            tensor_list.append(tensor)\n",
    "            tensor_size_list.append(tensor.shape[1])\n",
    "            \n",
    "            ground_truth = self.ground_truth_list[self.load_idxs_list[self.cur_idx]]\n",
    "            ground_truth_list.append(ground_truth)\n",
    "            ground_truth_size_list.append(len(ground_truth))\n",
    "            \n",
    "            if (tensor.shape[1] > max_seq_len):\n",
    "                max_seq_len = tensor.shape[1]\n",
    "            if (len(ground_truth) > max_sen_len):\n",
    "                max_sen_len = len(ground_truth)  \n",
    "            \n",
    "            self.cur_idx += 1\n",
    "            count += 1\n",
    "            \n",
    "        batched_tensor = torch.zeros(count, max_seq_len + 5, n_mels)\n",
    "        batched_ground_truth = torch.zeros(count, max_sen_len)\n",
    "        batched_loss_mask = torch.zeros(count, max_sen_len)\n",
    "        ground_truth_size_list = torch.tensor(np.asarray(ground_truth_size_list), dtype=torch.long)\n",
    "        \n",
    "        for order in range(count):\n",
    "            \n",
    "            target = tensor_list[order]\n",
    "            \n",
    "            if self.is_train:\n",
    "                pad_random = np.random.randint(0, 5)\n",
    "                # Time shift, add zeros in front of an image\n",
    "                if pad_random > 0:\n",
    "                    offset = torch.zeros(target.shape[0], pad_random, target.shape[2])\n",
    "                    target = torch.cat((offset, target), 1)\n",
    "                # Add random noise\n",
    "                target = target + (torch.rand(target.shape) - 0.5) / 20\n",
    "                # Value less than 0 or more than 1 is clamped to 0 and 1\n",
    "                target = torch.clamp(target, min=0.0, max=1.0)\n",
    "                batched_tensor[order, :tensor_size_list[order] + pad_random, :] = target\n",
    "            else:\n",
    "                batched_tensor[order, :tensor_size_list[order], :] = target\n",
    "\n",
    "#           batched_tensor[order, :tensor_size_list[order], :] = target\n",
    "            batched_ground_truth[order, :ground_truth_size_list[order]] = torch.tensor(ground_truth_list[order])\n",
    "            \n",
    "            # You do not need to know what loss mask is \n",
    "            batched_loss_mask[order, :ground_truth_size_list[order]] = torch.ones(ground_truth_size_list[order])\n",
    "        \n",
    "        return [batched_tensor, batched_ground_truth, batched_loss_mask, ground_truth_size_list, lev_truth_list]\n",
    "    \n",
    "    def create_mel(self, wav_path):  \n",
    "        y, sr = librosa.core.load(wav_path, sr=fs) \n",
    "        f, t, Zxx = sp.signal.stft(y, fs=sr, nperseg=nsc, noverlap=nov)\n",
    "        Sxx = np.abs(Zxx)\n",
    "\n",
    "        # mel_filters: (n_fft, n_mels)\n",
    "        mel_filters = librosa.filters.mel(sr=fs, n_fft=nsc, n_mels=n_mels)\n",
    "        mel_specgram = np.matmul(mel_filters, Sxx)\n",
    "\n",
    "        # log10(0) is minus infinite, so replace mel_specgram values smaller than 'eps' as 'eps' (1e-8)\n",
    "        log_mel_specgram = 20 * np.log10(np.maximum(mel_specgram, eps))\n",
    "        \n",
    "        # 20 * log10(eps) = 20 * -8 = -160\n",
    "        # -160 is the smallest value\n",
    "        # Add 160 and divide by 160 => Normalize value between 0 and 1\n",
    "        norm_log_mel_specgram = (log_mel_specgram + db_ref) / db_ref        \n",
    "        \n",
    "        # (F, T) -> (T, F)\n",
    "        input_spectrogram = norm_log_mel_specgram.T\n",
    "        # (T, F) -> (1, T, F)\n",
    "        # Inserted the first axis to make stacking easier\n",
    "        tensor_input = torch.tensor(input_spectrogram).view(1, input_spectrogram.shape[0], input_spectrogram.shape[1])\n",
    "        return tensor_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer maps numbers to characters, 8 -> 'ㄱ', 10 -> 'ㄴ'\n",
    "class Tokenizer():\n",
    "    def __init__(self, vocabs):\n",
    "        self.vocabs = vocabs\n",
    "        \n",
    "    def word2num(self, sentence):\n",
    "        tokens = list()\n",
    "        for char in sentence:\n",
    "            tokens.append(self.vocabs.index(char))    \n",
    "        return tokens\n",
    "        \n",
    "    def word2vec(self, sentence):\n",
    "        vectors = np.zeros((len(sentence), len(self.vocabs)))\n",
    "        for i, char in enumerate(sentence):\n",
    "            vectors[i, self.vocabs.index(char)] = 1   \n",
    "        return vectors\n",
    "    \n",
    "    def num2word(self, num):\n",
    "        output = list()\n",
    "        for i in num:\n",
    "            output.append(self.vocabs[i])\n",
    "        return output\n",
    "    \n",
    "    def num2vec(self, numbers):\n",
    "        vectors = np.zeros((len(numbers), len(self.vocabs)))\n",
    "        for i, num in enumerate(numbers):\n",
    "            vectors[i, num] = 1   \n",
    "        return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "9gbjg0_LPKA8",
    "outputId": "b2b29359-e867-4df6-e305-83de989ceef3"
   },
   "outputs": [],
   "source": [
    "unicode_jamo_list = list()\n",
    "\n",
    "# 초성\n",
    "for unicode in range(0x1100, 0x1113):\n",
    "    unicode_jamo_list.append(chr(unicode))  # chr: Change hexadecimal to unicode\n",
    "# 중성\n",
    "for unicode in range(0x1161, 0x1176):\n",
    "    unicode_jamo_list.append(chr(unicode))\n",
    "# 종성\n",
    "for unicode in range(0x11A8, 0x11C3):\n",
    "    unicode_jamo_list.append(chr(unicode))\n",
    "for unicode in range(ord('A'), ord('Z') + 1):\n",
    "    unicode_jamo_list.append(chr(unicode))\n",
    "for unicode in range(ord('a'), ord('z') + 1):\n",
    "    unicode_jamo_list.append(chr(unicode))\n",
    "for unicode in range(ord('0'), ord('9') + 1):\n",
    "    unicode_jamo_list.append(chr(unicode))\n",
    "\n",
    "unicode_jamo_list += [' ', '\\\\', '!', '~', '^', '<', '>', ',', '.', \"'\", '?', '？', '/', '%', '(', ')', ':', ';', '+',\n",
    "                      '-', '<s>', '</s>']\n",
    "unicode_jamo_list.sort()\n",
    "# '_' symbol represents \"blank\" in CTC loss system, \"blank\" has to be the index 0\n",
    "unicode_jamo_list = ['_'] + unicode_jamo_list\n",
    "\n",
    "tokenizer = Tokenizer(unicode_jamo_list)\n",
    "jamo_tokens = tokenizer.word2num(unicode_jamo_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_', ' ', '!', '%', \"'\", '(', ')', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '</s>', '<s>', '>', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '\\\\', '^', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '~', 'ᄀ', 'ᄁ', 'ᄂ', 'ᄃ', 'ᄄ', 'ᄅ', 'ᄆ', 'ᄇ', 'ᄈ', 'ᄉ', 'ᄊ', 'ᄋ', 'ᄌ', 'ᄍ', 'ᄎ', 'ᄏ', 'ᄐ', 'ᄑ', 'ᄒ', 'ᅡ', 'ᅢ', 'ᅣ', 'ᅤ', 'ᅥ', 'ᅦ', 'ᅧ', 'ᅨ', 'ᅩ', 'ᅪ', 'ᅫ', 'ᅬ', 'ᅭ', 'ᅮ', 'ᅯ', 'ᅰ', 'ᅱ', 'ᅲ', 'ᅳ', 'ᅴ', 'ᅵ', 'ᆨ', 'ᆩ', 'ᆪ', 'ᆫ', 'ᆬ', 'ᆭ', 'ᆮ', 'ᆯ', 'ᆰ', 'ᆱ', 'ᆲ', 'ᆳ', 'ᆴ', 'ᆵ', 'ᆶ', 'ᆷ', 'ᆸ', 'ᆹ', 'ᆺ', 'ᆻ', 'ᆼ', 'ᆽ', 'ᆾ', 'ᆿ', 'ᇀ', 'ᇁ', 'ᇂ', '？']\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151]\n"
     ]
    }
   ],
   "source": [
    "print(unicode_jamo_list)\n",
    "print(jamo_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'jamo_script_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-79c14d5f2e5c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mground_truth_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword2num\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'<s>'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjamo_script_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'</s>'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjamo_script_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'jamo_script_list' is not defined"
     ]
    }
   ],
   "source": [
    "ground_truth_list = [(tokenizer.word2num(['<s>'] + list(jamo_script_list[i]) + ['</s>'])) for i in range(len(jamo_script_list))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 90% of the data will be used as train\n",
    "split_index = int(0.9 * len(wav_paths))\n",
    "\n",
    "wav_path_list_train = wav_paths[:split_index]\n",
    "ground_truth_list_train = ground_truth_list[:split_index]\n",
    "script_path_list_train = script_paths[:split_index]\n",
    "\n",
    "wav_path_list_eval = wav_paths[split_index:]\n",
    "ground_truth_list_eval = ground_truth_list[split_index:]\n",
    "script_path_list_eval = script_paths[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "num_thread = 3\n",
    "\n",
    "preloader_eval = Threading_Batched_Preloader(wav_path_list_eval, ground_truth_list_eval, script_path_list_eval, batch_size, is_train=False)\n",
    "preloader_train = Threading_Batched_Preloader(wav_path_list_train, ground_truth_list_train, script_path_list_train, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, optimizer, ctc_loss, input_tensor, ground_truth, loss_mask, target_lengths):\n",
    "\n",
    "    # Shape of the input tensor (B, T, F)\n",
    "    # B: Number of a batch (8, 16, or 64 ...)\n",
    "    # T: Temporal length of an input\n",
    "    # F: Number of frequency band, 80\n",
    "\n",
    "    net.train()\n",
    "    \n",
    "    batch_size = input_tensor.shape[0]\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    pred_tensor = net(input_tensor)\n",
    "    \n",
    "    # Cast true sentence as Long data type, since CTC loss takes long tensor only\n",
    "    # Shape (B, S)\n",
    "    # S: Max length among true sentences \n",
    "    truth = ground_truth\n",
    "    truth = truth.type(torch.cuda.LongTensor)\n",
    "\n",
    "    input_lengths = torch.full(size=(batch_size,), fill_value=pred_tensor.shape[0], dtype=torch.long)\n",
    "\n",
    "    loss = ctc_loss(pred_tensor, truth, input_lengths, target_lengths)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Return loss divided by true length because loss is sum of the character losses\n",
    "\n",
    "    return pred_tensor, loss.item() / ground_truth.shape[1]\n",
    "\n",
    "\n",
    "def evaluate(net, ctc_loss, input_tensor, ground_truth, loss_mask, target_lengths):\n",
    "\n",
    "    # Shape of the input tensor (B, T, F)\n",
    "    # B: Number of a batch (8, 16, or 64 ...)\n",
    "    # T: Temporal length of an input\n",
    "    # F: Number of frequency band, 80\n",
    "\n",
    "    net.eval()\n",
    "    \n",
    "    batch_size = input_tensor.shape[0]\n",
    "    \n",
    "    pred_tensor = net(input_tensor)\n",
    "    \n",
    "    # Cast true sentence as Long data type, since CTC loss takes long tensor only\n",
    "    # Shape (B, S)\n",
    "    # S: Max length among true sentences \n",
    "    truth = ground_truth\n",
    "    truth = truth.type(torch.cuda.LongTensor)\n",
    "\n",
    "    input_lengths = torch.full(size=(batch_size,), fill_value=pred_tensor.shape[0], dtype=torch.long)\n",
    "\n",
    "    loss = ctc_loss(pred_tensor, truth, input_lengths, target_lengths)\n",
    "\n",
    "    # Return loss divided by true length because loss is sum of the character losses\n",
    "\n",
    "    return pred_tensor, loss.item() / ground_truth.shape[1]\n",
    "\n",
    "def save(model, optimizer, check_point_name):\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        }, check_point_name)\n",
    "\n",
    "def load(model, optimizer, check_point_name):\n",
    "    checkpoint = torch.load(check_point_name)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OG2yNubVPKBM"
   },
   "outputs": [],
   "source": [
    "# Use GPU if GPU is available \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, D_in, H):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.fc = torch.nn.Linear(D_in, H)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.gru = nn.GRU(H, int(H/2), bidirectional=True, batch_first=True)\n",
    "\n",
    "    def forward(self, input_tensor):\n",
    "        # (B, T, F)\n",
    "        output_tensor = self.fc(input_tensor)\n",
    "        output_tensor = self.relu(output_tensor)\n",
    "        output_tensor = self.dropout(output_tensor)\n",
    "        # (B, T, H)\n",
    "        output_tensor, _ = self.gru(output_tensor)\n",
    "        return output_tensor\n",
    "    \n",
    "class CTC_Decoder(nn.Module):\n",
    "    def __init__(self, H, D_out, num_chars):\n",
    "        super(CTC_Decoder, self).__init__()\n",
    "        self.fc_embed = nn.Linear(H, H)\n",
    "        self.relu_embed = torch.nn.ReLU()\n",
    "        self.dropout_embed = nn.Dropout(p=0.5) \n",
    "        self.gru = nn.GRU(H, D_out, batch_first=True)\n",
    "        self.fc = nn.Linear(D_out, num_chars)\n",
    "        self.log_softmax = nn.LogSoftmax(dim=2)\n",
    "\n",
    "    def forward(self, input_tensor):\n",
    "        # (B, T, 2 * H/2)\n",
    "        output_tensor = self.fc_embed(input_tensor)\n",
    "        output_tensor = self.relu_embed(output_tensor)\n",
    "        output_tensor = self.dropout_embed(output_tensor) \n",
    "        # (B, T, H)\n",
    "        output_tensor,_ = self.gru(input_tensor)\n",
    "        # (B, T, H)\n",
    "        output_tensor = self.fc(output_tensor)\n",
    "        # (B, T, 75)\n",
    "        prediction_tensor = self.log_softmax(output_tensor)\n",
    "\n",
    "        return prediction_tensor\n",
    "\n",
    "class Mel2SeqNet(nn.Module):\n",
    "    def __init__(self, D_in, H, D_out, num_chars, device):\n",
    "        super(Mel2SeqNet, self).__init__()\n",
    "        \n",
    "        self.encoder = Encoder(D_in, H).to(device)\n",
    "        self.decoder = CTC_Decoder(H, D_out, num_chars).to(device)\n",
    "        \n",
    "        # Initialize weights with random uniform numbers with range\n",
    "        for param in self.encoder.parameters():\n",
    "            param.data.uniform_(-0.1, 0.1)\n",
    "        for param in self.decoder.parameters():\n",
    "            param.data.uniform_(-0.1, 0.1)\n",
    "            \n",
    "    def forward(self, input_tensor):\n",
    "        batch_size = input_tensor.shape[0]\n",
    "        # (B, T, F) -> (B, T, H)\n",
    "        encoded_tensor = self.encoder(input_tensor)\n",
    "        # (B, T, H) -> (B, T, 75)\n",
    "        pred_tensor = self.decoder(encoded_tensor)\n",
    "        pred_tensor = pred_tensor.permute(1, 0, 2)\n",
    "        \n",
    "        return pred_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that interprets the CTC prediction result\n",
    "\n",
    "def Decode_CTC_Prediction(prediction):\n",
    "    CTC_pred = prediction.detach().cpu().numpy()\n",
    "    result = list()\n",
    "    last_elem = 0\n",
    "    for i, elem in enumerate(CTC_pred):\n",
    "        if elem != last_elem and elem != 0:\n",
    "            result.append(elem)\n",
    "        \n",
    "        last_elem = elem\n",
    "\n",
    "    result = np.asarray(result)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def label_to_string(labels):\n",
    "#     if len(labels.shape) == 1:\n",
    "#         sent = str()\n",
    "#         for i in labels:\n",
    "#             if i.item() == EOS_token:\n",
    "#                 break\n",
    "#             sent += index2char[i.item()]\n",
    "#         return sent\n",
    "\n",
    "#     elif len(labels.shape) == 2:\n",
    "#         sents = list()\n",
    "#         for i in labels:\n",
    "#             sent = str()\n",
    "#             for j in i:\n",
    "#                 if j.item() == EOS_token:\n",
    "#                     break\n",
    "#                 sent += index2char[j.item()]\n",
    "#             sents.append(sent)\n",
    "\n",
    "#         return sents\n",
    "    \n",
    "def lev_num_to_lev_string(lev_num_list, index2char):\n",
    "    lev_str_list = list()\n",
    "    for num_list in lev_num_list:\n",
    "        \n",
    "        temp = list()\n",
    "        for num in num_list:\n",
    "            temp.append(index2char[num])\n",
    "        \n",
    "        lev_str_list.append(''.join(temp))\n",
    "\n",
    "    return lev_str_list\n",
    "\n",
    "def char_distance(ref, hyp):\n",
    "    ref = ref.replace(' ', '') \n",
    "    hyp = hyp.replace(' ', '') \n",
    "\n",
    "    dist = Lev.distance(hyp, ref)\n",
    "    length = len(ref.replace(' ', ''))\n",
    "\n",
    "    return dist, length \n",
    "\n",
    "def char_distance_list(ref_list, hyp_list):\n",
    "\n",
    "    sum_dist = 0\n",
    "    sum_length = 0\n",
    "    \n",
    "    for ref, hyp in zip(ref_list, hyp_list):\n",
    "        dist, length = char_distance(ref, hyp)\n",
    "        sum_dist += dist\n",
    "        sum_length += length\n",
    "\n",
    "    return sum_dist, sum_length \n",
    "\n",
    "# def get_distance(ref_labels, hyp_labels, display=False):\n",
    "#     total_dist = 0\n",
    "#     total_length = 0\n",
    "#     for i in range(len(ref_labels)):\n",
    "#         ref = label_to_string(ref_labels[i])\n",
    "#         hyp = label_to_string(hyp_labels[i])\n",
    "#         dist, length = char_distance(ref, hyp)\n",
    "#         total_dist += dist\n",
    "#         total_length += length \n",
    "#         if display:\n",
    "#             cer = total_dist / total_length\n",
    "#             print('%d (%0.4f)\\n(%s)\\n(%s)' % (i, cer, ref, hyp))\n",
    "#     return total_dist, total_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def c2i_decoding(c2i, sentence):\n",
    "#     tokens = list()\n",
    "#     for char in sentence:\n",
    "#         try:\n",
    "#             tokens.append(c2i[char])   \n",
    "#         except:\n",
    "# #             print(char)\n",
    "#             pass\n",
    "#     return tokens\n",
    "\n",
    "def Decode_Prediction(pred_tensor, tokenizer, char2index):\n",
    "    decoded_list = list()\n",
    "    for i in range(pred_tensor.shape[1]):\n",
    "        _, CTC_index = pred_tensor[:, i, :].max(-1)\n",
    "        index = Decode_CTC_Prediction(CTC_index)\n",
    "        jamos = tokenizer.num2word(index)\n",
    "        sentence = jamotools.join_jamos(''.join(jamos))\n",
    "        \n",
    "        not_com_jamo = re.compile(u'[^\\u3130-\\u3190]')\n",
    "        filtered_sentence = ''.join(not_com_jamo.findall(sentence))\n",
    "        filtered_sentence = filtered_sentence.replace('<s>', '')\n",
    "        filtered_sentence = filtered_sentence.replace('</s>', '')\n",
    "#         filtered_sentence = filtered_sentence.replace('<eos>', '')\n",
    "#         final_prediction = c2i_decoding(char2index, filtered_sentence)\n",
    "        \n",
    "        decoded_list.append(filtered_sentence)\n",
    "    return decoded_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "Y9t1zv6cHp7y",
    "outputId": "e08fd2c2-ea3e-4479-e4c6-fe6dbe4e2a7a",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "EPOCH = 12 * 6     \n",
    "           \n",
    "# net = Mel2SeqNet(80, 512, 256)\n",
    "\n",
    "net = Mel2SeqNet(80, 1024, 512, len(unicode_jamo_list), device)\n",
    "\n",
    "net_optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "ctc_loss = nn.CTCLoss().to(device)\n",
    "\n",
    "keyword = 'NSML_100ms'\n",
    "\n",
    "train_loss_history = list()\n",
    "eval_loss_history = list()\n",
    "\n",
    "train_cer_history = list()\n",
    "eval_cer_history = list()\n",
    "\n",
    "try:\n",
    "    train_cer_history = list(np.load('model_saved/train_cer_history{}.npy'.format(keyword)))\n",
    "    eval_cer_history = list(np.load('model_saved/eval_cer_history{}.npy'.format(keyword)))\n",
    "except:\n",
    "    print(\"No CER Record\")\n",
    "\n",
    "try:\n",
    "    load(net, net_optimizer, 'model_saved/{}'.format(keyword))\n",
    "    train_loss_history = list(np.load('model_saved/train_loss_history_{}.npy'.format(keyword)))\n",
    "    eval_loss_history = list(np.load('model_saved/eval_loss_history_{}.npy'.format(keyword)))\n",
    "except:\n",
    "    print(\"Loading {} Error\".format(keyword))\n",
    "\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "\n",
    "    print((datetime.now().strftime('%m-%d %H:%M:%S')))\n",
    "\n",
    "    preloader_train.initialize_batch(num_thread)\n",
    "    loss_list_train = list()\n",
    "\n",
    "    total_dist = 0\n",
    "    total_length = 0\n",
    "#     count = 0\n",
    "    while preloader_train.end_flag == False:\n",
    "        batch = preloader_train.get_batch()\n",
    "        # logger.info(\"Got Batch\")\n",
    "        if batch != None:\n",
    "            tensor_input, ground_truth, loss_mask, length_list, lev_truth_list = batch\n",
    "            pred_tensor, loss = train(net, net_optimizer, ctc_loss, tensor_input.to(device),\n",
    "                                      ground_truth.to(device), loss_mask.to(device), length_list.to(device))\n",
    "            loss_list_train.append(loss)\n",
    "            \n",
    "            lev_pred_list = Decode_Prediction(pred_tensor, tokenizer, char2index)\n",
    "            lev_str_list = lev_num_to_lev_string(lev_truth_list, index2char)\n",
    "            dist, length = char_distance_list(lev_str_list, lev_pred_list)\n",
    "            total_dist += dist\n",
    "            total_length += length\n",
    "            \n",
    "#             print(\"Loss: {}\".format(loss))\n",
    "#             count += 1\n",
    "#             print(\"Train {}/{}\".format(count, int(np.ceil(len(wav_path_list_train)/batch_size))))\n",
    "#             # logger.info(\"Training\")\n",
    "\n",
    "    train_cer = total_dist / total_length\n",
    "    train_loss = np.mean(np.asarray(loss_list_train))\n",
    "    print((datetime.now().strftime('%m-%d %H:%M:%S')))\n",
    "    print(\"Mean Train Loss: {}\".format(train_loss))\n",
    "    print(\"Train CER: {}\".format(train_cer))\n",
    "    train_loss_history.append(train_loss)\n",
    "    train_cer_history.append(train_cer)\n",
    "    \n",
    "    preloader_eval.initialize_batch(num_thread)\n",
    "    loss_list_eval = list()\n",
    "\n",
    "    total_dist = 0\n",
    "    total_length = 0\n",
    "    \n",
    "    while preloader_eval.end_flag == False:\n",
    "        batch = preloader_eval.get_batch()\n",
    "        if batch != None:\n",
    "            tensor_input, ground_truth_, loss_mask, length_list, lev_truth_list_ = batch\n",
    "            pred_tensor_, loss = evaluate(net, ctc_loss, tensor_input.to(device), ground_truth_.to(device),\n",
    "                                          loss_mask.to(device), length_list.to(device))\n",
    "            loss_list_eval.append(loss)\n",
    "            \n",
    "            lev_pred_list = Decode_Prediction(pred_tensor_, tokenizer, char2index)\n",
    "            lev_str_list = lev_num_to_lev_string(lev_truth_list_, index2char)\n",
    "            dist, length = char_distance_list(lev_str_list, lev_pred_list)\n",
    "            total_dist += dist\n",
    "            total_length += length\n",
    "            \n",
    "    eval_cer = total_dist / total_length\n",
    "    eval_loss = np.mean(np.asarray(loss_list_eval))\n",
    "    print((datetime.now().strftime('%m-%d %H:%M:%S')))\n",
    "    print(\"Mean Evaluation Loss: {}\".format(eval_loss))\n",
    "    print(\"Evaluation CER: {}\".format(eval_cer))\n",
    "    eval_loss_history.append(eval_loss)\n",
    "    eval_cer_history.append(eval_cer)\n",
    "    \n",
    "    #####\n",
    "    \n",
    "    save(net, net_optimizer, 'model_saved/{}'.format(keyword))\n",
    "    np.save('model_saved/train_loss_history_{}'.format(keyword), train_loss_history)\n",
    "    np.save('model_saved/eval_loss_history_{}'.format(keyword), eval_loss_history)\n",
    "    np.save('model_saved/train_cer_history{}'.format(keyword), train_cer_history)\n",
    "    np.save('model_saved/eval_cer_history{}'.format(keyword), eval_cer_history)\n",
    "            \n",
    "    #####    \n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(train_loss_history)\n",
    "    plt.plot(eval_loss_history)\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(train_cer_history)\n",
    "    plt.plot(eval_cer_history)\n",
    "    plt.show()\n",
    "\n",
    "    # index is the position of the max probility of the first batch\n",
    "    # Shape of the pred_tensor: (T, B, 75)\n",
    "    # Shape of the index: (T)\n",
    "    _, index = pred_tensor[:, 0, :].max(-1)\n",
    "\n",
    "    # Change index numbers to character\n",
    "    sentence = tokenizer.num2word(index.view(-1))\n",
    "\n",
    "    # Change list to string\n",
    "    print(''.join(sentence))\n",
    "\n",
    "    # Remove \"blank\" and overlapping characters\n",
    "    index_ = Decode_CTC_Prediction(index)\n",
    "    sentence_ = tokenizer.num2word(index_)\n",
    "    print(''.join(sentence_))\n",
    "\n",
    "    true_sentence = tokenizer.num2word(ground_truth[0, :].detach().numpy().astype(int))\n",
    "    print(''.join(true_sentence))\n",
    "\n",
    "    # Plot image\n",
    "    # detach().cpu().numpy() transforms a tensor on gpu into a numpy matrix\n",
    "    plt.figure()\n",
    "    plt.imshow(pred_tensor[:, 0, :].detach().cpu().numpy())\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "\n",
    "    _, index = pred_tensor_[:, 0, :].max(-1)\n",
    "\n",
    "    sentence = tokenizer.num2word(index.view(-1))\n",
    "    print(''.join(sentence))\n",
    "    index_ = Decode_CTC_Prediction(index)\n",
    "    sentence_ = tokenizer.num2word(index_)\n",
    "    print(''.join(sentence_))\n",
    "    true_sentence = tokenizer.num2word(ground_truth_[0, :].detach().numpy().astype(int))\n",
    "    print(''.join(true_sentence))\n",
    "\n",
    "    plt.figure()\n",
    "    plt.imshow(pred_tensor_[:, 0, :].detach().cpu().numpy())\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "        \n",
    "    print(\"-------------------------------------------------------------------------------------------------------\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "CTC_best_result_on_Colab.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
